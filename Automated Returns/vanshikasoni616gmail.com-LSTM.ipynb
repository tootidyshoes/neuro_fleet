{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Credits: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "#https://www.liip.ch/en/blog/sentiment-detection-with-keras-word-embeddings-and-lstm-deep-learning-networks\n",
    "\n",
    "# LSTM for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.preprocessing import text,sequence\n",
    "from tensorflow.keras.layers import Activation, Add, Bidirectional, Conv1D, Dense, Dropout, Embedding, Flatten, Reshape\n",
    "from tensorflow.keras.layers import concatenate, GRU, Input, CuDNNLSTM, MaxPooling1D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D,  GlobalMaxPooling1D, SpatialDropout1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.python.keras import backend as k\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160221</td>\n",
       "      <td>p253737</td>\n",
       "      <td>c90749f5d961ff158d4b4d1e7dc665fc</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>IN</td>\n",
       "      <td>2016-12-05 13:43:57</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>ESL, Literacy</td>\n",
       "      <td>Educational Support for English Learners at Home</td>\n",
       "      <td>My students are English learners that are work...</td>\n",
       "      <td>\\\"The limits of your language are the limits o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need opportunities to practice beg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140945</td>\n",
       "      <td>p258326</td>\n",
       "      <td>897464ce9ddc600bced1151f324dd63a</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-10-25 09:22:10</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>History &amp; Civics, Health &amp; Sports</td>\n",
       "      <td>Civics &amp; Government, Team Sports</td>\n",
       "      <td>Wanted: Projector for Hungry Learners</td>\n",
       "      <td>Our students arrive to our school eager to lea...</td>\n",
       "      <td>The projector we need for our school is very c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need a projector to help with view...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21895</td>\n",
       "      <td>p182444</td>\n",
       "      <td>3465aaf82da834c0582ebd0ef8040ca0</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2016-08-31 12:03:56</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>Health &amp; Sports</td>\n",
       "      <td>Health &amp; Wellness, Team Sports</td>\n",
       "      <td>Soccer Equipment for AWESOME Middle School Stu...</td>\n",
       "      <td>\\r\\n\\\"True champions aren't always the ones th...</td>\n",
       "      <td>The students on the campus come to school know...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need shine guards, athletic socks,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id                        teacher_id teacher_prefix  \\\n",
       "0      160221  p253737  c90749f5d961ff158d4b4d1e7dc665fc           Mrs.   \n",
       "1      140945  p258326  897464ce9ddc600bced1151f324dd63a            Mr.   \n",
       "2       21895  p182444  3465aaf82da834c0582ebd0ef8040ca0            Ms.   \n",
       "\n",
       "  school_state project_submitted_datetime project_grade_category  \\\n",
       "0           IN        2016-12-05 13:43:57          Grades PreK-2   \n",
       "1           FL        2016-10-25 09:22:10             Grades 6-8   \n",
       "2           AZ        2016-08-31 12:03:56             Grades 6-8   \n",
       "\n",
       "          project_subject_categories     project_subject_subcategories  \\\n",
       "0                Literacy & Language                     ESL, Literacy   \n",
       "1  History & Civics, Health & Sports  Civics & Government, Team Sports   \n",
       "2                    Health & Sports    Health & Wellness, Team Sports   \n",
       "\n",
       "                                       project_title  \\\n",
       "0   Educational Support for English Learners at Home   \n",
       "1              Wanted: Projector for Hungry Learners   \n",
       "2  Soccer Equipment for AWESOME Middle School Stu...   \n",
       "\n",
       "                                     project_essay_1  \\\n",
       "0  My students are English learners that are work...   \n",
       "1  Our students arrive to our school eager to lea...   \n",
       "2  \\r\\n\\\"True champions aren't always the ones th...   \n",
       "\n",
       "                                     project_essay_2 project_essay_3  \\\n",
       "0  \\\"The limits of your language are the limits o...             NaN   \n",
       "1  The projector we need for our school is very c...             NaN   \n",
       "2  The students on the campus come to school know...             NaN   \n",
       "\n",
       "  project_essay_4                           project_resource_summary  \\\n",
       "0             NaN  My students need opportunities to practice beg...   \n",
       "1             NaN  My students need a projector to help with view...   \n",
       "2             NaN  My students need shine guards, athletic socks,...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \n",
       "0                                             0                    0  \n",
       "1                                             7                    1  \n",
       "2                                             1                    0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Resource_summary_has_digit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def hasNumbers(inputString):\n",
    "    return bool(re.search(r'\\d',inputString))\n",
    " \n",
    "resource_summary=list(df['project_resource_summary'].values)\n",
    "has_digits = [] \n",
    "for i in resource_summary:\n",
    "    if (hasNumbers(i)==True):\n",
    "        has_digits.append(1)\n",
    "    else:        \n",
    "        has_digits.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'project_title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "import re\n",
    "\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 109248/109248 [00:02<00:00, 51669.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# https://gist.github.com/sebleier/554280\n",
    "# we are removing the words from the stop words list: 'no', 'nor'\n",
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "preprocessed_title = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(df['project_title'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('nannan', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sent = ' '.join(e for e in sent.split(\" \") if e not in stopwords)\n",
    "    preprocessed_title.append(sent.lower().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'project_resource_summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 109248/109248 [00:04<00:00, 22683.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "summary = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(df['project_resource_summary'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('nannan', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sent = ' '.join(e for e in sent.split(\" \") if e not in stopwords)\n",
    "    summary.append(sent.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = pd.read_csv(\"preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data[\"title\"] = preprocessed_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['summary'] = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['summary_digits']=has_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109248, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_digits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>725.05</td>\n",
       "      <td>educational support english learners home</td>\n",
       "      <td>students need opportunities practice beginning...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>213.03</td>\n",
       "      <td>wanted projector hungry learners</td>\n",
       "      <td>students need projector help viewing education...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>having class 24 students comes diverse learner...</td>\n",
       "      <td>329.00</td>\n",
       "      <td>soccer equipment awesome middle school students</td>\n",
       "      <td>students need shine guards athletic socks socc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ga</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>appliedlearning</td>\n",
       "      <td>earlydevelopment</td>\n",
       "      <td>i recently read article giving students choice...</td>\n",
       "      <td>481.04</td>\n",
       "      <td>techie kindergarteners</td>\n",
       "      <td>students need engage reading math way inspire ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wa</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>my students crave challenge eat obstacles brea...</td>\n",
       "      <td>17.74</td>\n",
       "      <td>interactive math tools</td>\n",
       "      <td>students need hands practice mathematics fun p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state teacher_prefix project_grade_category  \\\n",
       "0           ca            mrs          grades_prek_2   \n",
       "1           ut             ms             grades_3_5   \n",
       "2           ca            mrs          grades_prek_2   \n",
       "3           ga            mrs          grades_prek_2   \n",
       "4           wa            mrs             grades_3_5   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            53                    1   \n",
       "1                                             4                    1   \n",
       "2                                            10                    1   \n",
       "3                                             2                    1   \n",
       "4                                             2                    1   \n",
       "\n",
       "    clean_categories                 clean_subcategories  \\\n",
       "0       math_science  appliedsciences health_lifescience   \n",
       "1       specialneeds                        specialneeds   \n",
       "2  literacy_language                            literacy   \n",
       "3    appliedlearning                    earlydevelopment   \n",
       "4  literacy_language                            literacy   \n",
       "\n",
       "                                               essay   price  \\\n",
       "0  i fortunate enough use fairy tale stem kits cl...  725.05   \n",
       "1  imagine 8 9 years old you third grade classroo...  213.03   \n",
       "2  having class 24 students comes diverse learner...  329.00   \n",
       "3  i recently read article giving students choice...  481.04   \n",
       "4  my students crave challenge eat obstacles brea...   17.74   \n",
       "\n",
       "                                             title  \\\n",
       "0        educational support english learners home   \n",
       "1                 wanted projector hungry learners   \n",
       "2  soccer equipment awesome middle school students   \n",
       "3                           techie kindergarteners   \n",
       "4                           interactive math tools   \n",
       "\n",
       "                                             summary  summary_digits  \n",
       "0  students need opportunities practice beginning...               0  \n",
       "1  students need projector help viewing education...               0  \n",
       "2  students need shine guards athletic socks socc...               0  \n",
       "3  students need engage reading math way inspire ...               0  \n",
       "4  students need hands practice mathematics fun p...               0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes : ['school_state' 'teacher_prefix' 'project_grade_category'\n",
      " 'teacher_number_of_previously_posted_projects' 'project_is_approved'\n",
      " 'clean_categories' 'clean_subcategories' 'essay' 'price' 'title'\n",
      " 'summary' 'summary_digits']\n"
     ]
    }
   ],
   "source": [
    "#Printing the attributes of project_data\n",
    "print(\"Attributes :\", project_data.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_data = pd.read_csv('resources.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p233245</td>\n",
       "      <td>LC652 - Lakeshore Double-Space Mobile Drying Rack</td>\n",
       "      <td>1</td>\n",
       "      <td>149.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Bouncy Bands for Desks (Blue support pipes)</td>\n",
       "      <td>3</td>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Cory Stories: A Kid's Book About Living With Adhd</td>\n",
       "      <td>1</td>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  quantity  \\\n",
       "0  p233245  LC652 - Lakeshore Double-Space Mobile Drying Rack         1   \n",
       "1  p069063        Bouncy Bands for Desks (Blue support pipes)         3   \n",
       "2  p069063  Cory Stories: A Kid's Book About Living With Adhd         1   \n",
       "\n",
       "    price  \n",
       "0  149.00  \n",
       "1   14.95  \n",
       "2    8.45  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p000001</td>\n",
       "      <td>459.56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p000002</td>\n",
       "      <td>515.89</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   price  quantity\n",
       "0  p000001  459.56         7\n",
       "1  p000002  515.89        21"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reference : https://stackoverflow.com/questions/22407798/how-to-reset-a-dataframes-indexes-for-all-groups-in-one-step\n",
    "price_data = resource_data.groupby('id').agg({'price':'sum', 'quantity':'sum'}).reset_index()\n",
    "price_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join two dataframes(project_data and price_data) in python\n",
    "# reference : https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
    "project_data['price'] = resource_data['price']\n",
    "project_data['quantity'] = resource_data['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_digits</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>149.00</td>\n",
       "      <td>educational support english learners home</td>\n",
       "      <td>students need opportunities practice beginning...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>14.95</td>\n",
       "      <td>wanted projector hungry learners</td>\n",
       "      <td>students need projector help viewing education...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state teacher_prefix project_grade_category  \\\n",
       "0           ca            mrs          grades_prek_2   \n",
       "1           ut             ms             grades_3_5   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            53                    1   \n",
       "1                                             4                    1   \n",
       "\n",
       "  clean_categories                 clean_subcategories  \\\n",
       "0     math_science  appliedsciences health_lifescience   \n",
       "1     specialneeds                        specialneeds   \n",
       "\n",
       "                                               essay   price  \\\n",
       "0  i fortunate enough use fairy tale stem kits cl...  149.00   \n",
       "1  imagine 8 9 years old you third grade classroo...   14.95   \n",
       "\n",
       "                                       title  \\\n",
       "0  educational support english learners home   \n",
       "1           wanted projector hungry learners   \n",
       "\n",
       "                                             summary  summary_digits  quantity  \n",
       "0  students need opportunities practice beginning...               0         1  \n",
       "1  students need projector help viewing education...               0         3  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Total numerical features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical inputs\n",
    "project_data['num'] = project_data['teacher_number_of_previously_posted_projects'] + project_data['price'] + project_data['quantity']+project_data['summary_digits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Total text data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['total_text'] = project_data['essay']+ \" \" +project_data['title']+ \" \" + project_data['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_digits</th>\n",
       "      <th>quantity</th>\n",
       "      <th>num</th>\n",
       "      <th>total_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>149.00</td>\n",
       "      <td>educational support english learners home</td>\n",
       "      <td>students need opportunities practice beginning...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>203.00</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>14.95</td>\n",
       "      <td>wanted projector hungry learners</td>\n",
       "      <td>students need projector help viewing education...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21.95</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>having class 24 students comes diverse learner...</td>\n",
       "      <td>8.45</td>\n",
       "      <td>soccer equipment awesome middle school students</td>\n",
       "      <td>students need shine guards athletic socks socc...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.45</td>\n",
       "      <td>having class 24 students comes diverse learner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ga</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>appliedlearning</td>\n",
       "      <td>earlydevelopment</td>\n",
       "      <td>i recently read article giving students choice...</td>\n",
       "      <td>13.59</td>\n",
       "      <td>techie kindergarteners</td>\n",
       "      <td>students need engage reading math way inspire ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17.59</td>\n",
       "      <td>i recently read article giving students choice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wa</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>my students crave challenge eat obstacles brea...</td>\n",
       "      <td>24.95</td>\n",
       "      <td>interactive math tools</td>\n",
       "      <td>students need hands practice mathematics fun p...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.95</td>\n",
       "      <td>my students crave challenge eat obstacles brea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state teacher_prefix project_grade_category  \\\n",
       "0           ca            mrs          grades_prek_2   \n",
       "1           ut             ms             grades_3_5   \n",
       "2           ca            mrs          grades_prek_2   \n",
       "3           ga            mrs          grades_prek_2   \n",
       "4           wa            mrs             grades_3_5   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            53                    1   \n",
       "1                                             4                    1   \n",
       "2                                            10                    1   \n",
       "3                                             2                    1   \n",
       "4                                             2                    1   \n",
       "\n",
       "    clean_categories                 clean_subcategories  \\\n",
       "0       math_science  appliedsciences health_lifescience   \n",
       "1       specialneeds                        specialneeds   \n",
       "2  literacy_language                            literacy   \n",
       "3    appliedlearning                    earlydevelopment   \n",
       "4  literacy_language                            literacy   \n",
       "\n",
       "                                               essay   price  \\\n",
       "0  i fortunate enough use fairy tale stem kits cl...  149.00   \n",
       "1  imagine 8 9 years old you third grade classroo...   14.95   \n",
       "2  having class 24 students comes diverse learner...    8.45   \n",
       "3  i recently read article giving students choice...   13.59   \n",
       "4  my students crave challenge eat obstacles brea...   24.95   \n",
       "\n",
       "                                             title  \\\n",
       "0        educational support english learners home   \n",
       "1                 wanted projector hungry learners   \n",
       "2  soccer equipment awesome middle school students   \n",
       "3                           techie kindergarteners   \n",
       "4                           interactive math tools   \n",
       "\n",
       "                                             summary  summary_digits  \\\n",
       "0  students need opportunities practice beginning...               0   \n",
       "1  students need projector help viewing education...               0   \n",
       "2  students need shine guards athletic socks socc...               0   \n",
       "3  students need engage reading math way inspire ...               0   \n",
       "4  students need hands practice mathematics fun p...               0   \n",
       "\n",
       "   quantity     num                                         total_text  \n",
       "0         1  203.00  i fortunate enough use fairy tale stem kits cl...  \n",
       "1         3   21.95  imagine 8 9 years old you third grade classroo...  \n",
       "2         1   19.45  having class 24 students comes diverse learner...  \n",
       "3         2   17.59  i recently read article giving students choice...  \n",
       "4         3   29.95  my students crave challenge eat obstacles brea...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['teacher_number_of_previously_posted_projects', 'price', 'quantity','essay','title','summary','summary_digits']\n",
    "\n",
    "project_data.drop(labels=col,axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>num</th>\n",
       "      <th>total_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>203.00</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>21.95</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>19.45</td>\n",
       "      <td>having class 24 students comes diverse learner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ga</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>1</td>\n",
       "      <td>appliedlearning</td>\n",
       "      <td>earlydevelopment</td>\n",
       "      <td>17.59</td>\n",
       "      <td>i recently read article giving students choice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wa</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>29.95</td>\n",
       "      <td>my students crave challenge eat obstacles brea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state teacher_prefix project_grade_category  project_is_approved  \\\n",
       "0           ca            mrs          grades_prek_2                    1   \n",
       "1           ut             ms             grades_3_5                    1   \n",
       "2           ca            mrs          grades_prek_2                    1   \n",
       "3           ga            mrs          grades_prek_2                    1   \n",
       "4           wa            mrs             grades_3_5                    1   \n",
       "\n",
       "    clean_categories                 clean_subcategories     num  \\\n",
       "0       math_science  appliedsciences health_lifescience  203.00   \n",
       "1       specialneeds                        specialneeds   21.95   \n",
       "2  literacy_language                            literacy   19.45   \n",
       "3    appliedlearning                    earlydevelopment   17.59   \n",
       "4  literacy_language                            literacy   29.95   \n",
       "\n",
       "                                          total_text  \n",
       "0  i fortunate enough use fairy tale stem kits cl...  \n",
       "1  imagine 8 9 years old you third grade classroo...  \n",
       "2  having class 24 students comes diverse learner...  \n",
       "3  i recently read article giving students choice...  \n",
       "4  my students crave challenge eat obstacles brea...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109248, 7)\n",
      "(109248,)\n"
     ]
    }
   ],
   "source": [
    "y = project_data['project_is_approved']\n",
    "project_data.drop(['project_is_approved'], axis=1, inplace=True)\n",
    "X = project_data\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data, stratify sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y , stratify = y, train_size = 0.7)\n",
    "X_train,X_cv,y_train,y_cv = train_test_split(X_train,y_train,stratify = y_train,train_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 7) (53531,)\n",
      "(22942, 7) (22942,)\n",
      "(32775, 7) (32775,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_cv.shape, y_cv.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting class labels to categorical variables\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_cv = to_categorical(y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Featurization and padding text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train['total_text'])\n",
    "word_index = t.word_index\n",
    "text_train = t.texts_to_sequences(X_train['total_text'])\n",
    "text_test = t.texts_to_sequences(X_test['total_text'])\n",
    "text_cv = t.texts_to_sequences(X_cv['total_text'])\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_review_length = 300\n",
    "text_train = pad_sequences(text_train, maxlen=max_review_length) \n",
    "text_test = pad_sequences(text_test, maxlen=max_review_length)\n",
    "text_cv = pad_sequences(text_cv, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,   10, 1572,   70, 2212,\n",
       "       1567,    7,    1,    5, 1572, 1008, 1541,    7,    1,  621, 1767,\n",
       "        114,   14,  947, 2425,  279,  327,  264, 2425,  279,  197,  456,\n",
       "          3,   31,  162,  177,   38,   39,   89,    2,   50,  125,   38,\n",
       "        284,    3,  524,  455, 4935,    1,  657,   72,  173,   92,   14,\n",
       "         25,   24, 1564,  326,    7,    1,   19,   24,  484,  968,  603,\n",
       "        649, 2767,    7,    3, 2505,   24,  215,    1,   56,    2, 4017,\n",
       "        395,  725,   11,  420,   24,  572, 2682,   49,    3,    7,  162,\n",
       "         51,    6,   83,    1,  385,   24,  177,   90,  572,  539,   26,\n",
       "          1,   71,  263,  177, 1947, 1008, 1541,  441, 2064, 2250,   26,\n",
       "         29, 2177, 2401, 2273,  572,  505,  406,  939,   17,   71,  781,\n",
       "       3488,   90,  127,    8, 2141, 2059,    1,   71,  150,  177, 1947,\n",
       "       1008, 1541,  441, 2064, 2250,   26,   29, 2177, 2401, 2273,  572,\n",
       "        505,  406,  939,   17,   71,  781, 3488,   90,  127,    8, 2141,\n",
       "       2059,    7,    1,   11, 1714, 1137,   90,    8,  327,  279,  320,\n",
       "        150,  103,   87,  379,  224, 1133,  424,  371, 2528, 3403, 1753,\n",
       "        168,  132,    1,  493,  223,    2,  320,   51,  128,    1,   11,\n",
       "         30,  395,   24,   26,    7,    1,  854, 2340,   24, 2035,   24,\n",
       "        168,  114,  409,    2,  143, 1384,   27, 7246,  569,    1,  160,\n",
       "         15, 4155,  678,  764,  427,    1,    1,    4,  764,  427, 4155,\n",
       "        678, 2327,   36])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating embedding matrix using pretrain golve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1917495 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.42B.300d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.15243   , -0.16945   , -0.022748  , ...,  0.61800998,\n",
       "         0.41281   ,  0.0010077 ],\n",
       "       [-0.043504  , -0.18483999, -0.14613   , ...,  0.1008    ,\n",
       "         0.1068    ,  0.089065  ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.14264999, -0.20883   ,  0.53634   , ...,  0.19422001,\n",
       "         0.062518  ,  0.018873  ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. School_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(X_train['school_state'])\n",
    "\n",
    "state_train = le.transform(X_train['school_state'])\n",
    "state_test = le.transform(X_test['school_state'])\n",
    "state_cv = le.transform(X_cv['school_state'])\n",
    "\n",
    "print(state_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Teacher_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531,)\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(X_train['teacher_prefix'])\n",
    "\n",
    "prefix_train = le.transform(X_train['teacher_prefix'])\n",
    "prefix_test = le.transform(X_test['teacher_prefix'])\n",
    "prefix_cv = le.transform(X_cv['teacher_prefix'])\n",
    "\n",
    "print(prefix_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Project_grade_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531,)\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(X_train['project_grade_category'])\n",
    "\n",
    "grade_train = le.transform(X_train['project_grade_category'])\n",
    "grade_test = le.transform(X_test['project_grade_category'])\n",
    "grade_cv = le.transform(X_cv['project_grade_category'])\n",
    "\n",
    "print(grade_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Clean_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 5)\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train['clean_categories'])\n",
    "word_index = t.word_index\n",
    "clean_cat_train = t.texts_to_sequences(X_train['clean_categories'])\n",
    "clean_cat_test = t.texts_to_sequences(X_test['clean_categories'])\n",
    "clean_cat_cv = t.texts_to_sequences(X_cv['clean_categories'])\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_review_length = 5\n",
    "clean_cat_train = pad_sequences(clean_cat_train, maxlen=max_review_length) \n",
    "clean_cat_test = pad_sequences(clean_cat_test, maxlen=max_review_length)\n",
    "clean_cat_cv = pad_sequences(clean_cat_cv, maxlen=max_review_length)\n",
    "\n",
    "print(clean_cat_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Clean_subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 5)\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train['clean_subcategories'])\n",
    "word_index = t.word_index\n",
    "clean_subcat_train = t.texts_to_sequences(X_train['clean_subcategories'])\n",
    "clean_subcat_test = t.texts_to_sequences(X_test['clean_subcategories'])\n",
    "clean_subcat_cv = t.texts_to_sequences(X_cv['clean_subcategories'])\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_review_length = 5\n",
    "clean_subcat_train = pad_sequences(clean_subcat_train, maxlen=max_review_length) \n",
    "clean_subcat_test = pad_sequences(clean_subcat_test, maxlen=max_review_length)\n",
    "clean_subcat_cv = pad_sequences(clean_subcat_cv, maxlen=max_review_length)\n",
    "\n",
    "print(clean_subcat_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler()\n",
    "scalar.fit(X_train['num'].values.reshape(-1,1))\n",
    "# finding the mean and standar \n",
    " \n",
    "# Now standardize the data with above maen and variance. \n",
    "num_train = scalar.transform(X_train['num'].values.reshape(-1, 1))\n",
    "num_cv = scalar.transform(X_cv['num'].values.reshape(-1, 1))\n",
    "num_test = scalar.transform(X_test['num'].values.reshape(-1, 1))\n",
    "\n",
    "print(num_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
    "#https://developpaper.com/question/how-to-apply-the-custom-operation-of-py_func-in-tensorflow-to-keras/\n",
    "def auc(y_true, y_pred) :\n",
    "    score = tf.py_func( lambda y_true, y_pred : roc_auc_score(y_true, y_pred, average='macro', sample_weight=None).astype('float32'),\n",
    "                        [y_true, y_pred],\n",
    "                        'float32',\n",
    "                        stateful=True,\n",
    "                        name='sklearnAUC')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/w395Yk9.png'>\n",
    "ref: https://i.imgur.com/w395Yk9.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To find the embedding size and vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "School_state\n",
      "embedding_output_dim 26\n",
      "vocab 52\n",
      "--------------------------------------------------\n",
      "Teacher_prefix\n",
      "embedding_output_dim 3\n",
      "vocab 6\n",
      "--------------------------------------------------\n",
      "Grade_category\n",
      "embedding_output_dim 2\n",
      "vocab 5\n",
      "--------------------------------------------------\n",
      "Subject_categories\n",
      "embedding_output_dim 25\n",
      "vocab 51\n",
      "--------------------------------------------------\n",
      "Subject_categories\n",
      "embedding_output_dim 50\n",
      "vocab 376\n"
     ]
    }
   ],
   "source": [
    "no_of_unique_cat  = X_train['school_state'].nunique()\n",
    "embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
    "print(\"School_state\")\n",
    "print(\"embedding_output_dim\",int(embedding_size))\n",
    "print('vocab', no_of_unique_cat+1)\n",
    "print(\"-\"*50)\n",
    "\n",
    "no_of_unique_cat  = X_train['teacher_prefix'].nunique()\n",
    "embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
    "print(\"Teacher_prefix\")\n",
    "print(\"embedding_output_dim\",int(embedding_size))\n",
    "print('vocab', no_of_unique_cat+1)\n",
    "print(\"-\"*50)\n",
    "\n",
    "no_of_unique_cat  = X_train['project_grade_category'].nunique()\n",
    "embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
    "print(\"Grade_category\")\n",
    "print(\"embedding_output_dim\",int(embedding_size))\n",
    "print('vocab', no_of_unique_cat+1)\n",
    "print(\"-\"*50)\n",
    "\n",
    "no_of_unique_cat  = X_train['clean_categories'].nunique()\n",
    "embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
    "print(\"Subject_categories\")\n",
    "print(\"embedding_output_dim\",int(embedding_size))\n",
    "print('vocab', no_of_unique_cat+1)\n",
    "print(\"-\"*50)\n",
    "\n",
    "no_of_unique_cat  = X_train['clean_subcategories'].nunique()\n",
    "embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
    "print(\"Subject_categories\")\n",
    "print(\"embedding_output_dim\",int(embedding_size))\n",
    "print('vocab', no_of_unique_cat+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vansh\\Anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\vansh\\Anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-46-9c0679feb436>:8: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 300, 300)     13936200    text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 300, 300)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "state (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prefix (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "grade (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subject_category (InputLayer)   [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subject_sub_category (InputLaye [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)          (None, 300, 256)     571392      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 26)        1352        state[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 3)         18          prefix[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 2)         10          grade[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 5, 25)        1275        subject_category[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 5, 50)        18800       subject_sub_category[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "numerical (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 76800)        0           cu_dnnlstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 26)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 3)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 125)          0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 250)          0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           32          numerical[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 77222)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          9884544     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64)           256         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            66          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,424,281\n",
      "Trainable params: 10,487,953\n",
      "Non-trainable params: 13,936,328\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Essay input --> 1\n",
    "text = Input(shape=(300,), name=\"text\")\n",
    "x1 = Embedding(input_dim=46454,output_dim=300,trainable=False,weights=[embedding_matrix])(text)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = CuDNNLSTM(256,return_sequences=True)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "\n",
    "#State input --> 2\n",
    "state = Input(shape=(1,), name=\"state\")\n",
    "x2 = Embedding(input_dim=52,output_dim=26)(state)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "#Teacher prefix input --> 3\n",
    "prefix = Input(shape=(1,), name=\"prefix\")\n",
    "x3 = Embedding(input_dim=6,output_dim=3)(prefix)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "#Grade category input --> 4\n",
    "grade = Input(shape=(1,), name=\"grade\")\n",
    "x4 = Embedding(input_dim=5,output_dim=2)(grade)\n",
    "x4 = Flatten()(x4)\n",
    "\n",
    "#Subject category input --> 5\n",
    "subj_cat = Input(shape=(5,), name=\"subject_category\")\n",
    "x5 = Embedding(input_dim=51,output_dim=25)(subj_cat)\n",
    "x5 = Flatten()(x5)\n",
    "\n",
    "#Subject subcategory input --> 6\n",
    "subj_subcat = Input(shape=(5,), name=\"subject_sub_category\")\n",
    "x6 = Embedding(input_dim=376,output_dim=50)(subj_subcat)\n",
    "x6 = Flatten()(x6)\n",
    "\n",
    "\n",
    "#Numerical input -->7\n",
    "num = Input(shape=(1,), name=\"numerical\")\n",
    "x7 = (Dense(16, activation='relu'))(num)\n",
    "\n",
    "\n",
    "\n",
    "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
    "\n",
    "x = Dense(128,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "output = Dense(2, activation = 'softmax')(x)\n",
    " \n",
    "\n",
    "model = Model([text,state,prefix,grade,subj_cat,subj_subcat,num], output)\n",
    "\n",
    "#https://www.youtube.com/watch?v=2U6Jl7oqRkM\n",
    "#Instantiating tensorboard for model visualization\n",
    "#To visualize, run -  tensorboard --log_dir=logs/{} in command prompt\n",
    "tensorboard = TensorBoard(log_dir=\"logs/\".format(time))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer= tensorflow.keras.optimizers.Adam(lr=0.0006,decay = 1e-4), metrics=[auc])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53531 samples, validate on 22942 samples\n",
      "Epoch 1/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.5248 - auc: 0.5486\n",
      "Epoch 00001: val_auc improved from -inf to 0.39083, saving model to weights_1.hdf5\n",
      "53531/53531 [==============================] - 100s 2ms/sample - loss: 0.5247 - auc: 0.5488 - val_loss: 0.5428 - val_auc: 0.3908\n",
      "Epoch 2/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.4518 - auc: 0.6576  E - ETA: 16s - lo - ETA: 14s - loss: 0.4583 - auc:  - ETA: 13s - loss: 0.4591 - a\n",
      "Epoch 00002: val_auc improved from 0.39083 to 0.70053, saving model to weights_1.hdf5\n",
      "53531/53531 [==============================] - 43s 812us/sample - loss: 0.4518 - auc: 0.6571 - val_loss: 0.4320 - val_auc: 0.7005\n",
      "Epoch 3/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.4320 - auc: 0.6872\n",
      "Epoch 00003: val_auc improved from 0.70053 to 0.71539, saving model to weights_1.hdf5\n",
      "53531/53531 [==============================] - 43s 805us/sample - loss: 0.4320 - auc: 0.6876 - val_loss: 0.4246 - val_auc: 0.7154\n",
      "Epoch 4/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.4185 - auc: 0.7096\n",
      "Epoch 00004: val_auc improved from 0.71539 to 0.72842, saving model to weights_1.hdf5\n",
      "53531/53531 [==============================] - 43s 808us/sample - loss: 0.4185 - auc: 0.7097 - val_loss: 0.4108 - val_auc: 0.7284\n",
      "Epoch 5/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.4114 - auc: 0.7195\n",
      "Epoch 00005: val_auc improved from 0.72842 to 0.73348, saving model to weights_1.hdf5\n",
      "53531/53531 [==============================] - 43s 812us/sample - loss: 0.4113 - auc: 0.7197 - val_loss: 0.4126 - val_auc: 0.7335\n",
      "Epoch 6/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.4039 - auc: 0.7365\n",
      "Epoch 00006: val_auc did not improve from 0.73348\n",
      "53531/53531 [==============================] - 42s 777us/sample - loss: 0.4041 - auc: 0.7368 - val_loss: 0.4042 - val_auc: 0.7329\n",
      "Epoch 7/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.3987 - auc: 0.7430\n",
      "Epoch 00007: val_auc improved from 0.73348 to 0.73648, saving model to weights_1.hdf5\n",
      "53531/53531 [==============================] - 44s 816us/sample - loss: 0.3988 - auc: 0.7428 - val_loss: 0.4051 - val_auc: 0.7365\n",
      "Epoch 8/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.3953 - auc: 0.7540\n",
      "Epoch 00008: val_auc improved from 0.73648 to 0.74610, saving model to weights_1.hdf5\n",
      "53531/53531 [==============================] - 43s 812us/sample - loss: 0.3955 - auc: 0.7537 - val_loss: 0.4068 - val_auc: 0.7461\n",
      "Epoch 9/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.3910 - auc: 0.7621\n",
      "Epoch 00009: val_auc did not improve from 0.74610\n",
      "53531/53531 [==============================] - 42s 778us/sample - loss: 0.3909 - auc: 0.7626 - val_loss: 0.4064 - val_auc: 0.7456\n",
      "Epoch 10/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.3910 - auc: 0.7682\n",
      "Epoch 00010: val_auc did not improve from 0.74610\n",
      "53531/53531 [==============================] - 42s 779us/sample - loss: 0.3910 - auc: 0.7675 - val_loss: 0.4125 - val_auc: 0.7430\n",
      "Epoch 11/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.3909 - auc: 0.7787- ETA: 1s - loss: 0.3909 - auc: \n",
      "Epoch 00011: val_auc did not improve from 0.74610\n",
      "53531/53531 [==============================] - 42s 779us/sample - loss: 0.3909 - auc: 0.7787 - val_loss: 0.4147 - val_auc: 0.7427\n",
      "Epoch 12/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.3894 - auc: 0.7916\n",
      "Epoch 00012: val_auc did not improve from 0.74610\n",
      "53531/53531 [==============================] - 42s 780us/sample - loss: 0.3893 - auc: 0.7916 - val_loss: 0.4308 - val_auc: 0.7410\n",
      "Epoch 13/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.3911 - auc: 0.8066\n",
      "Epoch 00013: val_auc did not improve from 0.74610\n",
      "53531/53531 [==============================] - 42s 780us/sample - loss: 0.3910 - auc: 0.8069 - val_loss: 0.4487 - val_auc: 0.7301\n",
      "Epoch 14/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.3897 - auc: 0.8235\n",
      "Epoch 00014: val_auc did not improve from 0.74610\n",
      "53531/53531 [==============================] - 42s 782us/sample - loss: 0.3896 - auc: 0.8234 - val_loss: 0.4688 - val_auc: 0.7268\n",
      "Epoch 15/15\n",
      "53400/53531 [============================>.] - ETA: 0s - loss: 0.3858 - auc: 0.8479\n",
      "Epoch 00015: val_auc did not improve from 0.74610\n",
      "53531/53531 [==============================] - 42s 785us/sample - loss: 0.3859 - auc: 0.8480 - val_loss: 0.5109 - val_auc: 0.7284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1776f005198>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"weights_1.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "model.fit([text_train,state_train,grade_train,prefix_train,clean_cat_train,clean_subcat_train,num_train], y_train, epochs=15, verbose=1, batch_size=300, validation_data=([text_cv,state_cv,grade_cv,prefix_cv,clean_cat_cv,clean_subcat_cv,num_cv], y_cv), callbacks=[tensorboard,checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compiling model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights_1.hdf5\")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[auc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC 0.7864668722630237\n",
      "--------------------------------------------------\n",
      "CV AUC 0.7450655336380656\n",
      "--------------------------------------------------\n",
      "Test AUC 0.760104170038495\n"
     ]
    }
   ],
   "source": [
    "print(\"Train AUC\",roc_auc_score(y_train,(model.predict([text_train,state_train,grade_train,prefix_train,clean_cat_train,clean_subcat_train,num_train]))))\n",
    "print(\"-\"*50)\n",
    "print(\"CV AUC\",roc_auc_score(y_cv,(model.predict([text_cv,state_cv,grade_cv,prefix_cv,clean_cat_cv,clean_subcat_cv,num_cv]))))\n",
    "print(\"-\"*50)\n",
    "print(\"Test AUC\",roc_auc_score(y_test,(model.predict([text_test,state_test,grade_test,prefix_test,clean_cat_test,clean_subcat_test,num_test]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Load TENSORBOARD\\n%load_ext tensorboard\\n# Start TENSORBOARD\\n%tensorboard --logdir logs --port=8008'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Load TENSORBOARD\n",
    "%load_ext tensorboard\n",
    "# Start TENSORBOARD\n",
    "%tensorboard --logdir logs --port=8008\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"model1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------  Model 2  ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 7) (53531, 2)\n",
      "(22942, 7) (22942, 2)\n",
      "(32775, 7) (32775, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_cv.shape, y_cv.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'IDF score')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "tfidf = TfidfVectorizer()\n",
    "data_text = tfidf.fit_transform(X_train['total_text'])\n",
    "plt.boxplot(tfidf.idf_)\n",
    "plt.ylabel(\"IDF score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 percentile (idf): [9.17998468]\n",
      "50 percentile (idf): [10.7894226]\n",
      "75 percentile (idf): [11.1948877]\n",
      "90 percentile (idf): [11.1948877]\n",
      "95 percentile (idf): [11.1948877]\n",
      "99 percentile (idf): [11.1948877]\n"
     ]
    }
   ],
   "source": [
    "print(\"25 percentile (idf):\", np.percentile(tfidf.idf_,[25]))\n",
    "print(\"50 percentile (idf):\",np.percentile(tfidf.idf_,[50]))\n",
    "print(\"75 percentile (idf):\",np.percentile(tfidf.idf_,[75]))\n",
    "print(\"90 percentile (idf):\",np.percentile(tfidf.idf_,[90]))\n",
    "print(\"95 percentile (idf):\",np.percentile(tfidf.idf_,[95]))\n",
    "print(\"99 percentile (idf):\",np.percentile(tfidf.idf_,[99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_idf = zip(tfidf.get_feature_names(),tfidf.idf_)\n",
    "\n",
    "feature_name = []\n",
    "for x,y in feature_idf:\n",
    "    \n",
    "    if y >=2 and 11.19:\n",
    "        feature_name.append(x)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46385"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering only those features with idf value between 25th and 75th percentile in 'project_essay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_text(df):\n",
    "    processed_text = []\n",
    "    for text in df:\n",
    "        sent = \" \"\n",
    "        words = text.split()\n",
    "        for word in words:\n",
    "            if word in feature_name:\n",
    "                sent = sent +\" \" + word\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        processed_text.append(sent)\n",
    "    return processed_text\n",
    "\n",
    "train_text_reduced = reduced_text(X_train['total_text'])\n",
    "test_text_reduced = reduced_text(X_test['total_text'])\n",
    "cv_text_reduced = reduced_text(X_cv['total_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  privilege working amazing although majority low socioeconomic families bring curiosity eagerness everyday diverse backgrounds bring unique perspective individual education plans unfortunately sedentary structures create obstacles best frequent movement options traditional furniture meet needs stress unable move needed receiving instruction cause disengaged often end receiving disciplinary referrals acting movement needs requesting exercise ball chairs give alternative traditional chairs offered exercise ball pretty popular problem ball stability necessary produce quality project special needs sensory challenges experience without discomfort traditional seating these chairs give opportunity exercise ball way keep focused rolling away listening literature books cds well listening center utilize cds levels esl'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_reduced[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Featurization and padding text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(train_text_reduced)\n",
    "word_index = t.word_index\n",
    "text_train_reduced = t.texts_to_sequences(train_text_reduced)\n",
    "text_test_reduced = t.texts_to_sequences(test_text_reduced)\n",
    "text_cv_reduced = t.texts_to_sequences(cv_text_reduced)\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_review_length = 200\n",
    "text_train_reduced = pad_sequences(text_train_reduced, maxlen=max_review_length) \n",
    "text_test_reduced = pad_sequences(text_test_reduced, maxlen=max_review_length)\n",
    "text_cv_reduced = pad_sequences(text_cv_reduced, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0, 1521,   48,  136,  559,  310,   63,  413,   84,  201,  811,\n",
       "       1711,  189,   83,  122,  201,  261, 2314,  273,   27, 1414,  524,\n",
       "       4220, 1578,   18,  839,   28, 2820,  185,  197,  527, 1205,  180,\n",
       "         23, 1066,  949,   72,  183,  696,  159, 1770, 7098,  126,  416,\n",
       "        696, 6428, 8904, 3588,  185,   23,  335,  462,  471,  103,   43,\n",
       "        449,  527,  103, 1913,  462,  471, 2337, 1599,  204,  471,  624,\n",
       "        323, 1157,  336,   20,   73,   23,  314,   99,   65,  161, 6429,\n",
       "        527,   42,    8,  103,   43,   45,  462,  471,   25,   74,  306,\n",
       "       2389,  589,  282,  363,    1, 2826,   35,  282,  151,  601, 2826,\n",
       "        186, 1159])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train_reduced[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating embedding matrix using pretrain golve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.50835001,  0.17623   , -0.16424   , ...,  0.77085   ,\n",
       "         0.15795   , -0.080663  ],\n",
       "       [-0.26078001, -0.36897999, -0.022831  , ...,  0.23384   ,\n",
       "         0.24267   ,  0.091846  ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.14264999, -0.20883   ,  0.53634   , ...,  0.19422001,\n",
       "         0.062518  ,  0.018873  ]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 200, 300)     13915800    text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 200, 300)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "state (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prefix (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "grade (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subject_category (InputLayer)   [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subject_sub_category (InputLaye [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)          (None, 200, 256)     571392      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 26)        1352        state[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 3)         18          prefix[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 2)         10          grade[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 5, 25)        1275        subject_category[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 5, 50)        18800       subject_sub_category[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "numerical (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 51200)        0           cu_dnnlstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 26)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 3)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 125)          0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 250)          0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           32          numerical[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 51622)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          6607744     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64)           256         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            66          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,127,081\n",
      "Trainable params: 7,211,153\n",
      "Non-trainable params: 13,915,928\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Essay input --> 1\n",
    "text = Input(shape=(200,), name=\"text\")\n",
    "x1 = Embedding(input_dim=46386,output_dim=300,trainable=False,weights=[embedding_matrix])(text)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = CuDNNLSTM(256,return_sequences=True)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "\n",
    "#State input --> 2\n",
    "state = Input(shape=(1,), name=\"state\")\n",
    "x2 = Embedding(input_dim=52,output_dim=26)(state)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "#Teacher prefix input --> 3\n",
    "prefix = Input(shape=(1,), name=\"prefix\")\n",
    "x3 = Embedding(input_dim=6,output_dim=3)(prefix)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "#Grade category input --> 4\n",
    "grade = Input(shape=(1,), name=\"grade\")\n",
    "x4 = Embedding(input_dim=5,output_dim=2)(grade)\n",
    "x4 = Flatten()(x4)\n",
    "\n",
    "#Subject category input --> 5\n",
    "subj_cat = Input(shape=(5,), name=\"subject_category\")\n",
    "x5 = Embedding(input_dim=51,output_dim=25)(subj_cat)\n",
    "x5 = Flatten()(x5)\n",
    "\n",
    "#Subject subcategory input --> 6\n",
    "subj_subcat = Input(shape=(5,), name=\"subject_sub_category\")\n",
    "x6 = Embedding(input_dim=376,output_dim=50)(subj_subcat)\n",
    "x6 = Flatten()(x6)\n",
    "\n",
    "\n",
    "#Numerical input -->7\n",
    "num = Input(shape=(1,), name=\"numerical\")\n",
    "x7 = (Dense(16, activation='relu'))(num)\n",
    "\n",
    "\n",
    "\n",
    "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
    "\n",
    "x = Dense(128,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "output = Dense(2, activation = 'softmax')(x)\n",
    " \n",
    "\n",
    "model = Model([text,state,prefix,grade,subj_cat,subj_subcat,num], output)\n",
    "\n",
    "#https://www.youtube.com/watch?v=2U6Jl7oqRkM\n",
    "#Instantiating tensorboard for model visualization\n",
    "#To visualize, run -  tensorboard --log_dir=logs/{} in command prompt\n",
    "tensorboard = TensorBoard(log_dir=\"logs/\".format(time))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer= tensorflow.keras.optimizers.Adam(lr=0.0006,decay = 1e-4), metrics=[auc])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53531 samples, validate on 22942 samples\n",
      "Epoch 1/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.5560 - auc: 0.5364\n",
      "Epoch 00001: val_auc improved from -inf to 0.62902, saving model to weights_2.hdf5\n",
      "53531/53531 [==============================] - 38s 714us/sample - loss: 0.5561 - auc: 0.5370 - val_loss: 0.4657 - val_auc: 0.6290\n",
      "Epoch 2/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4785 - auc: 0.6116\n",
      "Epoch 00002: val_auc improved from 0.62902 to 0.67708, saving model to weights_2.hdf5\n",
      "53531/53531 [==============================] - 29s 537us/sample - loss: 0.4785 - auc: 0.6124 - val_loss: 0.4454 - val_auc: 0.6771\n",
      "Epoch 3/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4515 - auc: 0.6698\n",
      "Epoch 00003: val_auc improved from 0.67708 to 0.67890, saving model to weights_2.hdf5\n",
      "53531/53531 [==============================] - 29s 536us/sample - loss: 0.4515 - auc: 0.6690 - val_loss: 0.4354 - val_auc: 0.6789\n",
      "Epoch 4/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4398 - auc: 0.6843\n",
      "Epoch 00004: val_auc improved from 0.67890 to 0.68632, saving model to weights_2.hdf5\n",
      "53531/53531 [==============================] - 29s 536us/sample - loss: 0.4397 - auc: 0.6841 - val_loss: 0.4279 - val_auc: 0.6863\n",
      "Epoch 5/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4272 - auc: 0.7012\n",
      "Epoch 00005: val_auc improved from 0.68632 to 0.71009, saving model to weights_2.hdf5\n",
      "53531/53531 [==============================] - 28s 531us/sample - loss: 0.4272 - auc: 0.7012 - val_loss: 0.4209 - val_auc: 0.7101\n",
      "Epoch 6/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4182 - auc: 0.7131\n",
      "Epoch 00006: val_auc improved from 0.71009 to 0.71548, saving model to weights_2.hdf5\n",
      "53531/53531 [==============================] - 29s 542us/sample - loss: 0.4182 - auc: 0.7116 - val_loss: 0.4132 - val_auc: 0.7155\n",
      "Epoch 7/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4125 - auc: 0.7239\n",
      "Epoch 00007: val_auc improved from 0.71548 to 0.72226, saving model to weights_2.hdf5\n",
      "53531/53531 [==============================] - 29s 533us/sample - loss: 0.4124 - auc: 0.7245 - val_loss: 0.4099 - val_auc: 0.7223\n",
      "Epoch 8/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4073 - auc: 0.7287\n",
      "Epoch 00008: val_auc improved from 0.72226 to 0.72404, saving model to weights_2.hdf5\n",
      "53531/53531 [==============================] - 29s 542us/sample - loss: 0.4073 - auc: 0.7291 - val_loss: 0.4099 - val_auc: 0.7240\n",
      "Epoch 9/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4022 - auc: 0.7418\n",
      "Epoch 00009: val_auc improved from 0.72404 to 0.72722, saving model to weights_2.hdf5\n",
      "53531/53531 [==============================] - 29s 541us/sample - loss: 0.4022 - auc: 0.7423 - val_loss: 0.4096 - val_auc: 0.7272\n",
      "Epoch 10/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4002 - auc: 0.7502\n",
      "Epoch 00010: val_auc improved from 0.72722 to 0.73366, saving model to weights_2.hdf5\n",
      "53531/53531 [==============================] - 29s 545us/sample - loss: 0.4001 - auc: 0.7509 - val_loss: 0.4099 - val_auc: 0.7337\n",
      "Epoch 11/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3981 - auc: 0.7566\n",
      "Epoch 00011: val_auc did not improve from 0.73366\n",
      "53531/53531 [==============================] - 28s 518us/sample - loss: 0.3982 - auc: 0.7558 - val_loss: 0.4145 - val_auc: 0.7303\n",
      "Epoch 12/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3973 - auc: 0.7660\n",
      "Epoch 00012: val_auc improved from 0.73366 to 0.73417, saving model to weights_2.hdf5\n",
      "53531/53531 [==============================] - 29s 537us/sample - loss: 0.3974 - auc: 0.7660 - val_loss: 0.4179 - val_auc: 0.7342\n",
      "Epoch 13/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3958 - auc: 0.7780\n",
      "Epoch 00013: val_auc improved from 0.73417 to 0.73569, saving model to weights_2.hdf5\n",
      "53531/53531 [==============================] - 29s 542us/sample - loss: 0.3958 - auc: 0.7785 - val_loss: 0.4233 - val_auc: 0.7357\n",
      "Epoch 14/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3923 - auc: 0.7969\n",
      "Epoch 00014: val_auc did not improve from 0.73569\n",
      "53531/53531 [==============================] - 28s 519us/sample - loss: 0.3923 - auc: 0.7966 - val_loss: 0.4348 - val_auc: 0.7306\n",
      "Epoch 15/15\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3912 - auc: 0.8123\n",
      "Epoch 00015: val_auc did not improve from 0.73569\n",
      "53531/53531 [==============================] - 28s 519us/sample - loss: 0.3913 - auc: 0.8126 - val_loss: 0.4574 - val_auc: 0.7260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17891485a90>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"weights_2.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "model.fit([text_train_reduced,state_train,grade_train,prefix_train,clean_cat_train,clean_subcat_train,num_train], y_train, epochs=15, verbose=1, batch_size=250, validation_data=([text_cv_reduced,state_cv,grade_cv,prefix_cv,clean_cat_cv,clean_subcat_cv,num_cv], y_cv), callbacks=[tensorboard,checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compiling model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights_2.hdf5\")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[auc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC 0.8240843559440708\n",
      "--------------------------------------------------\n",
      "CV AUC 0.7360593751179179\n",
      "--------------------------------------------------\n",
      "Test AUC 0.7463178622047653\n"
     ]
    }
   ],
   "source": [
    "print(\"Train AUC\",roc_auc_score(y_train,(model.predict([text_train_reduced,state_train,grade_train,prefix_train,clean_cat_train,clean_subcat_train,num_train]))))\n",
    "print(\"-\"*50)\n",
    "print(\"CV AUC\",roc_auc_score(y_cv,(model.predict([text_cv_reduced,state_cv,grade_cv,prefix_cv,clean_cat_cv,clean_subcat_cv,num_cv]))))\n",
    "print(\"-\"*50)\n",
    "print(\"Test AUC\",roc_auc_score(y_test,(model.predict([text_test_reduced,state_test,grade_test,prefix_test,clean_cat_test,clean_subcat_test,num_test]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Load TENSORBOARD\\n%load_ext tensorboard\\n# Start TENSORBOARD\\n%tensorboard --logdir logs --port=8008'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Load TENSORBOARD\n",
    "%load_ext tensorboard\n",
    "# Start TENSORBOARD\n",
    "%tensorboard --logdir logs --port=8008\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"model2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------  Model 3  ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/fkQ8nGo.png'>\n",
    "ref: https://i.imgur.com/fkQ8nGo.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 51)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(lowercase= False)\n",
    "token = CountVectorizer()\n",
    "\n",
    "school_state_train = (token.fit_transform(X_train['school_state'])).toarray()\n",
    "school_state_test = (token.transform(X_test['school_state'])).toarray()\n",
    "school_state_cv = (token.transform(X_cv['school_state'])).toarray()\n",
    "\n",
    "print(school_state_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 5)\n"
     ]
    }
   ],
   "source": [
    "prefix_train = token.fit_transform(X_train['teacher_prefix']).toarray()\n",
    "prefix_cv = token.transform(X_cv['teacher_prefix']).toarray()\n",
    "prefix_test = token.transform(X_test['teacher_prefix']).toarray()\n",
    "print(prefix_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 4)\n"
     ]
    }
   ],
   "source": [
    "grade_train = token.fit_transform(X_train['project_grade_category']).toarray()\n",
    "grade_cv = token.transform(X_cv['project_grade_category']).toarray()\n",
    "grade_test = token.transform(X_test['project_grade_category']).toarray()\n",
    "print(grade_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 9)\n"
     ]
    }
   ],
   "source": [
    "cat_train = token.fit_transform(X_train['clean_categories']).toarray()\n",
    "cat_cv = token.transform(X_cv['clean_categories']).toarray()\n",
    "cat_test = token.transform(X_test['clean_categories']).toarray()\n",
    "print(cat_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 30)\n"
     ]
    }
   ],
   "source": [
    "subcat_train = token.fit_transform(X_train['clean_subcategories']).toarray()\n",
    "subcat_cv = token.transform(X_cv['clean_subcategories']).toarray()\n",
    "subcat_test = token.transform(X_test['clean_subcategories']).toarray()\n",
    "print(subcat_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 1)\n",
      "(22942, 1)\n",
      "(32775, 1)\n"
     ]
    }
   ],
   "source": [
    "train_num = X_train['num'].values.reshape(-1,1)\n",
    "cv_num = X_cv['num'].values.reshape(-1,1)\n",
    "test_num = X_test['num'].values.reshape(-1,1)\n",
    "print(train_num.shape)\n",
    "print(cv_num.shape)\n",
    "print(test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 100)\n",
      "(22942, 100)\n",
      "(32775, 100)\n"
     ]
    }
   ],
   "source": [
    "cat_num_train_feat = np.hstack((school_state_train,prefix_train,grade_train,cat_train,subcat_train,train_num))\n",
    "cat_num_cv_feat = np.hstack((school_state_cv,prefix_cv,grade_cv,cat_cv,subcat_cv,cv_num))\n",
    "cat_num_test_feat = np.hstack((school_state_test,prefix_test,grade_test,cat_test,subcat_test,test_num))\n",
    "print(cat_num_train_feat.shape)\n",
    "print(cat_num_cv_feat.shape)\n",
    "print(cat_num_test_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_num_train_feat = np.resize(cat_num_train_feat, new_shape=(53531,100,1))\n",
    "cat_num_cv_feat = np.resize(cat_num_cv_feat, new_shape=(22942,100,1))\n",
    "cat_num_test_feat = np.resize(cat_num_test_feat, new_shape=(32775,100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vansh\\Anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\vansh\\Anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-34-9c0679feb436>:8: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "essay_input (InputLayer)        [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "other_input (InputLayer)        [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 300, 300)     13936200    essay_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 98, 64)       256         other_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 300, 300)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 98, 64)       256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)          (None, 300, 256)     571392      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 96, 64)       12352       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 76800)        0           cu_dnnlstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6144)         0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 82944)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           5308480     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64)           256         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 126)          8190        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            254         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 19,841,796\n",
      "Trainable params: 5,905,340\n",
      "Non-trainable params: 13,936,456\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# input 1\n",
    "essay = Input(batch_shape=(None,300), name=\"essay_input\")\n",
    "x1 = Embedding(input_dim=46454,output_dim = 300,weights=[embedding_matrix],trainable = False)(essay)\n",
    "x1 = SpatialDropout1D(0.4)(x1)\n",
    "x1 = CuDNNLSTM(256,return_sequences=True)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "# input 2\n",
    "other = Input(shape=(100,1),name=\"other_input\")\n",
    "x2 = Conv1D(filters=64,kernel_size=3,strides=1)(other)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = Conv1D(filters=64,kernel_size=3,strides=1)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "\n",
    "concat = concatenate([x1,x2])\n",
    "\n",
    "\n",
    "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(126,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "output = Dense(2, activation = 'softmax')(x)\n",
    " \n",
    "model = Model([essay,other], output)\n",
    "\n",
    "#To visualize, run -  tensorboard --log_dir=logs/ in command prompt\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/\".format(time))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer= tensorflow.keras.optimizers.Adam(lr=0.0006,decay = 1e-4), metrics=[auc])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53531 samples, validate on 22942 samples\n",
      "Epoch 1/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.5175 - auc: 0.5172\n",
      "Epoch 00001: val_auc improved from -inf to 0.55825, saving model to weights_3.hdf5\n",
      "53531/53531 [==============================] - 140s 3ms/sample - loss: 0.5176 - auc: 0.5165 - val_loss: 0.4840 - val_auc: 0.5583\n",
      "Epoch 2/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4858 - auc: 0.5234\n",
      "Epoch 00002: val_auc did not improve from 0.55825\n",
      "53531/53531 [==============================] - 40s 747us/sample - loss: 0.4857 - auc: 0.5225 - val_loss: 0.4858 - val_auc: 0.5080\n",
      "Epoch 3/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4657 - auc: 0.5816\n",
      "Epoch 00003: val_auc improved from 0.55825 to 0.63197, saving model to weights_3.hdf5\n",
      "53531/53531 [==============================] - 41s 768us/sample - loss: 0.4656 - auc: 0.5826 - val_loss: 0.5069 - val_auc: 0.6320\n",
      "Epoch 4/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4401 - auc: 0.6689\n",
      "Epoch 00004: val_auc improved from 0.63197 to 0.70634, saving model to weights_3.hdf5\n",
      "53531/53531 [==============================] - 41s 770us/sample - loss: 0.4401 - auc: 0.6674 - val_loss: 0.4867 - val_auc: 0.7063\n",
      "Epoch 5/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4280 - auc: 0.6933\n",
      "Epoch 00005: val_auc improved from 0.70634 to 0.71743, saving model to weights_3.hdf5\n",
      "53531/53531 [==============================] - 41s 773us/sample - loss: 0.4279 - auc: 0.6944 - val_loss: 0.4360 - val_auc: 0.7174\n",
      "Epoch 6/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4161 - auc: 0.7136\n",
      "Epoch 00006: val_auc improved from 0.71743 to 0.72785, saving model to weights_3.hdf5\n",
      "53531/53531 [==============================] - 42s 776us/sample - loss: 0.4164 - auc: 0.7142 - val_loss: 0.4666 - val_auc: 0.7278\n",
      "Epoch 7/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4078 - auc: 0.7276\n",
      "Epoch 00007: val_auc improved from 0.72785 to 0.73120, saving model to weights_3.hdf5\n",
      "53531/53531 [==============================] - 41s 772us/sample - loss: 0.4078 - auc: 0.7279 - val_loss: 0.4419 - val_auc: 0.7312\n",
      "Epoch 8/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4019 - auc: 0.7375\n",
      "Epoch 00008: val_auc improved from 0.73120 to 0.73642, saving model to weights_3.hdf5\n",
      "53531/53531 [==============================] - 41s 775us/sample - loss: 0.4020 - auc: 0.7367 - val_loss: 0.4664 - val_auc: 0.7364\n",
      "Epoch 9/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.4002 - auc: 0.7410\n",
      "Epoch 00009: val_auc improved from 0.73642 to 0.74336, saving model to weights_3.hdf5\n",
      "53531/53531 [==============================] - 41s 774us/sample - loss: 0.4001 - auc: 0.7412 - val_loss: 0.4515 - val_auc: 0.7434\n",
      "Epoch 10/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3930 - auc: 0.7519\n",
      "Epoch 00010: val_auc improved from 0.74336 to 0.74618, saving model to weights_3.hdf5\n",
      "53531/53531 [==============================] - 42s 776us/sample - loss: 0.3931 - auc: 0.7512 - val_loss: 0.4804 - val_auc: 0.7462\n",
      "Epoch 11/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3907 - auc: 0.7598\n",
      "Epoch 00011: val_auc improved from 0.74618 to 0.74923, saving model to weights_3.hdf5\n",
      "53531/53531 [==============================] - 41s 773us/sample - loss: 0.3907 - auc: 0.7598 - val_loss: 0.4468 - val_auc: 0.7492\n",
      "Epoch 12/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3862 - auc: 0.7673\n",
      "Epoch 00012: val_auc did not improve from 0.74923\n",
      "53531/53531 [==============================] - 41s 757us/sample - loss: 0.3861 - auc: 0.7676 - val_loss: 0.4147 - val_auc: 0.7450\n",
      "Epoch 13/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3849 - auc: 0.7709\n",
      "Epoch 00013: val_auc did not improve from 0.74923\n",
      "53531/53531 [==============================] - 41s 758us/sample - loss: 0.3848 - auc: 0.7716 - val_loss: 0.4395 - val_auc: 0.7476\n",
      "Epoch 14/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3795 - auc: 0.7804\n",
      "Epoch 00014: val_auc improved from 0.74923 to 0.75180, saving model to weights_3.hdf5\n",
      "53531/53531 [==============================] - 42s 782us/sample - loss: 0.3795 - auc: 0.7807 - val_loss: 0.4459 - val_auc: 0.7518\n",
      "Epoch 15/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3773 - auc: 0.7878\n",
      "Epoch 00015: val_auc did not improve from 0.75180\n",
      "53531/53531 [==============================] - 41s 758us/sample - loss: 0.3773 - auc: 0.7881 - val_loss: 0.4310 - val_auc: 0.7488\n",
      "Epoch 16/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3732 - auc: 0.8001\n",
      "Epoch 00016: val_auc did not improve from 0.75180\n",
      "53531/53531 [==============================] - 41s 759us/sample - loss: 0.3733 - auc: 0.7997 - val_loss: 0.4249 - val_auc: 0.7451\n",
      "Epoch 17/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3677 - auc: 0.8131\n",
      "Epoch 00017: val_auc did not improve from 0.75180\n",
      "53531/53531 [==============================] - 41s 759us/sample - loss: 0.3678 - auc: 0.8133 - val_loss: 0.4567 - val_auc: 0.7444\n",
      "Epoch 18/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3598 - auc: 0.8314\n",
      "Epoch 00018: val_auc did not improve from 0.75180\n",
      "53531/53531 [==============================] - 41s 767us/sample - loss: 0.3599 - auc: 0.8309 - val_loss: 0.4331 - val_auc: 0.7336\n",
      "Epoch 19/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3491 - auc: 0.8511\n",
      "Epoch 00019: val_auc did not improve from 0.75180\n",
      "53531/53531 [==============================] - 43s 794us/sample - loss: 0.3491 - auc: 0.8506 - val_loss: 0.4598 - val_auc: 0.7353\n",
      "Epoch 20/20\n",
      "53500/53531 [============================>.] - ETA: 0s - loss: 0.3404 - auc: 0.8703\n",
      "Epoch 00020: val_auc did not improve from 0.75180\n",
      "53531/53531 [==============================] - 42s 783us/sample - loss: 0.3404 - auc: 0.8706 - val_loss: 0.5032 - val_auc: 0.7253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24c0ca27b70>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"weights_3.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "model.fit([text_train,cat_num_train_feat], y_train, epochs=20, verbose=1, batch_size=250, validation_data=([text_cv,cat_num_cv_feat], y_cv), callbacks=[tensorboard,checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compiling model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.load_weights(\"weights_3.hdf5\")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[auc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC 0.8204224648514182\n",
      "--------------------------------------------------\n",
      "Cv AUC 0.751834165899868\n",
      "--------------------------------------------------\n",
      "Test AUC 0.7627339352050855\n"
     ]
    }
   ],
   "source": [
    "print(\"Train AUC\",roc_auc_score(y_train,(model.predict([text_train,cat_num_train_feat]))))\n",
    "print(\"-\"*50)\n",
    "print(\"Cv AUC\",roc_auc_score(y_cv,model.predict([text_cv,cat_num_cv_feat])))\n",
    "print(\"-\"*50)\n",
    "print(\"Test AUC\",roc_auc_score(y_test,model.predict([text_test,cat_num_test_feat])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"model_3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+--------+----------+\n",
      "|  Model  | Train AUC | Cv AUC | Test AUC |\n",
      "+---------+-----------+--------+----------+\n",
      "| Model 1 |    0.78   |  0.74  |   0.76   |\n",
      "| Model 2 |    0.82   |  0.74  |   0.75   |\n",
      "| Model 3 |    0.82   |  0.75  |   0.76   |\n",
      "+---------+-----------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "    \n",
    "x = PrettyTable([\"Model\", \"Train AUC\", \"Cv AUC\", \"Test AUC\"])\n",
    "\n",
    "x.add_row([\"Model 1\", 0.78,0.74,0.76])\n",
    "x.add_row([\"Model 2\", 0.82,0.74,0.75])\n",
    "x.add_row([\"Model 3\", 0.82,0.75,0.76])\n",
    "\n",
    "print(x.get_string(title=\"Model results\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
