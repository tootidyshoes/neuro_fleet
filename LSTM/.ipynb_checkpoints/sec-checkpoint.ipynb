{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credits: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "#https://www.liip.ch/en/blog/sentiment-detection-with-keras-word-embeddings-and-lstm-deep-learning-networks\n",
    "\n",
    "# LSTM for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.preprocessing import text,sequence\n",
    "from tensorflow.keras.layers import Activation, Add, Bidirectional, Conv1D, Dense, Dropout, Embedding, Flatten, Reshape\n",
    "from tensorflow.keras.layers import concatenate, GRU, Input, LSTM, MaxPooling1D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D,  GlobalMaxPooling1D, SpatialDropout1D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.python.keras import backend as k\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = pd.read_csv(\"preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>725.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>213.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>having class 24 students comes diverse learner...</td>\n",
       "      <td>329.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ga</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>appliedlearning</td>\n",
       "      <td>earlydevelopment</td>\n",
       "      <td>i recently read article giving students choice...</td>\n",
       "      <td>481.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wa</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>my students crave challenge eat obstacles brea...</td>\n",
       "      <td>17.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state teacher_prefix project_grade_category  \\\n",
       "0           ca            mrs          grades_prek_2   \n",
       "1           ut             ms             grades_3_5   \n",
       "2           ca            mrs          grades_prek_2   \n",
       "3           ga            mrs          grades_prek_2   \n",
       "4           wa            mrs             grades_3_5   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            53                    1   \n",
       "1                                             4                    1   \n",
       "2                                            10                    1   \n",
       "3                                             2                    1   \n",
       "4                                             2                    1   \n",
       "\n",
       "    clean_categories                 clean_subcategories  \\\n",
       "0       math_science  appliedsciences health_lifescience   \n",
       "1       specialneeds                        specialneeds   \n",
       "2  literacy_language                            literacy   \n",
       "3    appliedlearning                    earlydevelopment   \n",
       "4  literacy_language                            literacy   \n",
       "\n",
       "                                               essay   price  \n",
       "0  i fortunate enough use fairy tale stem kits cl...  725.05  \n",
       "1  imagine 8 9 years old you third grade classroo...  213.03  \n",
       "2  having class 24 students comes diverse learner...  329.00  \n",
       "3  i recently read article giving students choice...  481.04  \n",
       "4  my students crave challenge eat obstacles brea...   17.74  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes : ['school_state' 'teacher_prefix' 'project_grade_category'\n",
      " 'teacher_number_of_previously_posted_projects' 'project_is_approved'\n",
      " 'clean_categories' 'clean_subcategories' 'essay' 'price']\n"
     ]
    }
   ],
   "source": [
    "#Printing the attributes of project_data\n",
    "print(\"Attributes :\", project_data.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_data = pd.read_csv('resources.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p233245</td>\n",
       "      <td>LC652 - Lakeshore Double-Space Mobile Drying Rack</td>\n",
       "      <td>1</td>\n",
       "      <td>149.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Bouncy Bands for Desks (Blue support pipes)</td>\n",
       "      <td>3</td>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Cory Stories: A Kid's Book About Living With Adhd</td>\n",
       "      <td>1</td>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  quantity  \\\n",
       "0  p233245  LC652 - Lakeshore Double-Space Mobile Drying Rack         1   \n",
       "1  p069063        Bouncy Bands for Desks (Blue support pipes)         3   \n",
       "2  p069063  Cory Stories: A Kid's Book About Living With Adhd         1   \n",
       "\n",
       "    price  \n",
       "0  149.00  \n",
       "1   14.95  \n",
       "2    8.45  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p000001</td>\n",
       "      <td>459.56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p000002</td>\n",
       "      <td>515.89</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   price  quantity\n",
       "0  p000001  459.56         7\n",
       "1  p000002  515.89        21"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reference : https://stackoverflow.com/questions/22407798/how-to-reset-a-dataframes-indexes-for-all-groups-in-one-step\n",
    "price_data = resource_data.groupby('id').agg({'price':'sum', 'quantity':'sum'}).reset_index()\n",
    "price_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join two dataframes(project_data and price_data) in python\n",
    "# reference : https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
    "project_data['price'] = resource_data['price']\n",
    "project_data['quantity'] = resource_data['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>149.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>14.95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state teacher_prefix project_grade_category  \\\n",
       "0           ca            mrs          grades_prek_2   \n",
       "1           ut             ms             grades_3_5   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            53                    1   \n",
       "1                                             4                    1   \n",
       "\n",
       "  clean_categories                 clean_subcategories  \\\n",
       "0     math_science  appliedsciences health_lifescience   \n",
       "1     specialneeds                        specialneeds   \n",
       "\n",
       "                                               essay   price  quantity  \n",
       "0  i fortunate enough use fairy tale stem kits cl...  149.00         1  \n",
       "1  imagine 8 9 years old you third grade classroo...   14.95         3  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical inputs\n",
    "project_data['num'] = project_data['teacher_number_of_previously_posted_projects'] + project_data['price'] + project_data['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>149.00</td>\n",
       "      <td>1</td>\n",
       "      <td>203.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>14.95</td>\n",
       "      <td>3</td>\n",
       "      <td>21.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>having class 24 students comes diverse learner...</td>\n",
       "      <td>8.45</td>\n",
       "      <td>1</td>\n",
       "      <td>19.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ga</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>appliedlearning</td>\n",
       "      <td>earlydevelopment</td>\n",
       "      <td>i recently read article giving students choice...</td>\n",
       "      <td>13.59</td>\n",
       "      <td>2</td>\n",
       "      <td>17.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wa</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>my students crave challenge eat obstacles brea...</td>\n",
       "      <td>24.95</td>\n",
       "      <td>3</td>\n",
       "      <td>29.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state teacher_prefix project_grade_category  \\\n",
       "0           ca            mrs          grades_prek_2   \n",
       "1           ut             ms             grades_3_5   \n",
       "2           ca            mrs          grades_prek_2   \n",
       "3           ga            mrs          grades_prek_2   \n",
       "4           wa            mrs             grades_3_5   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            53                    1   \n",
       "1                                             4                    1   \n",
       "2                                            10                    1   \n",
       "3                                             2                    1   \n",
       "4                                             2                    1   \n",
       "\n",
       "    clean_categories                 clean_subcategories  \\\n",
       "0       math_science  appliedsciences health_lifescience   \n",
       "1       specialneeds                        specialneeds   \n",
       "2  literacy_language                            literacy   \n",
       "3    appliedlearning                    earlydevelopment   \n",
       "4  literacy_language                            literacy   \n",
       "\n",
       "                                               essay   price  quantity     num  \n",
       "0  i fortunate enough use fairy tale stem kits cl...  149.00         1  203.00  \n",
       "1  imagine 8 9 years old you third grade classroo...   14.95         3   21.95  \n",
       "2  having class 24 students comes diverse learner...    8.45         1   19.45  \n",
       "3  i recently read article giving students choice...   13.59         2   17.59  \n",
       "4  my students crave challenge eat obstacles brea...   24.95         3   29.95  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['teacher_number_of_previously_posted_projects', 'price', 'quantity']\n",
    "\n",
    "project_data.drop(labels=col,axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>203.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>21.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>having class 24 students comes diverse learner...</td>\n",
       "      <td>19.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ga</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>1</td>\n",
       "      <td>appliedlearning</td>\n",
       "      <td>earlydevelopment</td>\n",
       "      <td>i recently read article giving students choice...</td>\n",
       "      <td>17.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wa</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>my students crave challenge eat obstacles brea...</td>\n",
       "      <td>29.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state teacher_prefix project_grade_category  project_is_approved  \\\n",
       "0           ca            mrs          grades_prek_2                    1   \n",
       "1           ut             ms             grades_3_5                    1   \n",
       "2           ca            mrs          grades_prek_2                    1   \n",
       "3           ga            mrs          grades_prek_2                    1   \n",
       "4           wa            mrs             grades_3_5                    1   \n",
       "\n",
       "    clean_categories                 clean_subcategories  \\\n",
       "0       math_science  appliedsciences health_lifescience   \n",
       "1       specialneeds                        specialneeds   \n",
       "2  literacy_language                            literacy   \n",
       "3    appliedlearning                    earlydevelopment   \n",
       "4  literacy_language                            literacy   \n",
       "\n",
       "                                               essay     num  \n",
       "0  i fortunate enough use fairy tale stem kits cl...  203.00  \n",
       "1  imagine 8 9 years old you third grade classroo...   21.95  \n",
       "2  having class 24 students comes diverse learner...   19.45  \n",
       "3  i recently read article giving students choice...   17.59  \n",
       "4  my students crave challenge eat obstacles brea...   29.95  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109248, 7)\n",
      "(109248,)\n"
     ]
    }
   ],
   "source": [
    "y = project_data['project_is_approved'].values\n",
    "project_data.drop(['project_is_approved'], axis=1, inplace=True)\n",
    "X = project_data\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y , stratify = y, train_size = 0.7)\n",
    "X_train,X_cv,y_train,y_cv = train_test_split(X_train,y_train,stratify = y_train,train_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 7) (53531,)\n",
      "(22942, 7) (22942,)\n",
      "(32775, 7) (32775,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_cv.shape, y_cv.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting class labels to categorical variables\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_cv = to_categorical(y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('train.csv')\n",
    "X_cv.to_csv('cv.csv')\n",
    "X_test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating embedding matrix using pretrain golve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dict = {}\n",
    "glove = open('glove.42B.300d.txt', encoding=\"utf8\")     \n",
    "for line in glove:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:], dtype='float32')\n",
    "    emb_dict[word] = vector\n",
    "glove.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "def embedding_matrix(word_index, embedding_dim):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = emb_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and padding text data (essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bag_of_words = CountVectorizer(lowercase= False)\n",
    "features = []\n",
    "bow_words = bag_of_words.fit_transform(X_train['essay'])\n",
    "freqs = bow_words.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = bag_of_words.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "features.append(word_rank)\n",
    "rank = [] \n",
    "for sent in X_train['essay'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_train['essay'] = rank\n",
    "\n",
    "rank = []\n",
    "for sent in X_test['essay'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_test['essay'] = rank\n",
    "\n",
    "rank = [] # list of all the review with words replaced with rank\n",
    "for sent in X_cv['essay'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_cv['essay'] = rank\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_review_length = 250\n",
    "essay_train = pad_sequences(X_train['essay'], maxlen=max_review_length) \n",
    "essay_test = pad_sequences(X_test['essay'], maxlen=max_review_length)\n",
    "essay_cv = pad_sequences(X_cv['essay'], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0, 1447,   78,  155,    1,  542,\n",
       "        317,    1,   88,  403,  109,  242,  804, 1623,    9,  206,    3,\n",
       "          1,  106,  139,  242,  279, 2252,    4,   15,    1,  315,   59,\n",
       "       1392,  515, 4063,    5, 1587,   57,  798,    1,    9,   54, 2696,\n",
       "        231,  289,  528,    5, 1366,    8,  204,   56,    1,    6, 1090,\n",
       "        925,  112,  221,  670,  195, 1736, 6778,    4,  142,    1,  421,\n",
       "        670, 6093, 8465, 3505,  231,   56,  343,  551,  611,  176,   70,\n",
       "          1,  583,  528,  176, 1848,    2,   36,  551,  611,    5, 2340,\n",
       "       1628,    6,  236,  611,    8,  777,  339,    1, 1176,  398,   15,\n",
       "         28,   51,   10,    1,  102,   56,  422,  124,   97,    4,  183,\n",
       "       6144,  528,  113,   37,  176,   70,    1,   74,   17,  551,  611,\n",
       "         58,  119,  368,    4,    8, 2703,  614,   12])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. School_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_words = bag_of_words.fit_transform(X_train['school_state'])\n",
    "freqs = bow_words.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = bag_of_words.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "rank = [] \n",
    "for sent in X_train['school_state'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_train['school_state'] = rank\n",
    "\n",
    "rank = []\n",
    "for sent in X_test['school_state'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_test['school_state'] = rank\n",
    "\n",
    "rank = [] # list of all the review with words replaced with rank\n",
    "for sent in X_cv['school_state'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_cv['school_state'] = rank\n",
    "\n",
    "max_review_length = 1\n",
    "state_train = pad_sequences(X_train['school_state'], maxlen=max_review_length) \n",
    "state_test = pad_sequences(X_test['school_state'], maxlen=max_review_length)\n",
    "state_cv = pad_sequences(X_cv['school_state'], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Teacher_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_words = bag_of_words.fit_transform(X_train['teacher_prefix'])\n",
    "freqs = bow_words.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = bag_of_words.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "\n",
    "rank = [] \n",
    "for sent in X_train['teacher_prefix'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_train['teacher_prefix'] = rank\n",
    "\n",
    "rank = []\n",
    "for sent in X_test['teacher_prefix'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_test['teacher_prefix'] = rank\n",
    "\n",
    "rank = [] # list of all the review with words replaced with rank\n",
    "for sent in X_cv['teacher_prefix'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_cv['teacher_prefix'] = rank\n",
    "\n",
    "max_review_length = 1\n",
    "prefix_train = pad_sequences(X_train['teacher_prefix'], maxlen=max_review_length) \n",
    "prefix_test = pad_sequences(X_test['teacher_prefix'], maxlen=max_review_length)\n",
    "prefix_cv = pad_sequences(X_cv['teacher_prefix'], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Project_grade_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_words = bag_of_words.fit_transform(X_train['project_grade_category'])\n",
    "freqs = bow_words.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = bag_of_words.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "rank = [] \n",
    "for sent in X_train['project_grade_category'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_train['project_grade_category'] = rank\n",
    "\n",
    "rank = []\n",
    "for sent in X_test['project_grade_category'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_test['project_grade_category'] = rank\n",
    "\n",
    "rank = [] # list of all the review with words replaced with rank\n",
    "for sent in X_cv['project_grade_category'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_cv['project_grade_category'] = rank\n",
    "\n",
    "max_review_length = 1\n",
    "grade_train = pad_sequences(X_train['project_grade_category'], maxlen=max_review_length) \n",
    "grade_test = pad_sequences(X_test['project_grade_category'], maxlen=max_review_length)\n",
    "grade_cv = pad_sequences(X_cv['project_grade_category'], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Clean_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_words = bag_of_words.fit_transform(X_train['clean_categories'])\n",
    "freqs = bow_words.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = bag_of_words.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "\n",
    "rank = [] \n",
    "for sent in X_train['clean_categories'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_train['clean_categories'] = rank\n",
    "\n",
    "rank = []\n",
    "for sent in X_test['clean_categories'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_test['clean_categories'] = rank\n",
    "\n",
    "rank = [] # list of all the review with words replaced with rank\n",
    "for sent in X_cv['clean_categories'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_cv['clean_categories'] = rank\n",
    "\n",
    "max_review_length = 1\n",
    "clean_cat_train = pad_sequences(X_train['clean_categories'], maxlen=max_review_length) \n",
    "clean_cat_test = pad_sequences(X_test['clean_categories'], maxlen=max_review_length)\n",
    "clean_cat_cv = pad_sequences(X_cv['clean_categories'], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Clean_subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_words = bag_of_words.fit_transform(X_train['clean_subcategories'])\n",
    "freqs = bow_words.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = bag_of_words.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "\n",
    "rank = [] \n",
    "for sent in X_train['clean_subcategories'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_train['clean_subcategories'] = rank\n",
    "\n",
    "rank = []\n",
    "for sent in X_test['clean_subcategories'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_test['clean_subcategories'] = rank\n",
    "\n",
    "rank = [] # list of all the review with words replaced with rank\n",
    "for sent in X_cv['clean_subcategories'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_cv['clean_subcategories'] = rank\n",
    "\n",
    "max_review_length = 1\n",
    "clean_subcat_train = pad_sequences(X_train['clean_subcategories'], maxlen=max_review_length) \n",
    "clean_subcat_test = pad_sequences(X_test['clean_subcategories'], maxlen=max_review_length)\n",
    "clean_subcat_cv = pad_sequences(X_cv['clean_subcategories'], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
    "#https://developpaper.com/question/how-to-apply-the-custom-operation-of-py_func-in-tensorflow-to-keras/\n",
    "def auc(y_true, y_pred) :\n",
    "    score = tf.py_func( lambda y_true, y_pred : roc_auc_score( y_true, y_pred, average='macro', sample_weight=None).astype('float32'),\n",
    "                        [y_true, y_pred],\n",
    "                        'float32',\n",
    "                        stateful=True,\n",
    "                        name='sklearnAUC')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------  Model 1  ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/w395Yk9.png'>\n",
    "ref: https://i.imgur.com/w395Yk9.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "state (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 2)         104         state[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "essay (InputLayer)              [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 64)        192         embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "prefix (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "grade (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subject_category (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subject_sub_category (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 250, 300)     12759900    essay[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 1, 64)        0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 2)         10          prefix[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 2)         100         grade[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 50)        19250       subject_category[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 5)         30          subject_sub_category[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "numerical (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 250, 64)      19264       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 64)        4160        spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 64)        192         embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 64)        192         embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1, 64)        3264        embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1, 64)        384         embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 32)           64          numerical[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 250, 64)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 1, 64)        0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 1, 64)        0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 1, 64)        0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 1, 64)        0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 1, 64)        0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 64)           2112        dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 250, 64)      4160        spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 64)        4160        spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 64)        4160        spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1, 64)        4160        spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1, 64)        4160        spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1, 64)        4160        spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 250, 64)      0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 1, 64)        0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 1, 64)        0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 1, 64)        0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 1, 64)        0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 1, 64)        0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64)           4160        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 16000)        0           spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 64)           0           spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 64)           0           spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 64)           0           spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 64)           0           spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16384)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 32)           524320      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32)           128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 64)           2112        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64)           256         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 64)           4160        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64)           256         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 64)           4160        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2)            130         dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 13,373,860\n",
      "Trainable params: 613,640\n",
      "Non-trainable params: 12,760,220\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Essay input --> 1\n",
    "essay = Input(shape=(250,), name=\"essay\")\n",
    "x1 = Embedding(input_dim=42533,output_dim=300,trainable=False,weights=[embedding_matrix(features[0],300)])(essay)\n",
    "x1 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "\n",
    "#State input --> 2\n",
    "state = Input(shape=(1,), name=\"state\")\n",
    "x2 = Embedding(input_dim=52,output_dim=2)(state)\n",
    "x2 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x2)\n",
    "x2 = SpatialDropout1D(0.3)(x2)\n",
    "x2 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x2)\n",
    "x2 = SpatialDropout1D(0.3)(x2)\n",
    "x2 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x2)\n",
    "x2 = SpatialDropout1D(0.3)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "#Teacher prefix input --> 3\n",
    "prefix = Input(shape=(1,), name=\"prefix\")\n",
    "x3 = Embedding(input_dim=5,output_dim=2)(prefix)\n",
    "x3 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x3)\n",
    "x3 = SpatialDropout1D(0.3)(x3)\n",
    "x3 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x3)\n",
    "x3 = SpatialDropout1D(0.3)(x3)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "#Grade category input --> 4\n",
    "grade = Input(shape=(1,), name=\"grade\")\n",
    "x4 = Embedding(input_dim=50,output_dim=2)(grade)\n",
    "x4 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x4)\n",
    "x4 = SpatialDropout1D(0.3)(x4)\n",
    "x4 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x4)\n",
    "x4 = SpatialDropout1D(0.3)(x4)\n",
    "x4 = Flatten()(x4)\n",
    "\n",
    "#Subject category input --> 5\n",
    "subj_cat = Input(shape=(1,), name=\"subject_category\")\n",
    "x5 = Embedding(input_dim=385,output_dim=50)(subj_cat)\n",
    "x5 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x5)\n",
    "x5 = SpatialDropout1D(0.3)(x5)\n",
    "x5 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x5)\n",
    "x5 = SpatialDropout1D(0.3)(x5)\n",
    "x5 = Flatten()(x5)\n",
    "\n",
    "#Subject subcategory input --> 6\n",
    "subj_subcat = Input(shape=(1,), name=\"subject_sub_category\")\n",
    "x6 = Embedding(input_dim=6,output_dim=5)(subj_subcat)\n",
    "x6 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x6)\n",
    "x6 = SpatialDropout1D(0.3)(x6)\n",
    "x6 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x6)\n",
    "x6 = SpatialDropout1D(0.3)(x6)\n",
    "x6 = Flatten()(x6)\n",
    "\n",
    "#Numerical input -->7\n",
    "num = Input(shape=(1,), name=\"numerical\")\n",
    "x7 = (Dense(32, activation='relu',kernel_initializer=he_normal()))(num)\n",
    "x7 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x7)\n",
    "x7 = Dropout(0.3)(x7)\n",
    "x7 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x7)\n",
    "x7 = Dropout(0.3)(x7)\n",
    "\n",
    "\n",
    "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
    "\n",
    "x = (Dense(32, activation='relu',kernel_initializer=he_normal()))(concat)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x)\n",
    "output = (Dense(2, activation='softmax'))(x)\n",
    " \n",
    "\n",
    "model = Model([essay,state,prefix,grade,subj_cat,subj_subcat,num], output)\n",
    "\n",
    "#https://www.youtube.com/watch?v=2U6Jl7oqRkM\n",
    "#Instantiating tensorboard for model visualization\n",
    "#To visualize, run -  tensorboard --log_dir=logs/{} in command prompt\n",
    "log_dir=\"logs/visualize/\"\n",
    "tensorboard = TensorBoard(log_dir.format(time()))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[auc])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53531 samples, validate on 22942 samples\n",
      "Epoch 1/20\n",
      "53531/53531 [==============================] - 7s 136us/sample - loss: 0.5144 - auc: 0.5096 - val_loss: 0.4243 - val_auc: 0.5350\n",
      "Epoch 2/20\n",
      "53531/53531 [==============================] - 5s 102us/sample - loss: 0.4461 - auc: 0.5178 - val_loss: 0.4255 - val_auc: 0.5379\n",
      "Epoch 3/20\n",
      "53531/53531 [==============================] - 7s 125us/sample - loss: 0.4385 - auc: 0.5227 - val_loss: 0.4239 - val_auc: 0.5463\n",
      "Epoch 4/20\n",
      "53531/53531 [==============================] - 5s 103us/sample - loss: 0.4330 - auc: 0.5316 - val_loss: 0.4235 - val_auc: 0.5531\n",
      "Epoch 5/20\n",
      "53531/53531 [==============================] - 6s 104us/sample - loss: 0.4313 - auc: 0.5372 - val_loss: 0.4235 - val_auc: 0.5689\n",
      "Epoch 6/20\n",
      "53531/53531 [==============================] - 5s 103us/sample - loss: 0.4293 - auc: 0.5440 - val_loss: 0.4228 - val_auc: 0.5740\n",
      "Epoch 7/20\n",
      "53531/53531 [==============================] - 6s 108us/sample - loss: 0.4262 - auc: 0.5556 - val_loss: 0.4142 - val_auc: 0.6254\n",
      "Epoch 8/20\n",
      "53531/53531 [==============================] - 6s 106us/sample - loss: 0.4180 - auc: 0.6091 - val_loss: 0.3967 - val_auc: 0.6915\n",
      "Epoch 9/20\n",
      "53531/53531 [==============================] - 6s 112us/sample - loss: 0.4044 - auc: 0.6630 - val_loss: 0.3906 - val_auc: 0.7047\n",
      "Epoch 10/20\n",
      "53531/53531 [==============================] - 5s 102us/sample - loss: 0.3972 - auc: 0.6839 - val_loss: 0.3886 - val_auc: 0.7112\n",
      "Epoch 11/20\n",
      "53531/53531 [==============================] - 5s 101us/sample - loss: 0.3922 - auc: 0.6990 - val_loss: 0.3855 - val_auc: 0.7166\n",
      "Epoch 12/20\n",
      "53531/53531 [==============================] - 5s 101us/sample - loss: 0.3880 - auc: 0.7091 - val_loss: 0.3842 - val_auc: 0.7169\n",
      "Epoch 13/20\n",
      "53531/53531 [==============================] - 7s 123us/sample - loss: 0.3841 - auc: 0.7152 - val_loss: 0.3818 - val_auc: 0.7171\n",
      "Epoch 14/20\n",
      "53531/53531 [==============================] - 5s 103us/sample - loss: 0.3819 - auc: 0.7213 - val_loss: 0.3861 - val_auc: 0.7217\n",
      "Epoch 15/20\n",
      "53531/53531 [==============================] - 6s 116us/sample - loss: 0.3790 - auc: 0.7262 - val_loss: 0.3827 - val_auc: 0.7217\n",
      "Epoch 16/20\n",
      "53531/53531 [==============================] - 6s 104us/sample - loss: 0.3767 - auc: 0.7311 - val_loss: 0.3873 - val_auc: 0.7206\n",
      "Epoch 17/20\n",
      "53531/53531 [==============================] - 6s 115us/sample - loss: 0.3747 - auc: 0.7352 - val_loss: 0.3806 - val_auc: 0.7269\n",
      "Epoch 18/20\n",
      "53531/53531 [==============================] - 6s 105us/sample - loss: 0.3719 - auc: 0.7393 - val_loss: 0.3803 - val_auc: 0.7225\n",
      "Epoch 19/20\n",
      "53531/53531 [==============================] - 6s 103us/sample - loss: 0.3677 - auc: 0.7471 - val_loss: 0.3786 - val_auc: 0.7260\n",
      "Epoch 20/20\n",
      "53531/53531 [==============================] - 6s 109us/sample - loss: 0.3657 - auc: 0.7501 - val_loss: 0.3795 - val_auc: 0.7234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x144598045c0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([essay_train,state_train,grade_train,prefix_train,clean_cat_train,clean_subcat_train,X_train['num']], y_train, epochs=20, verbose=1, batch_size=300, validation_data=([essay_cv,state_cv,grade_cv,prefix_cv,clean_cat_cv,clean_subcat_cv,X_cv['num']], y_cv), callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC 0.7809139488148835\n",
      "--------------------------------------------------\n",
      "Cv AUC 0.7231819219387698\n",
      "--------------------------------------------------\n",
      "Test AUC 0.73341316458027\n"
     ]
    }
   ],
   "source": [
    "print(\"Train AUC\",roc_auc_score(y_train,(model.predict([essay_train,state_train,grade_train,prefix_train,clean_cat_train,clean_subcat_train,X_train['num']]))))\n",
    "print(\"-\"*50)\n",
    "print(\"Cv AUC\",roc_auc_score(y_cv,model.predict([essay_cv,state_cv,grade_cv,prefix_cv,clean_cat_cv,clean_subcat_cv,X_cv['num']])))\n",
    "print(\"-\"*50)\n",
    "print(\"Test AUC\",roc_auc_score(y_test,model.predict([essay_test,state_test,grade_test,prefix_test,clean_cat_test,clean_subcat_test,X_test['num']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------  Model 2  ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('train.csv')\n",
    "X_cv = pd.read_csv('cv.csv')\n",
    "X_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42462</td>\n",
       "      <td>or</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>i privilege working amazing students although ...</td>\n",
       "      <td>406.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33162</td>\n",
       "      <td>il</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>appliedlearning</td>\n",
       "      <td>earlydevelopment</td>\n",
       "      <td>my little ones beyond special they diverse ric...</td>\n",
       "      <td>350.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3065</td>\n",
       "      <td>la</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>i would really like students interested readin...</td>\n",
       "      <td>21.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 school_state teacher_prefix project_grade_category  \\\n",
       "0       42462           or             ms             grades_6_8   \n",
       "1       33162           il             ms          grades_prek_2   \n",
       "2        3065           la             ms             grades_3_5   \n",
       "\n",
       "    clean_categories clean_subcategories  \\\n",
       "0       specialneeds        specialneeds   \n",
       "1    appliedlearning    earlydevelopment   \n",
       "2  literacy_language            literacy   \n",
       "\n",
       "                                               essay     num  \n",
       "0  i privilege working amazing students although ...  406.06  \n",
       "1  my little ones beyond special they diverse ric...  350.99  \n",
       "2  i would really like students interested readin...   21.99  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'IDF score')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "tfidf = TfidfVectorizer()\n",
    "data_text = tfidf.fit_transform(X_train['essay'])\n",
    "plt.boxplot(tfidf.idf_)\n",
    "plt.ylabel(\"IDF score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 percentile (idf): [9.17998468]\n",
      "50 percentile (idf): [10.50174052]\n",
      "75 percentile (idf): [11.1948877]\n",
      "90 percentile (idf): [11.1948877]\n"
     ]
    }
   ],
   "source": [
    "print(\"25 percentile (idf):\", np.percentile(tfidf.idf_,[25]))\n",
    "print(\"50 percentile (idf):\",np.percentile(tfidf.idf_,[50]))\n",
    "print(\"75 percentile (idf):\",np.percentile(tfidf.idf_,[75]))\n",
    "print(\"90 percentile (idf):\",np.percentile(tfidf.idf_,[90]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_idf_val = zip(tfidf.get_feature_names(),tfidf.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking only those feature which have idf value between 25th and 75th percentile\n",
    "feat = []\n",
    "for f,val in feat_idf_val:\n",
    "    if val>=9.31350907 and val<=11.32841209:\n",
    "        feat.append(f)\n",
    "    else:\n",
    "        continue   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001', '002', '00am', '00p', '00pm']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering only those features with idf value between 25th and 75th percentile in 'project_essay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_essay = []\n",
    "for text in X_train['essay']:\n",
    "    sent = \" \"\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word in feat:\n",
    "            sent = \" \"+word\n",
    "        else:\n",
    "            continue\n",
    "    train_essay.append(sent)\n",
    "X_train['essay'] = train_essay  \n",
    "\n",
    "#Featurizing cv essay\n",
    "cv_essay = []\n",
    "for text in X_cv['essay']:\n",
    "    sent = \" \"\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word in feat:\n",
    "            sent = \" \"+word\n",
    "        else:\n",
    "            continue\n",
    "    cv_essay.append(sent)\n",
    "X_cv['essay'] = cv_essay  \n",
    "\n",
    "\n",
    "#Featurizing test essay\n",
    "test_essay = []\n",
    "for text in X_test['essay']:\n",
    "    sent = \" \"\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word in feat:\n",
    "            sent = \" \"+word\n",
    "        else:\n",
    "            continue\n",
    "    test_essay.append(sent)\n",
    "X_test['essay'] = test_essay  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bag_of_words = CountVectorizer(lowercase= False)\n",
    "features = []\n",
    "bow_words = bag_of_words.fit_transform(X_train['essay'])\n",
    "freqs = bow_words.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = bag_of_words.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "features.append(word_rank)\n",
    "rank = [] \n",
    "for sent in X_train['essay'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_train['essay'] = rank\n",
    "\n",
    "rank = []\n",
    "for sent in X_test['essay'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_test['essay'] = rank\n",
    "\n",
    "rank = [] # list of all the review with words replaced with rank\n",
    "for sent in X_cv['essay'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_cv['essay'] = rank\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_review_length = 250\n",
    "essay_train_m2 = pad_sequences(X_train['essay'], maxlen=max_review_length) \n",
    "essay_test_m2 = pad_sequences(X_test['essay'], maxlen=max_review_length)\n",
    "essay_cv_m2 = pad_sequences(X_cv['essay'], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.School State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_words = bag_of_words.fit_transform(X_train['school_state'])\n",
    "freqs = bow_words.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = bag_of_words.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "features.append(word_rank)\n",
    "rank = [] \n",
    "for sent in X_train['school_state'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_train['school_state'] = rank\n",
    "\n",
    "rank = []\n",
    "for sent in X_test['school_state'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_test['school_state'] = rank\n",
    "\n",
    "rank = [] # list of all the review with words replaced with rank\n",
    "for sent in X_cv['school_state'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_cv['school_state'] = rank\n",
    "\n",
    "max_review_length = 1\n",
    "state_train = pad_sequences(X_train['school_state'], maxlen=max_review_length) \n",
    "state_test = pad_sequences(X_test['school_state'], maxlen=max_review_length)\n",
    "state_cv = pad_sequences(X_cv['school_state'], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Teacher_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_words = bag_of_words.fit_transform(X_train['teacher_prefix'])\n",
    "freqs = bow_words.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = bag_of_words.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "features.append(word_rank)\n",
    "rank = [] \n",
    "for sent in X_train['teacher_prefix'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_train['teacher_prefix'] = rank\n",
    "\n",
    "rank = []\n",
    "for sent in X_test['teacher_prefix'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_test['teacher_prefix'] = rank\n",
    "\n",
    "rank = [] # list of all the review with words replaced with rank\n",
    "for sent in X_cv['teacher_prefix'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_cv['teacher_prefix'] = rank\n",
    "\n",
    "max_review_length = 1\n",
    "prefix_train = pad_sequences(X_train['teacher_prefix'], maxlen=max_review_length) \n",
    "prefix_test = pad_sequences(X_test['teacher_prefix'], maxlen=max_review_length)\n",
    "prefix_cv = pad_sequences(X_cv['teacher_prefix'], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Project_grade_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_words = bag_of_words.fit_transform(X_train['project_grade_category'])\n",
    "freqs = bow_words.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = bag_of_words.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "features.append(word_rank)\n",
    "rank = [] \n",
    "for sent in X_train['project_grade_category'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_train['project_grade_category'] = rank\n",
    "\n",
    "rank = []\n",
    "for sent in X_test['project_grade_category'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_test['project_grade_category'] = rank\n",
    "\n",
    "rank = [] # list of all the review with words replaced with rank\n",
    "for sent in X_cv['project_grade_category'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_cv['project_grade_category'] = rank\n",
    "\n",
    "max_review_length = 1\n",
    "grade_train = pad_sequences(X_train['project_grade_category'], maxlen=max_review_length) \n",
    "grade_test = pad_sequences(X_test['project_grade_category'], maxlen=max_review_length)\n",
    "grade_cv = pad_sequences(X_cv['project_grade_category'], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Clean_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_words = bag_of_words.fit_transform(X_train['clean_categories'])\n",
    "freqs = bow_words.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = bag_of_words.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "features.append(word_rank)\n",
    "rank = [] \n",
    "for sent in X_train['clean_categories'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_train['clean_categories'] = rank\n",
    "\n",
    "rank = []\n",
    "for sent in X_test['clean_categories'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_test['clean_categories'] = rank\n",
    "\n",
    "rank = [] # list of all the review with words replaced with rank\n",
    "for sent in X_cv['clean_categories'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_cv['clean_categories'] = rank\n",
    "\n",
    "max_review_length = 1\n",
    "clean_cat_train = pad_sequences(X_train['clean_categories'], maxlen=max_review_length) \n",
    "clean_cat_test = pad_sequences(X_test['clean_categories'], maxlen=max_review_length)\n",
    "clean_cat_cv = pad_sequences(X_cv['clean_categories'], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Clean_subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_words = bag_of_words.fit_transform(X_train['clean_subcategories'])\n",
    "freqs = bow_words.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = bag_of_words.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "features.append(word_rank)\n",
    "rank = [] \n",
    "for sent in X_train['clean_subcategories'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_train['clean_subcategories'] = rank\n",
    "\n",
    "rank = []\n",
    "for sent in X_test['clean_subcategories'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_test['clean_subcategories'] = rank\n",
    "\n",
    "rank = [] # list of all the review with words replaced with rank\n",
    "for sent in X_cv['clean_subcategories'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_cv['clean_subcategories'] = rank\n",
    "\n",
    "max_review_length = 1\n",
    "clean_subcat_train = pad_sequences(X_train['clean_subcategories'], maxlen=max_review_length) \n",
    "clean_subcat_test = pad_sequences(X_test['clean_subcategories'], maxlen=max_review_length)\n",
    "clean_subcat_cv = pad_sequences(X_cv['clean_subcategories'], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "state (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prefix (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "grade (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subject_category (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "essay (InputLayer)              [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 2)         104         state[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 2)         10          prefix[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 2)         100         grade[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 50)        19250       subject_category[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "subject_sub_category (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "numerical (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 250, 300)     5252400     essay[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 64)        192         embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 64)        192         embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 64)        192         embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 64)        3264        embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 5)         30          subject_sub_category[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           64          numerical[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 250, 64)      19264       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 1, 64)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 1, 64)        0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 1, 64)        0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 1, 64)        0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 64)        384         embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           2112        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 16000)        0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 64)           0           spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 64)           0           spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 64)           0           spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 64)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16384)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           524320      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32)           128         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           2112        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2)            130         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,824,248\n",
      "Trainable params: 571,784\n",
      "Non-trainable params: 5,252,464\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Essay input --> 1\n",
    "essay = Input(shape=(250,1), name=\"essay\")\n",
    "x1 = Embedding(input_dim=17508,output_dim=300,trainable=False,weights=[embedding_matrix(features[0],300)])(essay)\n",
    "x1 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "\n",
    "#State input --> 2\n",
    "state = Input(shape=(1,), name=\"state\")\n",
    "x2 = Embedding(input_dim=52,output_dim=2)(state)\n",
    "x2 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x2)\n",
    "x2 = SpatialDropout1D(0.3)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "#Teacher prefix input --> 3\n",
    "prefix = Input(shape=(1,), name=\"prefix\")\n",
    "x3 = Embedding(input_dim=5,output_dim=2)(prefix)\n",
    "x3 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x3)\n",
    "x3 = SpatialDropout1D(0.3)(x3)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "#Grade category input --> 4\n",
    "grade = Input(shape=(1,), name=\"grade\")\n",
    "x4 = Embedding(input_dim=50,output_dim=2)(grade)\n",
    "x4 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x4)\n",
    "x4 = SpatialDropout1D(0.3)(x4)\n",
    "\n",
    "x4 = Flatten()(x4)\n",
    "\n",
    "#Subject category input --> 5\n",
    "subj_cat = Input(shape=(1,), name=\"subject_category\")\n",
    "x5 = Embedding(input_dim=385,output_dim=50)(subj_cat)\n",
    "x5 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x5)\n",
    "x5 = SpatialDropout1D(0.3)(x5)\n",
    "x5 = Flatten()(x5)\n",
    "\n",
    "#Subject subcategory input --> 6\n",
    "subj_subcat = Input(shape=(1,), name=\"subject_sub_category\")\n",
    "x6 = Embedding(input_dim=6,output_dim=5)(subj_subcat)\n",
    "x6 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x6)\n",
    "\n",
    "x6 = Flatten()(x6)\n",
    "\n",
    "#Numerical input -->7\n",
    "num = Input(shape=(1,), name=\"numerical\")\n",
    "x7 = (Dense(32, activation='relu',kernel_initializer=he_normal()))(num)\n",
    "x7 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x7)\n",
    "x7 = Dropout(0.3)(x7)\n",
    "\n",
    "\n",
    "\n",
    "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
    "\n",
    "x = (Dense(32, activation='relu',kernel_initializer=he_normal()))(concat)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x)\n",
    "\n",
    "output = (Dense(2, activation='softmax'))(x)\n",
    " \n",
    "\n",
    "model = Model([essay,state,prefix,grade,subj_cat,subj_subcat,num], output)\n",
    "\n",
    "#https://www.youtube.com/watch?v=2U6Jl7oqRkM\n",
    "#Instantiating tensorboard for model visualization\n",
    "#To visualize, run -  tensorboard --log_dir=logs/{} in command prompt\n",
    "log_dir=\"logs/visualize_m2/\"\n",
    "tensorboard = TensorBoard(log_dir.format(time()))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[auc])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53531 samples, validate on 22942 samples\n",
      "Epoch 1/20\n",
      "53531/53531 [==============================] - 4s 72us/sample - loss: 0.4586 - auc: 0.5014 - val_loss: 0.4368 - val_auc: 0.4993\n",
      "Epoch 2/20\n",
      "53531/53531 [==============================] - 3s 60us/sample - loss: 0.4316 - auc: 0.5036 - val_loss: 0.4327 - val_auc: 0.5029\n",
      "Epoch 3/20\n",
      "53531/53531 [==============================] - 3s 60us/sample - loss: 0.4296 - auc: 0.5104 - val_loss: 0.4266 - val_auc: 0.5219\n",
      "Epoch 4/20\n",
      "53531/53531 [==============================] - 3s 60us/sample - loss: 0.4282 - auc: 0.5114 - val_loss: 0.4275 - val_auc: 0.5045\n",
      "Epoch 5/20\n",
      "53531/53531 [==============================] - 3s 60us/sample - loss: 0.4273 - auc: 0.5158 - val_loss: 0.4253 - val_auc: 0.5396\n",
      "Epoch 6/20\n",
      "53531/53531 [==============================] - 3s 60us/sample - loss: 0.4258 - auc: 0.5330 - val_loss: 0.4260 - val_auc: 0.5396\n",
      "Epoch 7/20\n",
      "53531/53531 [==============================] - 3s 60us/sample - loss: 0.4254 - auc: 0.5328 - val_loss: 0.4259 - val_auc: 0.5450\n",
      "Epoch 8/20\n",
      "53531/53531 [==============================] - 3s 60us/sample - loss: 0.4252 - auc: 0.5477 - val_loss: 0.4242 - val_auc: 0.5419\n",
      "Epoch 9/20\n",
      "53531/53531 [==============================] - 3s 61us/sample - loss: 0.4236 - auc: 0.5534 - val_loss: 0.4238 - val_auc: 0.5534\n",
      "Epoch 10/20\n",
      "53531/53531 [==============================] - 3s 59us/sample - loss: 0.4229 - auc: 0.5611 - val_loss: 0.4229 - val_auc: 0.5552\n",
      "Epoch 11/20\n",
      "53531/53531 [==============================] - 3s 61us/sample - loss: 0.4211 - auc: 0.5741 - val_loss: 0.4229 - val_auc: 0.5557\n",
      "Epoch 12/20\n",
      "53531/53531 [==============================] - 3s 59us/sample - loss: 0.4211 - auc: 0.5775 - val_loss: 0.4245 - val_auc: 0.5515\n",
      "Epoch 13/20\n",
      "53531/53531 [==============================] - 3s 59us/sample - loss: 0.4202 - auc: 0.5824 - val_loss: 0.4236 - val_auc: 0.5574\n",
      "Epoch 14/20\n",
      "53531/53531 [==============================] - 3s 59us/sample - loss: 0.4195 - auc: 0.5872 - val_loss: 0.4231 - val_auc: 0.5551\n",
      "Epoch 15/20\n",
      "53531/53531 [==============================] - 3s 59us/sample - loss: 0.4172 - auc: 0.6011 - val_loss: 0.4266 - val_auc: 0.5383\n",
      "Epoch 16/20\n",
      "53531/53531 [==============================] - 3s 59us/sample - loss: 0.4172 - auc: 0.6012 - val_loss: 0.4234 - val_auc: 0.5551\n",
      "Epoch 17/20\n",
      "53531/53531 [==============================] - 3s 59us/sample - loss: 0.4148 - auc: 0.6135 - val_loss: 0.4246 - val_auc: 0.5512\n",
      "Epoch 18/20\n",
      "53531/53531 [==============================] - 3s 59us/sample - loss: 0.4133 - auc: 0.6202 - val_loss: 0.4240 - val_auc: 0.5491\n",
      "Epoch 19/20\n",
      "53531/53531 [==============================] - 3s 59us/sample - loss: 0.4106 - auc: 0.6276 - val_loss: 0.4261 - val_auc: 0.5508\n",
      "Epoch 20/20\n",
      "53531/53531 [==============================] - 3s 59us/sample - loss: 0.4063 - auc: 0.6457 - val_loss: 0.4279 - val_auc: 0.5432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18a72b9c358>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([essay_train_m2,state_train,grade_train,prefix_train,clean_cat_train,clean_subcat_train,X_train['num']], y_train, epochs=20, verbose=1, batch_size=300, validation_data=([essay_cv_m2,state_cv,grade_cv,prefix_cv,clean_cat_cv,clean_subcat_cv,X_cv['num']], y_cv), callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC 0.6774337552953027\n",
      "--------------------------------------------------\n",
      "Cv AUC 0.5439057084835437\n",
      "--------------------------------------------------\n",
      "Test AUC 0.5417117791316319\n"
     ]
    }
   ],
   "source": [
    "print(\"Train AUC\",roc_auc_score(y_train,(model.predict([essay_train_m2,state_train,grade_train,prefix_train,clean_cat_train,clean_subcat_train,X_train['num']]))))\n",
    "print(\"-\"*50)\n",
    "print(\"Cv AUC\",roc_auc_score(y_cv,model.predict([essay_cv_m2,state_cv,grade_cv,prefix_cv,clean_cat_cv,clean_subcat_cv,X_cv['num']])))\n",
    "print(\"-\"*50)\n",
    "print(\"Test AUC\",roc_auc_score(y_test,model.predict([essay_test_m2,state_test,grade_test,prefix_test,clean_cat_test,clean_subcat_test,X_test['num']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------  Model 3  ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('train.csv')\n",
    "X_cv = pd.read_csv('cv.csv')\n",
    "X_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bag_of_words = CountVectorizer(lowercase= False)\n",
    "features = []\n",
    "bow_words = bag_of_words.fit_transform(X_train['essay'])\n",
    "freqs = bow_words.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = bag_of_words.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "features.append(word_rank)\n",
    "rank = [] \n",
    "for sent in X_train['essay'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_train['essay'] = rank\n",
    "\n",
    "rank = []\n",
    "for sent in X_test['essay'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_test['essay'] = rank\n",
    "\n",
    "rank = [] # list of all the review with words replaced with rank\n",
    "for sent in X_cv['essay'].values:\n",
    "    txt_row = []\n",
    "    for word in sent.split():\n",
    "        if word in word_rank.keys():\n",
    "            txt_row.append(word_rank[word])\n",
    "        else:\n",
    "            pass\n",
    "    rank.append(txt_row)\n",
    "X_cv['essay'] = rank\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_review_length = 250\n",
    "essay_train = pad_sequences(X_train['essay'], maxlen=max_review_length) \n",
    "essay_test = pad_sequences(X_test['essay'], maxlen=max_review_length)\n",
    "essay_cv = pad_sequences(X_cv['essay'], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 250)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0, 1447,   78,  155,    1,  542,\n",
       "        317,    1,   88,  403,  109,  242,  804, 1623,    9,  206,    3,\n",
       "          1,  106,  139,  242,  279, 2252,    4,   15,    1,  315,   59,\n",
       "       1392,  515, 4063,    5, 1587,   57,  798,    1,    9,   54, 2696,\n",
       "        231,  289,  528,    5, 1366,    8,  204,   56,    1,    6, 1090,\n",
       "        925,  112,  221,  670,  195, 1736, 6778,    4,  142,    1,  421,\n",
       "        670, 6093, 8465, 3505,  231,   56,  343,  551,  611,  176,   70,\n",
       "          1,  583,  528,  176, 1848,    2,   36,  551,  611,    5, 2340,\n",
       "       1628,    6,  236,  611,    8,  777,  339,    1, 1176,  398,   15,\n",
       "         28,   51,   10,    1,  102,   56,  422,  124,   97,    4,  183,\n",
       "       6144,  528,  113,   37,  176,   70,    1,   74,   17,  551,  611,\n",
       "         58,  119,  368,    4,    8, 2703,  614,   12])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(essay_train.shape)\n",
    "essay_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 51)\n"
     ]
    }
   ],
   "source": [
    "token = CountVectorizer()\n",
    "\n",
    "school_state_train = (token.fit_transform(X_train['school_state'])).toarray()\n",
    "school_state_test = (token.transform(X_test['school_state'])).toarray()\n",
    "school_state_cv = (token.transform(X_cv['school_state'])).toarray()\n",
    "\n",
    "print(school_state_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 5)\n"
     ]
    }
   ],
   "source": [
    "prefix_train = token.fit_transform(X_train['teacher_prefix']).toarray()\n",
    "prefix_cv = token.transform(X_cv['teacher_prefix']).toarray()\n",
    "prefix_test = token.transform(X_test['teacher_prefix']).toarray()\n",
    "print(prefix_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 4)\n"
     ]
    }
   ],
   "source": [
    "grade_train = token.fit_transform(X_train['project_grade_category']).toarray()\n",
    "grade_cv = token.transform(X_cv['project_grade_category']).toarray()\n",
    "grade_test = token.transform(X_test['project_grade_category']).toarray()\n",
    "print(grade_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 9)\n"
     ]
    }
   ],
   "source": [
    "cat_train = token.fit_transform(X_train['clean_categories']).toarray()\n",
    "cat_cv = token.transform(X_cv['clean_categories']).toarray()\n",
    "cat_test = token.transform(X_test['clean_categories']).toarray()\n",
    "print(cat_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 30)\n"
     ]
    }
   ],
   "source": [
    "subcat_train = token.fit_transform(X_train['clean_subcategories']).toarray()\n",
    "subcat_cv = token.transform(X_cv['clean_subcategories']).toarray()\n",
    "subcat_test = token.transform(X_test['clean_subcategories']).toarray()\n",
    "print(subcat_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 1)\n",
      "(22942, 1)\n",
      "(32775, 1)\n"
     ]
    }
   ],
   "source": [
    "train_num = X_train['num'].values.reshape(-1,1)\n",
    "cv_num = X_cv['num'].values.reshape(-1,1)\n",
    "test_num = X_test['num'].values.reshape(-1,1)\n",
    "print(train_num.shape)\n",
    "print(cv_num.shape)\n",
    "print(test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 100)\n",
      "(22942, 100)\n",
      "(32775, 100)\n"
     ]
    }
   ],
   "source": [
    "cat_num_train_feat = np.hstack((school_state_train,prefix_train,grade_train,cat_train,subcat_train,train_num))\n",
    "cat_num_cv_feat = np.hstack((school_state_cv,prefix_cv,grade_cv,cat_cv,subcat_cv,cv_num))\n",
    "cat_num_test_feat = np.hstack((school_state_test,prefix_test,grade_test,cat_test,subcat_test,test_num))\n",
    "print(cat_num_train_feat.shape)\n",
    "print(cat_num_cv_feat.shape)\n",
    "print(cat_num_test_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_num_train_feat = np.resize(cat_num_train_feat, new_shape=(53531,100,1))\n",
    "cat_num_cv_feat = np.resize(cat_num_cv_feat, new_shape=(22942,100,1))\n",
    "cat_num_test_feat = np.resize(cat_num_test_feat, new_shape=(32775,100,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/fkQ8nGo.png'>\n",
    "ref: https://i.imgur.com/fkQ8nGo.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "essay_input (InputLayer)        [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 250, 300)     12759900    essay_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "other_input (InputLayer)        [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 250, 64)      19264       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 99, 64)       192         other_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 250, 64)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 98, 128)      16512       conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 250, 128)     8320        spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 98, 128)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 250, 128)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 97, 512)      131584      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32000)        0           spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 49664)        0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 81664)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2613280     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           2112        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          8320        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128)          512         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          66048       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 512)          262656      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            1026        dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,889,726\n",
      "Trainable params: 3,129,570\n",
      "Non-trainable params: 12,760,156\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# input 1\n",
    "essay = Input(batch_shape=(None,250), name=\"essay_input\")\n",
    "x1 = Embedding(input_dim=42533,output_dim = 300,weights=[embedding_matrix(features[0],300)],trainable = False)(essay)\n",
    "x1 = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = (Dense(128, activation='relu',kernel_initializer=he_normal()))(x1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "# input 2\n",
    "other = Input(shape=(100,1),name=\"other_input\")\n",
    "x2 = Conv1D(filters=64,kernel_size=2,strides=1)(other)\n",
    "x2 = Conv1D(filters=128,kernel_size=2,strides=1)(x2)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "x2 = Conv1D(filters=512,kernel_size=2,strides=1)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "concat = concatenate([x1,x2])\n",
    "\n",
    "x = (Dense(32, activation='relu',kernel_initializer=he_normal()))(concat)\n",
    "x = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x)\n",
    "x = (Dense(128, activation='relu',kernel_initializer=he_normal()))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = (Dense(512, activation='relu',kernel_initializer=he_normal()))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = (Dense(512, activation='relu',kernel_initializer=he_normal()))(x)\n",
    "\n",
    "output = (Dense(2, activation='softmax'))(x)\n",
    "model = Model([essay,other], output)\n",
    "\n",
    "#To visualize, run -  tensorboard --log_dir=logs/ in command prompt\n",
    "log_dir=\"logs/visualize_m3/\"\n",
    "tensorboard = TensorBoard(log_dir.format(time()))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[auc])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53531 samples, validate on 22942 samples\n",
      "Epoch 1/20\n",
      "53531/53531 [==============================] - 12s 225us/sample - loss: 0.4865 - auc: 0.5354 - val_loss: 0.4606 - val_auc: 0.5747\n",
      "Epoch 2/20\n",
      "53531/53531 [==============================] - 10s 195us/sample - loss: 0.4337 - auc: 0.5660 - val_loss: 0.4294 - val_auc: 0.6056\n",
      "Epoch 3/20\n",
      "53531/53531 [==============================] - 10s 196us/sample - loss: 0.4194 - auc: 0.6171 - val_loss: 0.4597 - val_auc: 0.6857\n",
      "Epoch 4/20\n",
      "53531/53531 [==============================] - 10s 194us/sample - loss: 0.3982 - auc: 0.6855 - val_loss: 0.5325 - val_auc: 0.7120\n",
      "Epoch 5/20\n",
      "53531/53531 [==============================] - 10s 194us/sample - loss: 0.3855 - auc: 0.7152 - val_loss: 0.4331 - val_auc: 0.7041\n",
      "Epoch 6/20\n",
      "53531/53531 [==============================] - 10s 194us/sample - loss: 0.3810 - auc: 0.7260 - val_loss: 0.4257 - val_auc: 0.7149\n",
      "Epoch 7/20\n",
      "53531/53531 [==============================] - 10s 195us/sample - loss: 0.3757 - auc: 0.7350 - val_loss: 0.4784 - val_auc: 0.7146\n",
      "Epoch 8/20\n",
      "53531/53531 [==============================] - 10s 195us/sample - loss: 0.3686 - auc: 0.7480 - val_loss: 0.4680 - val_auc: 0.7189\n",
      "Epoch 9/20\n",
      "53531/53531 [==============================] - 10s 196us/sample - loss: 0.3644 - auc: 0.7546 - val_loss: 0.4330 - val_auc: 0.7213\n",
      "Epoch 10/20\n",
      "53531/53531 [==============================] - 11s 196us/sample - loss: 0.3550 - auc: 0.7710 - val_loss: 0.4825 - val_auc: 0.7110\n",
      "Epoch 11/20\n",
      "53531/53531 [==============================] - 10s 195us/sample - loss: 0.3449 - auc: 0.7892 - val_loss: 0.4071 - val_auc: 0.6997\n",
      "Epoch 12/20\n",
      "53531/53531 [==============================] - 11s 197us/sample - loss: 0.3354 - auc: 0.8062 - val_loss: 0.4069 - val_auc: 0.6784\n",
      "Epoch 13/20\n",
      "53531/53531 [==============================] - 11s 197us/sample - loss: 0.3224 - auc: 0.8245 - val_loss: 0.4384 - val_auc: 0.6933\n",
      "Epoch 14/20\n",
      "53531/53531 [==============================] - 11s 200us/sample - loss: 0.3143 - auc: 0.8357 - val_loss: 0.4649 - val_auc: 0.6918\n",
      "Epoch 15/20\n",
      "53531/53531 [==============================] - 11s 200us/sample - loss: 0.2988 - auc: 0.8567 - val_loss: 0.4465 - val_auc: 0.6788\n",
      "Epoch 16/20\n",
      "53531/53531 [==============================] - 10s 192us/sample - loss: 0.2885 - auc: 0.8680 - val_loss: 0.4584 - val_auc: 0.6823\n",
      "Epoch 17/20\n",
      "53531/53531 [==============================] - 10s 194us/sample - loss: 0.2777 - auc: 0.8806 - val_loss: 0.4605 - val_auc: 0.6729\n",
      "Epoch 18/20\n",
      "53531/53531 [==============================] - 11s 198us/sample - loss: 0.2649 - auc: 0.8934 - val_loss: 0.4623 - val_auc: 0.6682\n",
      "Epoch 19/20\n",
      "53531/53531 [==============================] - 11s 197us/sample - loss: 0.2549 - auc: 0.9031 - val_loss: 0.5031 - val_auc: 0.6647\n",
      "Epoch 20/20\n",
      "53531/53531 [==============================] - 11s 197us/sample - loss: 0.2472 - auc: 0.9109 - val_loss: 0.5000 - val_auc: 0.6702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1445e90f2b0>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([essay_train,cat_num_train_feat], y_train, epochs=20, verbose=1, batch_size=300, validation_data=([essay_cv,cat_num_cv_feat], y_cv), callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train AUC\",roc_auc_score(y_train,(model.predict([essay_train_m2,state_train,grade_train,prefix_train,clean_cat_train,clean_subcat_train,X_train['num']]))))\n",
    "print(\"-\"*50)\n",
    "print(\"Cv AUC\",roc_auc_score(y_cv,model.predict([essay_cv_m2,state_cv,grade_cv,prefix_cv,clean_cat_cv,clean_subcat_cv,X_cv['num']])))\n",
    "print(\"-\"*50)\n",
    "print(\"Test AUC\",roc_auc_score(y_test,model.predict([essay_test_m2,state_test,grade_test,prefix_test,clean_cat_test,clean_subcat_test,X_test['num']])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
