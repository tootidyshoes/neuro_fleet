{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Credits: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "#https://www.liip.ch/en/blog/sentiment-detection-with-keras-word-embeddings-and-lstm-deep-learning-networks\n",
    "\n",
    "# LSTM for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.preprocessing import text,sequence\n",
    "from tensorflow.keras.layers import Activation, Add, Bidirectional, Conv1D, Dense, Dropout, Embedding, Flatten, Reshape\n",
    "from tensorflow.keras.layers import concatenate, GRU, Input, CuDNNLSTM, MaxPooling1D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D,  GlobalMaxPooling1D, SpatialDropout1D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.python.keras import backend as k\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = pd.read_csv(\"preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>725.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>213.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>having class 24 students comes diverse learner...</td>\n",
       "      <td>329.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ga</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>appliedlearning</td>\n",
       "      <td>earlydevelopment</td>\n",
       "      <td>i recently read article giving students choice...</td>\n",
       "      <td>481.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wa</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>my students crave challenge eat obstacles brea...</td>\n",
       "      <td>17.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state teacher_prefix project_grade_category  \\\n",
       "0           ca            mrs          grades_prek_2   \n",
       "1           ut             ms             grades_3_5   \n",
       "2           ca            mrs          grades_prek_2   \n",
       "3           ga            mrs          grades_prek_2   \n",
       "4           wa            mrs             grades_3_5   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            53                    1   \n",
       "1                                             4                    1   \n",
       "2                                            10                    1   \n",
       "3                                             2                    1   \n",
       "4                                             2                    1   \n",
       "\n",
       "    clean_categories                 clean_subcategories  \\\n",
       "0       math_science  appliedsciences health_lifescience   \n",
       "1       specialneeds                        specialneeds   \n",
       "2  literacy_language                            literacy   \n",
       "3    appliedlearning                    earlydevelopment   \n",
       "4  literacy_language                            literacy   \n",
       "\n",
       "                                               essay   price  \n",
       "0  i fortunate enough use fairy tale stem kits cl...  725.05  \n",
       "1  imagine 8 9 years old you third grade classroo...  213.03  \n",
       "2  having class 24 students comes diverse learner...  329.00  \n",
       "3  i recently read article giving students choice...  481.04  \n",
       "4  my students crave challenge eat obstacles brea...   17.74  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes : ['school_state' 'teacher_prefix' 'project_grade_category'\n",
      " 'teacher_number_of_previously_posted_projects' 'project_is_approved'\n",
      " 'clean_categories' 'clean_subcategories' 'essay' 'price']\n"
     ]
    }
   ],
   "source": [
    "#Printing the attributes of project_data\n",
    "print(\"Attributes :\", project_data.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_data = pd.read_csv('resources.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p233245</td>\n",
       "      <td>LC652 - Lakeshore Double-Space Mobile Drying Rack</td>\n",
       "      <td>1</td>\n",
       "      <td>149.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Bouncy Bands for Desks (Blue support pipes)</td>\n",
       "      <td>3</td>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Cory Stories: A Kid's Book About Living With Adhd</td>\n",
       "      <td>1</td>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  quantity  \\\n",
       "0  p233245  LC652 - Lakeshore Double-Space Mobile Drying Rack         1   \n",
       "1  p069063        Bouncy Bands for Desks (Blue support pipes)         3   \n",
       "2  p069063  Cory Stories: A Kid's Book About Living With Adhd         1   \n",
       "\n",
       "    price  \n",
       "0  149.00  \n",
       "1   14.95  \n",
       "2    8.45  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p000001</td>\n",
       "      <td>459.56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p000002</td>\n",
       "      <td>515.89</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   price  quantity\n",
       "0  p000001  459.56         7\n",
       "1  p000002  515.89        21"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reference : https://stackoverflow.com/questions/22407798/how-to-reset-a-dataframes-indexes-for-all-groups-in-one-step\n",
    "price_data = resource_data.groupby('id').agg({'price':'sum', 'quantity':'sum'}).reset_index()\n",
    "price_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join two dataframes(project_data and price_data) in python\n",
    "# reference : https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
    "project_data['price'] = resource_data['price']\n",
    "project_data['quantity'] = resource_data['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>149.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>14.95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state teacher_prefix project_grade_category  \\\n",
       "0           ca            mrs          grades_prek_2   \n",
       "1           ut             ms             grades_3_5   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            53                    1   \n",
       "1                                             4                    1   \n",
       "\n",
       "  clean_categories                 clean_subcategories  \\\n",
       "0     math_science  appliedsciences health_lifescience   \n",
       "1     specialneeds                        specialneeds   \n",
       "\n",
       "                                               essay   price  quantity  \n",
       "0  i fortunate enough use fairy tale stem kits cl...  149.00         1  \n",
       "1  imagine 8 9 years old you third grade classroo...   14.95         3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical inputs\n",
    "project_data['num'] = project_data['teacher_number_of_previously_posted_projects'] + project_data['price'] + project_data['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>149.00</td>\n",
       "      <td>1</td>\n",
       "      <td>203.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>14.95</td>\n",
       "      <td>3</td>\n",
       "      <td>21.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>having class 24 students comes diverse learner...</td>\n",
       "      <td>8.45</td>\n",
       "      <td>1</td>\n",
       "      <td>19.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ga</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>appliedlearning</td>\n",
       "      <td>earlydevelopment</td>\n",
       "      <td>i recently read article giving students choice...</td>\n",
       "      <td>13.59</td>\n",
       "      <td>2</td>\n",
       "      <td>17.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wa</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>my students crave challenge eat obstacles brea...</td>\n",
       "      <td>24.95</td>\n",
       "      <td>3</td>\n",
       "      <td>29.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state teacher_prefix project_grade_category  \\\n",
       "0           ca            mrs          grades_prek_2   \n",
       "1           ut             ms             grades_3_5   \n",
       "2           ca            mrs          grades_prek_2   \n",
       "3           ga            mrs          grades_prek_2   \n",
       "4           wa            mrs             grades_3_5   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            53                    1   \n",
       "1                                             4                    1   \n",
       "2                                            10                    1   \n",
       "3                                             2                    1   \n",
       "4                                             2                    1   \n",
       "\n",
       "    clean_categories                 clean_subcategories  \\\n",
       "0       math_science  appliedsciences health_lifescience   \n",
       "1       specialneeds                        specialneeds   \n",
       "2  literacy_language                            literacy   \n",
       "3    appliedlearning                    earlydevelopment   \n",
       "4  literacy_language                            literacy   \n",
       "\n",
       "                                               essay   price  quantity     num  \n",
       "0  i fortunate enough use fairy tale stem kits cl...  149.00         1  203.00  \n",
       "1  imagine 8 9 years old you third grade classroo...   14.95         3   21.95  \n",
       "2  having class 24 students comes diverse learner...    8.45         1   19.45  \n",
       "3  i recently read article giving students choice...   13.59         2   17.59  \n",
       "4  my students crave challenge eat obstacles brea...   24.95         3   29.95  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['teacher_number_of_previously_posted_projects', 'price', 'quantity']\n",
    "\n",
    "project_data.drop(labels=col,axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>203.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>21.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>having class 24 students comes diverse learner...</td>\n",
       "      <td>19.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ga</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>1</td>\n",
       "      <td>appliedlearning</td>\n",
       "      <td>earlydevelopment</td>\n",
       "      <td>i recently read article giving students choice...</td>\n",
       "      <td>17.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wa</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>my students crave challenge eat obstacles brea...</td>\n",
       "      <td>29.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state teacher_prefix project_grade_category  project_is_approved  \\\n",
       "0           ca            mrs          grades_prek_2                    1   \n",
       "1           ut             ms             grades_3_5                    1   \n",
       "2           ca            mrs          grades_prek_2                    1   \n",
       "3           ga            mrs          grades_prek_2                    1   \n",
       "4           wa            mrs             grades_3_5                    1   \n",
       "\n",
       "    clean_categories                 clean_subcategories  \\\n",
       "0       math_science  appliedsciences health_lifescience   \n",
       "1       specialneeds                        specialneeds   \n",
       "2  literacy_language                            literacy   \n",
       "3    appliedlearning                    earlydevelopment   \n",
       "4  literacy_language                            literacy   \n",
       "\n",
       "                                               essay     num  \n",
       "0  i fortunate enough use fairy tale stem kits cl...  203.00  \n",
       "1  imagine 8 9 years old you third grade classroo...   21.95  \n",
       "2  having class 24 students comes diverse learner...   19.45  \n",
       "3  i recently read article giving students choice...   17.59  \n",
       "4  my students crave challenge eat obstacles brea...   29.95  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109248, 7)\n",
      "(109248,)\n"
     ]
    }
   ],
   "source": [
    "y = project_data['project_is_approved']\n",
    "project_data.drop(['project_is_approved'], axis=1, inplace=True)\n",
    "X = project_data\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y , stratify = y, train_size = 0.7)\n",
    "X_train,X_cv,y_train,y_cv = train_test_split(X_train,y_train,stratify = y_train,train_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 7) (53531,)\n",
      "(22942, 7) (22942,)\n",
      "(32775, 7) (32775,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_cv.shape, y_cv.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting class labels to categorical variables\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_cv = to_categorical(y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating embedding matrix using pretrain golve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dict = {}\n",
    "glove = open('glove.42B.300d.txt', encoding=\"utf8\")     \n",
    "for line in glove:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:], dtype='float32')\n",
    "    emb_dict[word] = vector\n",
    "glove.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "def embedding_matrix(word_index, embedding_dim):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = emb_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and padding text data (essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(lowercase= False)\n",
    "features = []\n",
    "essay_train = count.fit_transform(X_train['essay'])\n",
    "freqs = essay_train.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = count.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "features.append(word_rank)\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# define documents\n",
    "train_doc = X_train['essay']\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(train_doc)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "essay_train = t.texts_to_sequences(train_doc)\n",
    "test_doc = X_test['essay']\n",
    "essay_test = t.texts_to_sequences(test_doc)\n",
    "cv_doc = X_cv['essay']\n",
    "essay_cv = t.texts_to_sequences(cv_doc)\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_review_length = 250\n",
    "essay_train = pad_sequences(essay_train, maxlen=max_review_length) \n",
    "essay_test = pad_sequences(essay_test, maxlen=max_review_length)\n",
    "essay_cv = pad_sequences(essay_cv, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    7, 1489,   70, 2136, 1473,    4,    1,    5,\n",
       "       1489,  980, 1520,    4,    1,  576, 1699,  118,   12,  903, 2314,\n",
       "        275,  316,  254, 2314,  275,  175,  427,    3,   30,  146,  183,\n",
       "         37,   39,   88,    2,   49,  112,   37,  273,    3,  485,  414,\n",
       "       4606,    1,  601,   64,  150,   83,   12,   22,   27, 1474,  302,\n",
       "          4,    1,   19,   27,  471,  920,  571,  641, 2612,    4,    3,\n",
       "       2369,   27,  207,    1,   57,    2, 3792,  363,  709,    9,  412,\n",
       "         27,  597, 2624,   50,    3,    4,  146,   58,    6,   82,    1,\n",
       "        358,   27,  183,  101,  597,  534,   26,    1,   69,  270,  183,\n",
       "       1931,  980, 1520,  449, 2080, 2234,   26,   25, 2045, 2578, 2333,\n",
       "        597,  538,  406, 1086,   14,   69,  764, 3249,  101,  129,   11,\n",
       "       2144, 1972,    1,   69,  226,  183, 1931,  980, 1520,  449, 2080,\n",
       "       2234,   26,   25, 2045, 2578, 2333,  597,  538,  406, 1086,   14,\n",
       "         69,  764, 3249,  101,  129,   11, 2144, 1972,    4,    1,    9,\n",
       "       1731, 1074,  101,   11,  316,  275,  289,  226,  109,  100,  366,\n",
       "        209, 1077,  514,  352, 2386, 3158, 1642,  204,  125,    1,  462,\n",
       "        199,    2,  289,   58,  128,    1,    9,   28,  363,   27,   26,\n",
       "          4,    1,  814, 2228,   27, 1938,   27,  204,  118,  377,    2,\n",
       "        136, 1312,   24, 6818,  526,    1,  148,   13])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_train[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. School_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# define documents\n",
    "state_train_doc = X_train['school_state']\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(state_train_doc)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "state_train = t.texts_to_sequences(state_train_doc)\n",
    "state_test_doc = X_test['school_state']\n",
    "state_test = t.texts_to_sequences(state_test_doc)\n",
    "state_cv_doc = X_cv['school_state']\n",
    "state_cv = t.texts_to_sequences(state_cv_doc)\n",
    "\n",
    "max_review_length = 1\n",
    "state_train = pad_sequences(state_train, maxlen=max_review_length)\n",
    "state_test = pad_sequences(state_test, maxlen=max_review_length)\n",
    "state_cv = pad_sequences(state_cv, maxlen=max_review_length)\n",
    "\n",
    "print(state_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Teacher_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# define documents\n",
    "prefix_train_doc = X_train['teacher_prefix']\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(prefix_train_doc)\n",
    "prefix_size = len(t.word_index) + 1\n",
    "prefix_train = t.texts_to_sequences(prefix_train_doc)\n",
    "prefix_test_doc = X_test['teacher_prefix']\n",
    "prefix_test = t.texts_to_sequences(prefix_test_doc)\n",
    "prefix_cv_doc = X_cv['teacher_prefix']\n",
    "prefix_cv = t.texts_to_sequences(prefix_cv_doc)\n",
    "\n",
    "max_review_length = 1\n",
    "prefix_train = pad_sequences(prefix_train, maxlen=max_review_length)\n",
    "prefix_test = pad_sequences(prefix_test, maxlen=max_review_length)\n",
    "prefix_cv = pad_sequences(prefix_cv, maxlen=max_review_length)\n",
    "\n",
    "print(prefix_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Project_grade_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# define documents\n",
    "grade_train_doc = X_train['project_grade_category']\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(grade_train_doc)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "grade_train = t.texts_to_sequences(grade_train_doc)\n",
    "grade_test_doc = X_test['project_grade_category']\n",
    "grade_test = t.texts_to_sequences(grade_test_doc)\n",
    "grade_cv_doc = X_cv['project_grade_category']\n",
    "grade_cv = t.texts_to_sequences(grade_cv_doc)\n",
    "\n",
    "max_review_length = 1\n",
    "grade_train = pad_sequences(grade_train, maxlen=max_review_length)\n",
    "grade_test = pad_sequences(grade_test, maxlen=max_review_length)\n",
    "grade_cv = pad_sequences(grade_cv, maxlen=max_review_length)\n",
    "\n",
    "print(grade_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Clean_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# define documents\n",
    "clean_cat_train_doc = X_train['clean_categories']\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(clean_cat_train_doc)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "clean_cat_train = t.texts_to_sequences(clean_cat_train_doc)\n",
    "clean_cat_test_doc = X_test['clean_categories']\n",
    "clean_cat_test = t.texts_to_sequences(clean_cat_test_doc)\n",
    "clean_cat_cv_doc = X_cv['clean_categories']\n",
    "clean_cat_cv = t.texts_to_sequences(clean_cat_cv_doc)\n",
    "\n",
    "max_review_length = 1\n",
    "clean_cat_train = pad_sequences(clean_cat_train, maxlen=max_review_length)\n",
    "clean_cat_test = pad_sequences(clean_cat_test, maxlen=max_review_length)\n",
    "clean_cat_cv = pad_sequences(clean_cat_cv, maxlen=max_review_length)\n",
    "\n",
    "print(clean_cat_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Clean_subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# define documents\n",
    "clean_subcat_train_doc = X_train['clean_subcategories']\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(clean_subcat_train_doc)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "clean_subcat_train = t.texts_to_sequences(clean_subcat_train_doc)\n",
    "clean_subcat_test_doc = X_test['clean_subcategories']\n",
    "clean_subcat_test = t.texts_to_sequences(clean_subcat_test_doc)\n",
    "clean_subcat_cv_doc = X_cv['clean_subcategories']\n",
    "clean_subcat_cv = t.texts_to_sequences(clean_subcat_cv_doc)\n",
    "\n",
    "max_review_length = 1\n",
    "clean_subcat_train = pad_sequences(clean_subcat_train, maxlen=max_review_length)\n",
    "clean_subcat_test = pad_sequences(clean_subcat_test, maxlen=max_review_length)\n",
    "clean_subcat_cv = pad_sequences(clean_subcat_cv, maxlen=max_review_length)\n",
    "\n",
    "print(clean_subcat_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
    "#https://developpaper.com/question/how-to-apply-the-custom-operation-of-py_func-in-tensorflow-to-keras/\n",
    "def auc(y_true, y_pred) :\n",
    "    score = tf.py_func( lambda y_true, y_pred : roc_auc_score( y_true, y_pred, average='macro', sample_weight=None).astype('float32'),\n",
    "                        [y_true, y_pred],\n",
    "                        'float32',\n",
    "                        stateful=True,\n",
    "                        name='sklearnAUC')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------  Model 1  ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/w395Yk9.png'>\n",
    "ref: https://i.imgur.com/w395Yk9.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vansh\\Anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\vansh\\Anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-28-8ce479a739e9>:8: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "essay (InputLayer)              [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 250, 300)     12759900    essay[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)          (None, 250, 128)     220160      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "state (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prefix (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "grade (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subject_category (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subject_sub_category (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 250, 128)     0           cu_dnnlstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 2)         104         state[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 2)         10          prefix[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 2)         100         grade[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 50)        19250       subject_category[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 5)         30          subject_sub_category[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "numerical (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32000)        0           spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2)            0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 50)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 5)            0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           64          numerical[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32093)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          4108032     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64)           256         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            66          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,118,308\n",
      "Trainable params: 4,358,280\n",
      "Non-trainable params: 12,760,028\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Essay input --> 1\n",
    "essay = Input(shape=(250,), name=\"essay\")\n",
    "x1 = Embedding(input_dim=42533,output_dim=300,trainable=False,weights=[embedding_matrix(features[0],300)])(essay)\n",
    "x1 = CuDNNLSTM(128,return_sequences=True)(x1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "\n",
    "#State input --> 2\n",
    "state = Input(shape=(1,), name=\"state\")\n",
    "x2 = Embedding(input_dim=52,output_dim=2)(state)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "#Teacher prefix input --> 3\n",
    "prefix = Input(shape=(1,), name=\"prefix\")\n",
    "x3 = Embedding(input_dim=5,output_dim=2)(prefix)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "#Grade category input --> 4\n",
    "grade = Input(shape=(1,), name=\"grade\")\n",
    "x4 = Embedding(input_dim=50,output_dim=2)(grade)\n",
    "x4 = Flatten()(x4)\n",
    "\n",
    "#Subject category input --> 5\n",
    "subj_cat = Input(shape=(1,), name=\"subject_category\")\n",
    "x5 = Embedding(input_dim=385,output_dim=50)(subj_cat)\n",
    "x5 = Flatten()(x5)\n",
    "\n",
    "#Subject subcategory input --> 6\n",
    "subj_subcat = Input(shape=(1,), name=\"subject_sub_category\")\n",
    "x6 = Embedding(input_dim=6,output_dim=5)(subj_subcat)\n",
    "x6 = Flatten()(x6)\n",
    "\n",
    "#Numerical input -->7\n",
    "num = Input(shape=(1,), name=\"numerical\")\n",
    "x7 = (Dense(32, activation='relu',kernel_initializer=he_normal()))(num)\n",
    "\n",
    "\n",
    "\n",
    "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
    "\n",
    "x = (Dense(128, activation='relu',kernel_initializer=he_normal()))(concat)\n",
    "x = Dropout(0.3)(x)\n",
    "x = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = (Dense(32, activation='relu',kernel_initializer=he_normal()))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = (Dense(2, activation='softmax'))(x)\n",
    " \n",
    "\n",
    "model = Model([essay,state,prefix,grade,subj_cat,subj_subcat,num], output)\n",
    "\n",
    "#https://www.youtube.com/watch?v=2U6Jl7oqRkM\n",
    "#Instantiating tensorboard for model visualization\n",
    "#To visualize, run -  tensorboard --log_dir=logs/{} in command prompt\n",
    "tensorboard = TensorBoard(log_dir=\"logs/\".format(time))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[auc])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53531 samples, validate on 22942 samples\n",
      "Epoch 1/15\n",
      "53531/53531 [==============================] - 43s 796us/sample - loss: 0.5032 - auc: 0.5099 - val_loss: 0.4393 - val_auc: 0.5292\n",
      "Epoch 2/15\n",
      "53531/53531 [==============================] - 23s 423us/sample - loss: 0.4498 - auc: 0.5199 - val_loss: 0.4483 - val_auc: 0.5332\n",
      "Epoch 3/15\n",
      "53531/53531 [==============================] - 23s 422us/sample - loss: 0.4381 - auc: 0.5327 - val_loss: 0.4400 - val_auc: 0.5140\n",
      "Epoch 4/15\n",
      "53531/53531 [==============================] - 23s 426us/sample - loss: 0.4340 - auc: 0.5260 - val_loss: 0.4314 - val_auc: 0.5300\n",
      "Epoch 5/15\n",
      "53531/53531 [==============================] - 23s 427us/sample - loss: 0.4259 - auc: 0.5669 - val_loss: 0.4272 - val_auc: 0.6090\n",
      "Epoch 6/15\n",
      "53531/53531 [==============================] - 23s 427us/sample - loss: 0.4203 - auc: 0.6008 - val_loss: 0.4176 - val_auc: 0.6309\n",
      "Epoch 7/15\n",
      "53531/53531 [==============================] - 23s 421us/sample - loss: 0.4119 - auc: 0.6320 - val_loss: 0.4252 - val_auc: 0.5692\n",
      "Epoch 8/15\n",
      "53531/53531 [==============================] - 23s 427us/sample - loss: 0.4181 - auc: 0.5956 - val_loss: 0.4120 - val_auc: 0.6586\n",
      "Epoch 9/15\n",
      "53531/53531 [==============================] - 23s 424us/sample - loss: 0.3962 - auc: 0.6881 - val_loss: 0.3971 - val_auc: 0.6929\n",
      "Epoch 10/15\n",
      "53531/53531 [==============================] - 23s 425us/sample - loss: 0.3884 - auc: 0.7102 - val_loss: 0.3929 - val_auc: 0.6997\n",
      "Epoch 11/15\n",
      "53531/53531 [==============================] - 23s 424us/sample - loss: 0.3783 - auc: 0.7347 - val_loss: 0.3918 - val_auc: 0.7004\n",
      "Epoch 12/15\n",
      "53531/53531 [==============================] - 23s 424us/sample - loss: 0.3678 - auc: 0.7582 - val_loss: 0.3886 - val_auc: 0.7048\n",
      "Epoch 13/15\n",
      "53531/53531 [==============================] - 23s 423us/sample - loss: 0.3567 - auc: 0.7771 - val_loss: 0.3945 - val_auc: 0.7071\n",
      "Epoch 14/15\n",
      "53531/53531 [==============================] - 23s 423us/sample - loss: 0.3385 - auc: 0.8061 - val_loss: 0.4005 - val_auc: 0.7050\n",
      "Epoch 15/15\n",
      "53531/53531 [==============================] - 23s 423us/sample - loss: 0.3148 - auc: 0.8364 - val_loss: 0.4041 - val_auc: 0.6930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224d0c665c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([essay_train,state_train,grade_train,prefix_train,clean_cat_train,clean_subcat_train,X_train['num']], y_train, epochs=15, verbose=1, batch_size=300, validation_data=([essay_cv,state_cv,grade_cv,prefix_cv,clean_cat_cv,clean_subcat_cv,X_cv['num']], y_cv), callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "model.save_weights(\"model1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC 0.889562317498128\n",
      "--------------------------------------------------\n",
      "Cv AUC 0.6936691179680007\n",
      "--------------------------------------------------\n",
      "Test AUC 0.7058652426489026\n"
     ]
    }
   ],
   "source": [
    "print(\"Train AUC\",roc_auc_score(y_train,(model.predict([essay_train,state_train,grade_train,prefix_train,clean_cat_train,clean_subcat_train,X_train['num']]))))\n",
    "print(\"-\"*50)\n",
    "print(\"Cv AUC\",roc_auc_score(y_cv,model.predict([essay_cv,state_cv,grade_cv,prefix_cv,clean_cat_cv,clean_subcat_cv,X_cv['num']])))\n",
    "print(\"-\"*50)\n",
    "print(\"Test AUC\",roc_auc_score(y_test,model.predict([essay_test,state_test,grade_test,prefix_test,clean_cat_test,clean_subcat_test,X_test['num']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"model1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Load TENSORBOARD\\n%load_ext tensorboard\\n# Start TENSORBOARD\\n%tensorboard --logdir logs'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Load TENSORBOARD\n",
    "%load_ext tensorboard\n",
    "# Start TENSORBOARD\n",
    "%tensorboard --logdir logs'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------  Model 2  ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 7) (53531, 2)\n",
      "(22942, 7) (22942, 2)\n",
      "(32775, 7) (32775, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_cv.shape, y_cv.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'IDF score')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "tfidf = TfidfVectorizer()\n",
    "data_text = tfidf.fit_transform(X_train['essay'])\n",
    "plt.boxplot(tfidf.idf_)\n",
    "plt.ylabel(\"IDF score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 percentile (idf): [9.17998468]\n",
      "50 percentile (idf): [10.50174052]\n",
      "75 percentile (idf): [11.1948877]\n",
      "90 percentile (idf): [11.1948877]\n"
     ]
    }
   ],
   "source": [
    "print(\"25 percentile (idf):\", np.percentile(tfidf.idf_,[25]))\n",
    "print(\"50 percentile (idf):\",np.percentile(tfidf.idf_,[50]))\n",
    "print(\"75 percentile (idf):\",np.percentile(tfidf.idf_,[75]))\n",
    "print(\"90 percentile (idf):\",np.percentile(tfidf.idf_,[90]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_idf_val = zip(tfidf.get_feature_names(),tfidf.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = []\n",
    "for f,val in feat_idf_val:\n",
    "    if val>=2 and val<=10:\n",
    "        feat.append(f)\n",
    "    else:\n",
    "        continue   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering only those features with idf value between 25th and 75th percentile in 'project_essay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_essay = []\n",
    "for text in X_train['essay']:\n",
    "    sent = \" \"\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word in feat:\n",
    "            sent = \" \"+word\n",
    "        else:\n",
    "            continue\n",
    "    train_essay.append(sent)\n",
    "X_train['essay'] = train_essay  \n",
    "\n",
    "#Featurizing cv essay\n",
    "cv_essay = []\n",
    "for text in X_cv['essay']:\n",
    "    sent = \" \"\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word in feat:\n",
    "            sent = \" \"+word\n",
    "        else:\n",
    "            continue\n",
    "    cv_essay.append(sent)\n",
    "X_cv['essay'] = cv_essay  \n",
    "\n",
    "\n",
    "#Featurizing test essay\n",
    "test_essay = []\n",
    "for text in X_test['essay']:\n",
    "    sent = \" \"\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word in feat:\n",
    "            sent = \" \"+word\n",
    "        else:\n",
    "            continue\n",
    "    test_essay.append(sent)\n",
    "X_test['essay'] = test_essay  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(lowercase= False)\n",
    "features = []\n",
    "essay_train = count.fit_transform(X_train['essay'])\n",
    "freqs = essay_train.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = count.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "features.append(word_rank)\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# define documents\n",
    "train_doc = X_train['essay']\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(train_doc)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "essay_train = t.texts_to_sequences(train_doc)\n",
    "test_doc = X_test['essay']\n",
    "essay_test = t.texts_to_sequences(test_doc)\n",
    "cv_doc = X_cv['essay']\n",
    "essay_cv = t.texts_to_sequences(cv_doc)\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_review_length = 250\n",
    "essay_train = pad_sequences(essay_train, maxlen=max_review_length) \n",
    "essay_test = pad_sequences(essay_test, maxlen=max_review_length)\n",
    "essay_cv = pad_sequences(essay_cv, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Essay input --> 1\n",
    "essay = Input(shape=(250,), name=\"essay\")\n",
    "x1 = Embedding(input_dim=4908,output_dim=300,trainable=False,weights=[embedding_matrix(features[0],300)])(essay)\n",
    "x1 = CuDNNLSTM(128,return_sequences=True)(x1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "\n",
    "#State input --> 2\n",
    "state = Input(shape=(1,), name=\"state\")\n",
    "x2 = Embedding(input_dim=52,output_dim=2)(state)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "#Teacher prefix input --> 3\n",
    "prefix = Input(shape=(1,), name=\"prefix\")\n",
    "x3 = Embedding(input_dim=5,output_dim=2)(prefix)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "#Grade category input --> 4\n",
    "grade = Input(shape=(1,), name=\"grade\")\n",
    "x4 = Embedding(input_dim=50,output_dim=2)(grade)\n",
    "x4 = Flatten()(x4)\n",
    "\n",
    "#Subject category input --> 5\n",
    "subj_cat = Input(shape=(1,), name=\"subject_category\")\n",
    "x5 = Embedding(input_dim=385,output_dim=50)(subj_cat)\n",
    "x5 = Flatten()(x5)\n",
    "\n",
    "#Subject subcategory input --> 6\n",
    "subj_subcat = Input(shape=(1,), name=\"subject_sub_category\")\n",
    "x6 = Embedding(input_dim=6,output_dim=5)(subj_subcat)\n",
    "x6 = Flatten()(x6)\n",
    "\n",
    "#Numerical input -->7\n",
    "num = Input(shape=(1,), name=\"numerical\")\n",
    "x7 = (Dense(32, activation='relu',kernel_initializer=he_normal()))(num)\n",
    "\n",
    "\n",
    "\n",
    "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
    "\n",
    "x = (Dense(128, activation='relu',kernel_initializer=he_normal()))(concat)\n",
    "x = Dropout(0.3)(x)\n",
    "x = (Dense(64, activation='relu',kernel_initializer=he_normal()))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = (Dense(32, activation='relu',kernel_initializer=he_normal()))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = (Dense(2, activation='softmax'))(x)\n",
    " \n",
    "\n",
    "model = Model([essay,state,prefix,grade,subj_cat,subj_subcat,num], output)\n",
    "\n",
    "#https://www.youtube.com/watch?v=2U6Jl7oqRkM\n",
    "#Instantiating tensorboard for model visualization\n",
    "#To visualize, run -  tensorboard --log_dir=logs/{} in command prompt\n",
    "tensorboard = TensorBoard(log_dir=\"logs/\".format(time))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[auc])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53531 samples, validate on 22942 samples\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "model.fit([essay_train,state_train,grade_train,prefix_train,clean_cat_train,clean_subcat_train,X_train['num']], y_train, epochs=20, verbose=1, batch_size=300, validation_data=([essay_cv,state_cv,grade_cv,prefix_cv,clean_cat_cv,clean_subcat_cv,X_cv['num']], y_cv),callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "\n",
    "model.save_weights(\"model2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC 0.5289546532322853\n",
      "--------------------------------------------------\n",
      "Cv AUC 0.5347986063722183\n",
      "--------------------------------------------------\n",
      "Test AUC 0.5250754856033888\n"
     ]
    }
   ],
   "source": [
    "print(\"Train AUC\",roc_auc_score(y_train,(model.predict([essay_train,state_train,grade_train,prefix_train,clean_cat_train,clean_subcat_train,X_train['num']]))))\n",
    "print(\"-\"*50)\n",
    "print(\"Cv AUC\",roc_auc_score(y_cv,model.predict([essay_cv,state_cv,grade_cv,prefix_cv,clean_cat_cv,clean_subcat_cv,X_cv['num']])))\n",
    "print(\"-\"*50)\n",
    "print(\"Test AUC\",roc_auc_score(y_test,model.predict([essay_test,state_test,grade_test,prefix_test,clean_cat_test,clean_subcat_test,X_test['num']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Load TENSORBOARD\\n%load_ext tensorboard\\n# Start TENSORBOARD\\n%tensorboard --logdir logs'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Load TENSORBOARD\n",
    "%load_ext tensorboard\n",
    "# Start TENSORBOARD\n",
    "%tensorboard --logdir logs'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"model2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------  Model 3  ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y , stratify = y, train_size = 0.7)\n",
    "X_train,X_cv,y_train,y_cv = train_test_split(X_train,y_train,stratify = y_train,train_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 7) (53531,)\n",
      "(22942, 7) (22942,)\n",
      "(32775, 7) (32775,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_cv.shape, y_cv.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting class labels to categorical variables\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_cv = to_categorical(y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 7) (53531,)\n",
      "(22942, 7) (22942,)\n",
      "(32775, 7) (32775,)\n"
     ]
    }
   ],
   "source": [
    "#splitting data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y , stratify = y, train_size = 0.7)\n",
    "X_train,X_cv,y_train,y_cv = train_test_split(X_train,y_train,stratify = y_train,train_size = 0.7)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_cv.shape, y_cv.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "#converting class labels to categorical variables\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_cv = to_categorical(y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(lowercase= False)\n",
    "features = []\n",
    "essay_train = count.fit_transform(X_train['essay'])\n",
    "freqs = essay_train.sum(axis=0).A1\n",
    "index = freqs.argsort()\n",
    "words = count.get_feature_names()\n",
    "\n",
    "word_rank = dict()\n",
    "rank = 1\n",
    "for i in index[::-1]:\n",
    "    k = words[i]\n",
    "    word_rank[k] = rank\n",
    "    rank+=1\n",
    "features.append(word_rank)\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# define documents\n",
    "train_doc = X_train['essay']\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(train_doc)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "essay_train = t.texts_to_sequences(train_doc)\n",
    "test_doc = X_test['essay']\n",
    "essay_test = t.texts_to_sequences(test_doc)\n",
    "cv_doc = X_cv['essay']\n",
    "essay_cv = t.texts_to_sequences(cv_doc)\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_review_length = 250\n",
    "essay_train = pad_sequences(essay_train, maxlen=max_review_length) \n",
    "essay_test = pad_sequences(essay_test, maxlen=max_review_length)\n",
    "essay_cv = pad_sequences(essay_cv, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 250)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,  106,   76,   91,  135,   52,  134,    3,  172,    1,  614,\n",
       "        291,  129,    6,  256,   12,  129,  204,    2,   34,   73, 6738,\n",
       "        708,  350,  369,   43,  869,  258,    9,  469,  474,   10,  111,\n",
       "        110,  474,  101,  469,  745,  294,   74,    9, 1149,  672,  700,\n",
       "        749,   61,    2,  151,   21,  763,  173,   10,   30,  269,  118,\n",
       "          5,  127, 1267,  334,   67,  207,  160,   27,    2,  137,   21,\n",
       "         73,  382,   74,  192,   28, 2872,    3,  731,   11,  315, 2724,\n",
       "         58,  118,  146,   71,  731,   11,   44,   16,  131, 1150,  583,\n",
       "        238,  453,  314,  207,   27,    9,   29,   21,  325,  152,  469,\n",
       "        708,  334,   42,   65,  117, 1841,    9,  312,  127,  150,   50,\n",
       "        117, 3070,   67,  146, 2328,  111, 3555,  238,  371, 1097, 1150,\n",
       "        583,  312, 2610, 3610,  459,  238,   16,  131, 4060,  327, 1686,\n",
       "         16,  131,  152, 2328,  231, 1859, 4060,  483,  238, 1021,  238,\n",
       "        395,  212,   44,  127,   11,  101,  469,  745,   21,   11, 1248,\n",
       "        192,  155,   28,   11,   29,  101,  469,  715, 1572,  569,  238,\n",
       "        453,   27,   73,   75,   11,  110, 5294,   13])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(essay_train.shape)\n",
    "essay_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 51)\n"
     ]
    }
   ],
   "source": [
    "token = CountVectorizer()\n",
    "\n",
    "school_state_train = (token.fit_transform(X_train['school_state'])).toarray()\n",
    "school_state_test = (token.transform(X_test['school_state'])).toarray()\n",
    "school_state_cv = (token.transform(X_cv['school_state'])).toarray()\n",
    "\n",
    "print(school_state_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 5)\n"
     ]
    }
   ],
   "source": [
    "prefix_train = token.fit_transform(X_train['teacher_prefix']).toarray()\n",
    "prefix_cv = token.transform(X_cv['teacher_prefix']).toarray()\n",
    "prefix_test = token.transform(X_test['teacher_prefix']).toarray()\n",
    "print(prefix_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 4)\n"
     ]
    }
   ],
   "source": [
    "grade_train = token.fit_transform(X_train['project_grade_category']).toarray()\n",
    "grade_cv = token.transform(X_cv['project_grade_category']).toarray()\n",
    "grade_test = token.transform(X_test['project_grade_category']).toarray()\n",
    "print(grade_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 9)\n"
     ]
    }
   ],
   "source": [
    "cat_train = token.fit_transform(X_train['clean_categories']).toarray()\n",
    "cat_cv = token.transform(X_cv['clean_categories']).toarray()\n",
    "cat_test = token.transform(X_test['clean_categories']).toarray()\n",
    "print(cat_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 30)\n"
     ]
    }
   ],
   "source": [
    "subcat_train = token.fit_transform(X_train['clean_subcategories']).toarray()\n",
    "subcat_cv = token.transform(X_cv['clean_subcategories']).toarray()\n",
    "subcat_test = token.transform(X_test['clean_subcategories']).toarray()\n",
    "print(subcat_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 1)\n",
      "(22942, 1)\n",
      "(32775, 1)\n"
     ]
    }
   ],
   "source": [
    "train_num = X_train['num'].values.reshape(-1,1)\n",
    "cv_num = X_cv['num'].values.reshape(-1,1)\n",
    "test_num = X_test['num'].values.reshape(-1,1)\n",
    "print(train_num.shape)\n",
    "print(cv_num.shape)\n",
    "print(test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53531, 100)\n",
      "(22942, 100)\n",
      "(32775, 100)\n"
     ]
    }
   ],
   "source": [
    "cat_num_train_feat = np.hstack((school_state_train,prefix_train,grade_train,cat_train,subcat_train,train_num))\n",
    "cat_num_cv_feat = np.hstack((school_state_cv,prefix_cv,grade_cv,cat_cv,subcat_cv,cv_num))\n",
    "cat_num_test_feat = np.hstack((school_state_test,prefix_test,grade_test,cat_test,subcat_test,test_num))\n",
    "print(cat_num_train_feat.shape)\n",
    "print(cat_num_cv_feat.shape)\n",
    "print(cat_num_test_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_num_train_feat = np.resize(cat_num_train_feat, new_shape=(53531,100,1))\n",
    "cat_num_cv_feat = np.resize(cat_num_cv_feat, new_shape=(22942,100,1))\n",
    "cat_num_test_feat = np.resize(cat_num_test_feat, new_shape=(32775,100,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/fkQ8nGo.png'>\n",
    "ref: https://i.imgur.com/fkQ8nGo.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "other_input (InputLayer)        [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "essay_input (InputLayer)        [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 98, 64)       256         other_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 250, 300)     12826200    essay_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 98, 64)       256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 250, 300)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 98, 64)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)          (None, 250, 100)     160800      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 96, 128)      24704       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 25000)        0           cu_dnnlstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12288)        0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 37288)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           2386496     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          8320        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128)          512         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 516)          66564       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 516)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            1034        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,492,166\n",
      "Trainable params: 2,665,326\n",
      "Non-trainable params: 12,826,840\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "import os\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# input 1\n",
    "essay = Input(batch_shape=(None,250), name=\"essay_input\")\n",
    "x1 = Embedding(input_dim=42754,output_dim = 300,weights=[embedding_matrix(features[0],300)],trainable = False)(essay)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = CuDNNLSTM(100,return_sequences=True)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "# input 2\n",
    "other = Input(shape=(100,1),name=\"other_input\")\n",
    "x2 = Conv1D(filters=64,kernel_size=3,strides=1)(other)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "x2 = Conv1D(filters=128,kernel_size=3,strides=1)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "\n",
    "concat = concatenate([x1,x2])\n",
    "\n",
    "\n",
    "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(516,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = (Dense(2, activation='softmax'))(x)\n",
    "model = Model([essay,other], output)\n",
    "\n",
    "#To visualize, run -  tensorboard --log_dir=logs/ in command prompt\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/\".format(time))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[auc])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53531 samples, validate on 22942 samples\n",
      "Epoch 1/20\n",
      "53531/53531 [==============================] - 16s 301us/sample - loss: 0.6931 - auc: 0.5133 - val_loss: 0.5828 - val_auc: 0.5788\n",
      "Epoch 2/20\n",
      "53531/53531 [==============================] - 15s 288us/sample - loss: 0.6157 - auc: 0.5187 - val_loss: 0.5716 - val_auc: 0.5693\n",
      "Epoch 3/20\n",
      "53531/53531 [==============================] - 16s 295us/sample - loss: 0.5772 - auc: 0.5240 - val_loss: 0.5641 - val_auc: 0.5765\n",
      "Epoch 4/20\n",
      "53531/53531 [==============================] - 16s 291us/sample - loss: 0.5543 - auc: 0.5409 - val_loss: 0.5591 - val_auc: 0.5813\n",
      "Epoch 5/20\n",
      "53531/53531 [==============================] - 16s 291us/sample - loss: 0.5410 - auc: 0.5436 - val_loss: 0.5284 - val_auc: 0.5801\n",
      "Epoch 6/20\n",
      "53531/53531 [==============================] - 16s 291us/sample - loss: 0.5282 - auc: 0.5529 - val_loss: 0.5431 - val_auc: 0.5883\n",
      "Epoch 7/20\n",
      "53531/53531 [==============================] - 16s 291us/sample - loss: 0.5163 - auc: 0.5718 - val_loss: 0.5266 - val_auc: 0.6187\n",
      "Epoch 8/20\n",
      "53531/53531 [==============================] - 16s 291us/sample - loss: 0.5035 - auc: 0.6018 - val_loss: 0.5430 - val_auc: 0.6559\n",
      "Epoch 9/20\n",
      "53531/53531 [==============================] - 16s 291us/sample - loss: 0.4908 - auc: 0.6404 - val_loss: 0.4974 - val_auc: 0.6725\n",
      "Epoch 10/20\n",
      "53531/53531 [==============================] - 16s 291us/sample - loss: 0.4765 - auc: 0.6682 - val_loss: 0.5094 - val_auc: 0.6830\n",
      "Epoch 11/20\n",
      "53531/53531 [==============================] - 16s 292us/sample - loss: 0.4679 - auc: 0.6775 - val_loss: 0.5191 - val_auc: 0.6901\n",
      "Epoch 12/20\n",
      "53531/53531 [==============================] - 16s 293us/sample - loss: 0.4571 - auc: 0.6934 - val_loss: 0.4825 - val_auc: 0.6960\n",
      "Epoch 13/20\n",
      "53531/53531 [==============================] - 16s 292us/sample - loss: 0.4477 - auc: 0.7034 - val_loss: 0.4739 - val_auc: 0.7060\n",
      "Epoch 14/20\n",
      "53531/53531 [==============================] - 16s 290us/sample - loss: 0.4395 - auc: 0.7142 - val_loss: 0.4560 - val_auc: 0.7121\n",
      "Epoch 15/20\n",
      "53531/53531 [==============================] - 16s 291us/sample - loss: 0.4306 - auc: 0.7297 - val_loss: 0.4816 - val_auc: 0.7151\n",
      "Epoch 16/20\n",
      "53531/53531 [==============================] - 16s 290us/sample - loss: 0.4233 - auc: 0.7429 - val_loss: 0.4859 - val_auc: 0.7169\n",
      "Epoch 17/20\n",
      "53531/53531 [==============================] - 16s 290us/sample - loss: 0.4200 - auc: 0.7483 - val_loss: 0.4856 - val_auc: 0.7164\n",
      "Epoch 18/20\n",
      "53531/53531 [==============================] - 16s 294us/sample - loss: 0.4112 - auc: 0.7615 - val_loss: 0.4357 - val_auc: 0.7152\n",
      "Epoch 19/20\n",
      "53531/53531 [==============================] - 16s 292us/sample - loss: 0.4047 - auc: 0.7765 - val_loss: 0.4582 - val_auc: 0.7100\n",
      "Epoch 20/20\n",
      "53531/53531 [==============================] - 16s 293us/sample - loss: 0.3947 - auc: 0.8000 - val_loss: 0.4669 - val_auc: 0.7144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e97160d898>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([essay_train,cat_num_train_feat], y_train, epochs=20, verbose=1, batch_size=500, validation_data=([essay_cv,cat_num_cv_feat], y_cv), callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "# serialize model to JSON\n",
    "model.save_weights(\"model3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC 0.8657763867195336\n",
      "--------------------------------------------------\n",
      "Cv AUC 0.7141414415626062\n",
      "--------------------------------------------------\n",
      "Test AUC 0.7175532621102763\n"
     ]
    }
   ],
   "source": [
    "print(\"Train AUC\",roc_auc_score(y_train,(model.predict([essay_train,cat_num_train_feat]))))\n",
    "print(\"-\"*50)\n",
    "print(\"Cv AUC\",roc_auc_score(y_cv,model.predict([essay_cv,cat_num_cv_feat])))\n",
    "print(\"-\"*50)\n",
    "print(\"Test AUC\",roc_auc_score(y_test,model.predict([essay_test,cat_num_test_feat])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Load TENSORBOARD\\n%reload_ext tensorboard\\n# Start TENSORBOARD\\n%tensorboard --logdir logs --port=8080'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Load TENSORBOARD\n",
    "%reload_ext tensorboard\n",
    "# Start TENSORBOARD\n",
    "%tensorboard --logdir logs --port=8080\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"model_3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+--------+----------+\n",
      "|  Model  | Train AUC | Cv AUC | Test AUC |\n",
      "+---------+-----------+--------+----------+\n",
      "| Model 1 |    0.88   |  0.69  |   0.7    |\n",
      "| Model 2 |    0.52   |  0.53  |   0.52   |\n",
      "| Model 3 |    0.86   |  0.71  |   0.71   |\n",
      "+---------+-----------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "    \n",
    "x = PrettyTable([\"Model\", \"Train AUC\", \"Cv AUC\", \"Test AUC\"])\n",
    "\n",
    "x.add_row([\"Model 1\", 0.88,0.69,0.70])\n",
    "x.add_row([\"Model 2\", 0.52,0.53,0.52])\n",
    "x.add_row([\"Model 3\", 0.86,0.71,0.71])\n",
    "\n",
    "print(x.get_string(title=\"Model results\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
