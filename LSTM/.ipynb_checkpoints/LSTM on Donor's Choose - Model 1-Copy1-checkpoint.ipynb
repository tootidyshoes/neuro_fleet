{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Introduction </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required lib\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import SpatialDropout1D, LSTM, BatchNormalization,concatenate,Flatten,Embedding,Dense,Dropout,MaxPooling2D,Reshape,CuDNNLSTM\n",
    "from keras.models import Sequential\n",
    "from keras import Model,Input\n",
    "from keras.layers.convolutional import Conv2D,Conv1D\n",
    "import keras.backend as k\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.utils import compute_class_weight\n",
    "from keras.initializers import he_normal,glorot_normal\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint,LearningRateScheduler\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from IPython.display import SVG, display\n",
    "import pickle \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('glove_vectors.pickle', 'rb')      \n",
    "db = pickle.load(dbfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['mallinson'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109248, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REading the dataset\n",
    "project_data = pd.read_csv('processed_train_data.csv')\n",
    "project_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging teacher number of previouly posted projects, presence of the numerical digits, price and quantity into a single feature\n",
    "project_data.drop(['Unnamed: 0'], axis =1 , inplace = True)\n",
    "class_label = project_data['project_is_approved']\n",
    "project_data['remaining_input'] = project_data['teacher_number_of_previously_posted_projects']  +\\\n",
    "                                    project_data['presence_of_the_numerical_digits']  + \\\n",
    "                                    project_data['price'] + project_data['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['total_txt'] = project_data['project_title'] + ' ' + project_data['essay'] + ' ' + project_data['project_resource_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data.replace(to_replace=np.NaN, value= str('nan'),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
       "       'project_submitted_datetime', 'project_grade_category',\n",
       "       'project_subject_categories', 'project_subject_subcategories',\n",
       "       'project_title', 'project_essay_1', 'project_essay_2',\n",
       "       'project_essay_3', 'project_essay_4', 'project_resource_summary',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
       "       'essay', 'price', 'quantity', 'presence_of_the_numerical_digits',\n",
       "       'remaining_input', 'total_txt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = project_data.columns\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['id','teacher_id','project_submitted_datetime','project_title','project_essay_1', 'project_essay_2',\n",
    "       'project_essay_3', 'project_essay_4','project_resource_summary',\n",
    "       'teacher_number_of_previously_posted_projects', 'project_is_approved','price', 'quantity',\n",
    "        'presence_of_the_numerical_digits','essay']\n",
    "\n",
    "project_data.drop(labels=col,axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = project_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['teacher_prefix', 'school_state', 'project_grade_category',\n",
    "       'project_subject_categories', 'project_subject_subcategories','total_txt',\n",
    "       'remaining_input']\n",
    "project_data = project_data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_ranking(dataframe):\n",
    "    col_names = dataframe.columns\n",
    "    features = []\n",
    "    #performing train test split\n",
    "    train,test,y_train,y_test = train_test_split(dataframe, class_label , stratify = class_label, train_size = 0.7)\n",
    "\n",
    "    train,cv,y_train,y_cv = train_test_split(train,y_train,stratify = y_train,train_size = 0.8)\n",
    "    for col in col_names[:6]:\n",
    "        print(col)\n",
    "        bag_of_words = CountVectorizer(lowercase= False)\n",
    "        bow_words = bag_of_words.fit_transform(train[col])\n",
    "        print(bow_words.shape)\n",
    "        \n",
    "        #Lets now store the document term matrix in a dictionary.\n",
    "        freqs = bow_words.sum(axis=0).A1\n",
    "        index = freqs.argsort()\n",
    "        words = bag_of_words.get_feature_names()\n",
    "        \n",
    "        \n",
    "\n",
    "        # Assigning Rank to each word based on its freq of occurance. Word with highest freq is assigned rank 1 \n",
    "        word_rank = dict()\n",
    "        rank = 1\n",
    "        for i in index[::-1]:\n",
    "            k = words[i]\n",
    "            word_rank[k] = rank\n",
    "            rank+=1\n",
    "        features.append(word_rank)\n",
    "\n",
    "        #Every word in each review is replaced by its rank\n",
    "        rank = [] # list of all the review with words replaced with rank\n",
    "        for sent in train[col].values:\n",
    "            txt_row = []\n",
    "            for word in sent.split():\n",
    "                if word in word_rank.keys():\n",
    "                    txt_row.append(word_rank[word])\n",
    "                else:\n",
    "                    pass\n",
    "            rank.append(txt_row)\n",
    "        \n",
    "        train[col] = rank\n",
    "        \n",
    "        rank = [] # list of all the review with words replaced with rank\n",
    "        for sent in test[col].values:\n",
    "            txt_row = []\n",
    "            for word in sent.split():\n",
    "                if word in word_rank.keys():\n",
    "                    txt_row.append(word_rank[word])\n",
    "                else:\n",
    "                    pass\n",
    "            rank.append(txt_row)\n",
    "        \n",
    "        test[col] = rank\n",
    "        \n",
    "        rank = [] # list of all the review with words replaced with rank\n",
    "        for sent in cv[col].values:\n",
    "            txt_row = []\n",
    "            for word in sent.split():\n",
    "                if word in word_rank.keys():\n",
    "                    txt_row.append(word_rank[word])\n",
    "                else:\n",
    "                    pass\n",
    "            rank.append(txt_row)\n",
    "        \n",
    "        cv[col] = rank\n",
    "    return train,test,cv,y_train,y_test,y_cv,features\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher_prefix\n",
      "(61178, 5)\n",
      "school_state\n",
      "(61178, 51)\n",
      "project_grade_category\n",
      "(61178, 4)\n",
      "project_subject_categories\n",
      "(61178, 51)\n",
      "project_subject_subcategories\n",
      "(61178, 387)\n",
      "total_txt\n",
      "(61178, 56905)\n"
     ]
    }
   ],
   "source": [
    "train,test,cv,y_train,y_test,y_cv,feature_names = word_ranking(project_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Train dataset:  61178\n",
      "Shape of the Test dataset:  32775\n",
      "Shape of the cv dataset: 15295\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the Train dataset: \", train.shape[0])\n",
    "print(\"Shape of the Test dataset: \", test.shape[0])\n",
    "print(\"Shape of the cv dataset:\", cv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting class labels to categorical variables\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_cv = to_categorical(y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_wght = compute_class_weight(\"balanced\", classes= np.unique(class_label),y=class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.30214001, 0.58921753])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_wght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'literacy': 1,\n",
       " 'literacy_mathematics': 2,\n",
       " 'literature_writing_mathematics': 3,\n",
       " 'literacy_literature_writing': 4,\n",
       " 'mathematics': 5,\n",
       " 'literature_writing': 6,\n",
       " 'specialneeds': 7,\n",
       " 'health_wellness': 8,\n",
       " 'appliedsciences_mathematics': 9,\n",
       " 'appliedsciences': 10,\n",
       " 'literacy_specialneeds': 11,\n",
       " 'visualarts': 12,\n",
       " 'gym_fitness_health_wellness': 13,\n",
       " 'esl_literacy': 14,\n",
       " 'music': 15,\n",
       " 'warmth_care_hunger': 16,\n",
       " 'literature_writing_specialneeds': 17,\n",
       " 'health_wellness_specialneeds': 18,\n",
       " 'mathematics_specialneeds': 19,\n",
       " 'gym_fitness': 20,\n",
       " 'environmentalscience': 21,\n",
       " 'teamsports': 22,\n",
       " 'music_performingarts': 23,\n",
       " 'appliedsciences_environmentalscience': 24,\n",
       " 'environmentalscience_health_lifescience': 25,\n",
       " 'earlydevelopment': 26,\n",
       " 'other': 27,\n",
       " 'environmentalscience_mathematics': 28,\n",
       " 'health_lifescience': 29,\n",
       " 'health_wellness_nutritioneducation': 30,\n",
       " 'earlydevelopment_specialneeds': 31,\n",
       " 'literature_writing_visualarts': 32,\n",
       " 'earlydevelopment_literacy': 33,\n",
       " 'esl_literature_writing': 34,\n",
       " 'history_geography_literature_writing': 35,\n",
       " 'literacy_visualarts': 36,\n",
       " 'appliedsciences_visualarts': 37,\n",
       " 'gym_fitness_teamsports': 38,\n",
       " 'appliedsciences_health_lifescience': 39,\n",
       " 'appliedsciences_literacy': 40,\n",
       " 'history_geography': 41,\n",
       " 'history_geography_literacy': 42,\n",
       " 'health_lifescience_mathematics': 43,\n",
       " 'mathematics_visualarts': 44,\n",
       " 'health_wellness_literacy': 45,\n",
       " 'environmentalscience_literacy': 46,\n",
       " 'appliedsciences_literature_writing': 47,\n",
       " 'esl': 48,\n",
       " 'college_careerprep': 49,\n",
       " 'literacy_socialsciences': 50,\n",
       " 'appliedsciences_specialneeds': 51,\n",
       " 'performingarts': 52,\n",
       " 'appliedsciences_college_careerprep': 53,\n",
       " 'foreignlanguages': 54,\n",
       " 'charactereducation': 55,\n",
       " 'literature_writing_socialsciences': 56,\n",
       " 'charactereducation_literacy': 57,\n",
       " 'earlydevelopment_mathematics': 58,\n",
       " 'health_wellness_teamsports': 59,\n",
       " 'health_lifescience_literacy': 60,\n",
       " 'history_geography_socialsciences': 61,\n",
       " 'environmentalscience_literature_writing': 62,\n",
       " 'other_specialneeds': 63,\n",
       " 'college_careerprep_mathematics': 64,\n",
       " 'earlydevelopment_health_wellness': 65,\n",
       " 'specialneeds_visualarts': 66,\n",
       " 'esl_mathematics': 67,\n",
       " 'health_wellness_literature_writing': 68,\n",
       " 'college_careerprep_literature_writing': 69,\n",
       " 'nutritioneducation': 70,\n",
       " 'college_careerprep_literacy': 71,\n",
       " 'civics_government_history_geography': 72,\n",
       " 'earlydevelopment_literature_writing': 73,\n",
       " 'health_wellness_mathematics': 74,\n",
       " 'environmentalscience_visualarts': 75,\n",
       " 'foreignlanguages_literacy': 76,\n",
       " 'socialsciences': 77,\n",
       " 'esl_specialneeds': 78,\n",
       " 'history_geography_visualarts': 79,\n",
       " 'charactereducation_specialneeds': 80,\n",
       " 'health_wellness_other': 81,\n",
       " 'health_lifescience_literature_writing': 82,\n",
       " 'literacy_parentinvolvement': 83,\n",
       " 'earlydevelopment_visualarts': 84,\n",
       " 'charactereducation_literature_writing': 85,\n",
       " 'health_lifescience_health_wellness': 86,\n",
       " 'gym_fitness_specialneeds': 87,\n",
       " 'literacy_other': 88,\n",
       " 'environmentalscience_history_geography': 89,\n",
       " 'charactereducation_earlydevelopment': 90,\n",
       " 'earlydevelopment_other': 91,\n",
       " 'appliedsciences_earlydevelopment': 92,\n",
       " 'financialliteracy': 93,\n",
       " 'civics_government_literacy': 94,\n",
       " 'environmentalscience_specialneeds': 95,\n",
       " 'health_lifescience_specialneeds': 96,\n",
       " 'financialliteracy_mathematics': 97,\n",
       " 'appliedsciences_extracurricular': 98,\n",
       " 'literacy_music': 99,\n",
       " 'appliedsciences_other': 100,\n",
       " 'charactereducation_college_careerprep': 101,\n",
       " 'college_careerprep_specialneeds': 102,\n",
       " 'college_careerprep_visualarts': 103,\n",
       " 'literacy_performingarts': 104,\n",
       " 'history_geography_specialneeds': 105,\n",
       " 'music_specialneeds': 106,\n",
       " 'charactereducation_health_wellness': 107,\n",
       " 'charactereducation_mathematics': 108,\n",
       " 'literature_writing_other': 109,\n",
       " 'literature_writing_performingarts': 110,\n",
       " 'extracurricular': 111,\n",
       " 'charactereducation_other': 112,\n",
       " 'extracurricular_visualarts': 113,\n",
       " 'history_geography_mathematics': 114,\n",
       " 'health_lifescience_visualarts': 115,\n",
       " 'performingarts_visualarts': 116,\n",
       " 'mathematics_other': 117,\n",
       " 'college_careerprep_other': 118,\n",
       " 'foreignlanguages_literature_writing': 119,\n",
       " 'appliedsciences_history_geography': 120,\n",
       " 'esl_earlydevelopment': 121,\n",
       " 'mathematics_socialsciences': 122,\n",
       " 'civics_government': 123,\n",
       " 'mathematics_parentinvolvement': 124,\n",
       " 'health_lifescience_history_geography': 125,\n",
       " 'civics_government_literature_writing': 126,\n",
       " 'appliedsciences_esl': 127,\n",
       " 'environmentalscience_socialsciences': 128,\n",
       " 'civics_government_socialsciences': 129,\n",
       " 'socialsciences_specialneeds': 130,\n",
       " 'economics_financialliteracy': 131,\n",
       " 'literature_writing_parentinvolvement': 132,\n",
       " 'appliedsciences_music': 133,\n",
       " 'appliedsciences_parentinvolvement': 134,\n",
       " 'health_lifescience_socialsciences': 135,\n",
       " 'charactereducation_visualarts': 136,\n",
       " 'mathematics_music': 137,\n",
       " 'appliedsciences_socialsciences': 138,\n",
       " 'communityservice': 139,\n",
       " 'gym_fitness_nutritioneducation': 140,\n",
       " 'extracurricular_mathematics': 141,\n",
       " 'health_lifescience_nutritioneducation': 142,\n",
       " 'socialsciences_visualarts': 143,\n",
       " 'charactereducation_extracurricular': 144,\n",
       " 'other_visualarts': 145,\n",
       " 'appliedsciences_charactereducation': 146,\n",
       " 'music_visualarts': 147,\n",
       " 'earlydevelopment_environmentalscience': 148,\n",
       " 'appliedsciences_health_wellness': 149,\n",
       " 'esl_visualarts': 150,\n",
       " 'financialliteracy_specialneeds': 151,\n",
       " 'environmentalscience_health_wellness': 152,\n",
       " 'esl_foreignlanguages': 153,\n",
       " 'charactereducation_communityservice': 154,\n",
       " 'esl_environmentalscience': 155,\n",
       " 'college_careerprep_health_lifescience': 156,\n",
       " 'health_wellness_visualarts': 157,\n",
       " 'extracurricular_literacy': 158,\n",
       " 'foreignlanguages_mathematics': 159,\n",
       " 'parentinvolvement': 160,\n",
       " 'specialneeds_teamsports': 161,\n",
       " 'esl_health_lifescience': 162,\n",
       " 'college_careerprep_extracurricular': 163,\n",
       " 'environmentalscience_nutritioneducation': 164,\n",
       " 'literature_writing_music': 165,\n",
       " 'college_careerprep_communityservice': 166,\n",
       " 'health_wellness_music': 167,\n",
       " 'extracurricular_other': 168,\n",
       " 'earlydevelopment_parentinvolvement': 169,\n",
       " 'college_careerprep_environmentalscience': 170,\n",
       " 'economics': 171,\n",
       " 'nutritioneducation_specialneeds': 172,\n",
       " 'esl_history_geography': 173,\n",
       " 'appliedsciences_performingarts': 174,\n",
       " 'gym_fitness_mathematics': 175,\n",
       " 'earlydevelopment_gym_fitness': 176,\n",
       " 'gym_fitness_literacy': 177,\n",
       " 'communityservice_environmentalscience': 178,\n",
       " 'civics_government_economics': 179,\n",
       " 'parentinvolvement_specialneeds': 180,\n",
       " 'communityservice_literature_writing': 181,\n",
       " 'communityservice_mathematics': 182,\n",
       " 'economics_history_geography': 183,\n",
       " 'communityservice_visualarts': 184,\n",
       " 'extracurricular_literature_writing': 185,\n",
       " 'history_geography_music': 186,\n",
       " 'parentinvolvement_visualarts': 187,\n",
       " 'charactereducation_health_lifescience': 188,\n",
       " 'college_careerprep_earlydevelopment': 189,\n",
       " 'college_careerprep_history_geography': 190,\n",
       " 'earlydevelopment_music': 191,\n",
       " 'college_careerprep_parentinvolvement': 192,\n",
       " 'earlydevelopment_health_lifescience': 193,\n",
       " 'extracurricular_music': 194,\n",
       " 'college_careerprep_socialsciences': 195,\n",
       " 'college_careerprep_performingarts': 196,\n",
       " 'communityservice_specialneeds': 197,\n",
       " 'extracurricular_specialneeds': 198,\n",
       " 'charactereducation_parentinvolvement': 199,\n",
       " 'charactereducation_music': 200,\n",
       " 'civics_government_environmentalscience': 201,\n",
       " 'health_wellness_warmth_care_hunger': 202,\n",
       " 'charactereducation_environmentalscience': 203,\n",
       " 'performingarts_specialneeds': 204,\n",
       " 'esl_health_wellness': 205,\n",
       " 'college_careerprep_health_wellness': 206,\n",
       " 'esl_socialsciences': 207,\n",
       " 'extracurricular_performingarts': 208,\n",
       " 'economics_mathematics': 209,\n",
       " 'charactereducation_teamsports': 210,\n",
       " 'earlydevelopment_performingarts': 211,\n",
       " 'extracurricular_teamsports': 212,\n",
       " 'appliedsciences_communityservice': 213,\n",
       " 'esl_performingarts': 214,\n",
       " 'foreignlanguages_history_geography': 215,\n",
       " 'specialneeds_warmth_care_hunger': 216,\n",
       " 'gym_fitness_music': 217,\n",
       " 'esl_other': 218,\n",
       " 'foreignlanguages_specialneeds': 219,\n",
       " 'charactereducation_esl': 220,\n",
       " 'charactereducation_socialsciences': 221,\n",
       " 'gym_fitness_literature_writing': 222,\n",
       " 'college_careerprep_foreignlanguages': 223,\n",
       " 'financialliteracy_literacy': 224,\n",
       " 'health_wellness_history_geography': 225,\n",
       " 'gym_fitness_visualarts': 226,\n",
       " 'history_geography_performingarts': 227,\n",
       " 'communityservice_extracurricular': 228,\n",
       " 'mathematics_performingarts': 229,\n",
       " 'communityservice_health_wellness': 230,\n",
       " 'college_careerprep_financialliteracy': 231,\n",
       " 'communityservice_literacy': 232,\n",
       " 'health_wellness_performingarts': 233,\n",
       " 'civics_government_health_lifescience': 234,\n",
       " 'financialliteracy_literature_writing': 235,\n",
       " 'economics_socialsciences': 236,\n",
       " 'extracurricular_health_wellness': 237,\n",
       " 'communityservice_health_lifescience': 238,\n",
       " 'other_parentinvolvement': 239,\n",
       " 'appliedsciences_gym_fitness': 240,\n",
       " 'environmentalscience_parentinvolvement': 241,\n",
       " 'appliedsciences_civics_government': 242,\n",
       " 'civics_government_specialneeds': 243,\n",
       " 'college_careerprep_music': 244,\n",
       " 'gym_fitness_health_lifescience': 245,\n",
       " 'earlydevelopment_extracurricular': 246,\n",
       " 'foreignlanguages_visualarts': 247,\n",
       " 'college_careerprep_esl': 248,\n",
       " 'performingarts_socialsciences': 249,\n",
       " 'civics_government_financialliteracy': 250,\n",
       " 'health_lifescience_parentinvolvement': 251,\n",
       " 'nutritioneducation_teamsports': 252,\n",
       " 'civics_government_college_careerprep': 253,\n",
       " 'music_teamsports': 254,\n",
       " 'health_wellness_socialsciences': 255,\n",
       " 'esl_music': 256,\n",
       " 'mathematics_nutritioneducation': 257,\n",
       " 'college_careerprep_nutritioneducation': 258,\n",
       " 'communityservice_other': 259,\n",
       " 'environmentalscience_music': 260,\n",
       " 'communityservice_socialsciences': 261,\n",
       " 'mathematics_teamsports': 262,\n",
       " 'esl_parentinvolvement': 263,\n",
       " 'civics_government_mathematics': 264,\n",
       " 'environmentalscience_extracurricular': 265,\n",
       " 'health_lifescience_other': 266,\n",
       " 'literacy_teamsports': 267,\n",
       " 'economics_literacy': 268,\n",
       " 'gym_fitness_performingarts': 269,\n",
       " 'civics_government_communityservice': 270,\n",
       " 'performingarts_teamsports': 271,\n",
       " 'charactereducation_performingarts': 272,\n",
       " 'history_geography_other': 273,\n",
       " 'foreignlanguages_health_wellness': 274,\n",
       " 'civics_government_visualarts': 275,\n",
       " 'literature_writing_teamsports': 276,\n",
       " 'gym_fitness_other': 277,\n",
       " 'environmentalscience_other': 278,\n",
       " 'earlydevelopment_nutritioneducation': 279,\n",
       " 'economics_visualarts': 280,\n",
       " 'college_careerprep_economics': 281,\n",
       " 'music_other': 282,\n",
       " 'health_lifescience_music': 283,\n",
       " 'extracurricular_nutritioneducation': 284,\n",
       " 'earlydevelopment_socialsciences': 285,\n",
       " 'nutritioneducation_other': 286,\n",
       " 'appliedsciences_teamsports': 287,\n",
       " 'teamsports_visualarts': 288,\n",
       " 'civics_government_performingarts': 289,\n",
       " 'nutritioneducation_visualarts': 290,\n",
       " 'health_lifescience_teamsports': 291,\n",
       " 'extracurricular_health_lifescience': 292,\n",
       " 'literacy_nutritioneducation': 293,\n",
       " 'environmentalscience_financialliteracy': 294,\n",
       " 'foreignlanguages_other': 295,\n",
       " 'extracurricular_gym_fitness': 296,\n",
       " 'charactereducation_financialliteracy': 297,\n",
       " 'charactereducation_foreignlanguages': 298,\n",
       " 'charactereducation_gym_fitness': 299,\n",
       " 'literacy_warmth_care_hunger': 300,\n",
       " 'communityservice_parentinvolvement': 301,\n",
       " 'extracurricular_parentinvolvement': 302,\n",
       " 'economics_environmentalscience': 303,\n",
       " 'environmentalscience_gym_fitness': 304,\n",
       " 'civics_government_esl': 305,\n",
       " 'esl_nutritioneducation': 306,\n",
       " 'health_lifescience_warmth_care_hunger': 307,\n",
       " 'economics_specialneeds': 308,\n",
       " 'foreignlanguages_health_lifescience': 309,\n",
       " 'appliedsciences_financialliteracy': 310,\n",
       " 'financialliteracy_visualarts': 311,\n",
       " 'communityservice_earlydevelopment': 312,\n",
       " 'financialliteracy_health_lifescience': 313,\n",
       " 'environmentalscience_performingarts': 314,\n",
       " 'environmentalscience_warmth_care_hunger': 315,\n",
       " 'financialliteracy_history_geography': 316,\n",
       " 'esl_financialliteracy': 317,\n",
       " 'foreignlanguages_music': 318,\n",
       " 'foreignlanguages_performingarts': 319,\n",
       " 'esl_extracurricular': 320,\n",
       " 'other_teamsports': 321,\n",
       " 'earlydevelopment_financialliteracy': 322,\n",
       " 'appliedsciences_foreignlanguages': 323,\n",
       " 'parentinvolvement_performingarts': 324,\n",
       " 'charactereducation_economics': 325,\n",
       " 'parentinvolvement_socialsciences': 326,\n",
       " 'charactereducation_history_geography': 327,\n",
       " 'other_socialsciences': 328,\n",
       " 'charactereducation_nutritioneducation': 329,\n",
       " 'literature_writing_warmth_care_hunger': 330,\n",
       " 'music_socialsciences': 331,\n",
       " 'environmentalscience_foreignlanguages': 332,\n",
       " 'charactereducation_civics_government': 333,\n",
       " 'nutritioneducation_warmth_care_hunger': 334,\n",
       " 'appliedsciences_nutritioneducation': 335,\n",
       " 'esl_gym_fitness': 336,\n",
       " 'music_parentinvolvement': 337,\n",
       " 'economics_literature_writing': 338,\n",
       " 'extracurricular_foreignlanguages': 339,\n",
       " 'health_lifescience_performingarts': 340,\n",
       " 'earlydevelopment_warmth_care_hunger': 341,\n",
       " 'financialliteracy_socialsciences': 342,\n",
       " 'financialliteracy_other': 343,\n",
       " 'earlydevelopment_history_geography': 344,\n",
       " 'health_wellness_parentinvolvement': 345,\n",
       " 'communityservice_economics': 346,\n",
       " 'charactereducation_warmth_care_hunger': 347,\n",
       " 'earlydevelopment_foreignlanguages': 348,\n",
       " 'communityservice_esl': 349,\n",
       " 'extracurricular_history_geography': 350,\n",
       " 'gym_fitness_history_geography': 351,\n",
       " 'communityservice_history_geography': 352,\n",
       " 'extracurricular_socialsciences': 353,\n",
       " 'nutritioneducation_socialsciences': 354,\n",
       " 'financialliteracy_health_wellness': 355,\n",
       " 'economics_other': 356,\n",
       " 'foreignlanguages_socialsciences': 357,\n",
       " 'financialliteracy_performingarts': 358,\n",
       " 'college_careerprep_gym_fitness': 359,\n",
       " 'other_performingarts': 360,\n",
       " 'appliedsciences_economics': 361,\n",
       " 'other_warmth_care_hunger': 362,\n",
       " 'foreignlanguages_gym_fitness': 363,\n",
       " 'communityservice_performingarts': 364,\n",
       " 'parentinvolvement_warmth_care_hunger': 365,\n",
       " 'gym_fitness_parentinvolvement': 366,\n",
       " 'gym_fitness_warmth_care_hunger': 367,\n",
       " 'financialliteracy_foreignlanguages': 368,\n",
       " 'gym_fitness_socialsciences': 369,\n",
       " 'history_geography_warmth_care_hunger': 370,\n",
       " 'socialsciences_teamsports': 371,\n",
       " 'history_geography_parentinvolvement': 372,\n",
       " 'economics_nutritioneducation': 373,\n",
       " 'economics_music': 374,\n",
       " 'extracurricular_financialliteracy': 375,\n",
       " 'communityservice_music': 376,\n",
       " 'literature_writing_nutritioneducation': 377,\n",
       " 'visualarts_warmth_care_hunger': 378,\n",
       " 'economics_health_lifescience': 379,\n",
       " 'economics_foreignlanguages': 380,\n",
       " 'civics_government_extracurricular': 381,\n",
       " 'civics_government_health_wellness': 382,\n",
       " 'appliedsciences_warmth_care_hunger': 383,\n",
       " 'earlydevelopment_teamsports': 384,\n",
       " 'mathematics_warmth_care_hunger': 385,\n",
       " 'history_geography_teamsports': 386,\n",
       " 'environmentalscience_teamsports': 387}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a matrix with rows as words and columns with 50 dim vectors for each word\n",
    "def embedding_mat(word_index,embedding_dim = 300):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = db.get(word)\n",
    "        if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the Text part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 250)\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0  160   73\n",
      "  692   45 1490 1716  401 1164   23    2   19 1054   91  159    5  241\n",
      "  118  167  692  217   18 1269 3701 3627    7  435   17 2333  846  217\n",
      "    2  121  351  643  936    1  136   66   89    1  705  174  559    8\n",
      "  134  459  670   29   41   34   60  134   50    7  203  201   82  132\n",
      "  692   23    5  217   91    7  209  168  324  157 1816  170  682  403\n",
      "   41   30  242  619   14    1  682  403  736    1  710   20  170   48\n",
      "   73  788  279 1526 1470  864  847  721  160   73  151  213 1496    6\n",
      "   11   60 2735  234  991  113  520 4977  336   92 1883   45  266  167\n",
      "   79 1998  160   73    5  559 3371  335   93  804   35  509  160   73\n",
      "  226    6    1   37  160   73  226   13   10    1    3  111  109  160\n",
      "   73  226   69  123    9 1450   64  480   15    4   69  173]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_review_length = 250\n",
    "X_train = pad_sequences(train['total_txt'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test = pad_sequences(test['total_txt'], maxlen=max_review_length)\n",
    "X_cv = pad_sequences(cv['total_txt'], maxlen=max_review_length)\n",
    "print(X_train.shape)\n",
    "print(X_train[256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the school state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32775, 1)\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_review_length = 1\n",
    "X_train_school_state = pad_sequences(train['school_state'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test_school_state = pad_sequences(test['school_state'], maxlen=max_review_length)\n",
    "X_cv_school_state = pad_sequences(cv['school_state'], maxlen=max_review_length)\n",
    "print(X_test_school_state.shape)\n",
    "print(X_test_school_state[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the project_grade_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 1)\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1\n",
    "X_train_project_grade = pad_sequences(train['project_grade_category'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test_project_grade = pad_sequences(test['project_grade_category'], maxlen=max_review_length)\n",
    "X_cv_project_grade = pad_sequences(cv['project_grade_category'], maxlen=max_review_length)\n",
    "print(X_train_project_grade.shape)\n",
    "print(X_train_project_grade[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the project categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 1)\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1\n",
    "X_train_project_cat = pad_sequences(train['project_subject_categories'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test_project_cat = pad_sequences(test['project_subject_categories'], maxlen=max_review_length)\n",
    "X_cv_project_cat = pad_sequences(cv['project_subject_categories'], maxlen=max_review_length)\n",
    "print(X_train_project_cat.shape)\n",
    "print(X_train_project_cat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the project subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 1)\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1\n",
    "X_train_project_subcat = pad_sequences(train['project_subject_subcategories'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test_project_subcat = pad_sequences(test['project_subject_subcategories'], maxlen=max_review_length)\n",
    "X_cv_project_subcat = pad_sequences(cv['project_subject_subcategories'], maxlen=max_review_length)\n",
    "print(X_train_project_subcat.shape)\n",
    "print(X_train_project_subcat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the teacher prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 1)\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1\n",
    "X_train_teacher_prefix = pad_sequences(train['teacher_prefix'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test_teacher_prefix = pad_sequences(test['teacher_prefix'], maxlen=max_review_length)\n",
    "X_cv_teacher_prefix = pad_sequences(cv['teacher_prefix'], maxlen=max_review_length)\n",
    "print(X_train_teacher_prefix.shape)\n",
    "print(X_test_teacher_prefix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>total_txt</th>\n",
       "      <th>remaining_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76202</th>\n",
       "      <td>[2]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[5, 1137, 284, 2520, 1, 2120, 487, 2038, 1909,...</td>\n",
       "      <td>135.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76133</th>\n",
       "      <td>[2]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[187, 310, 52, 1, 407, 93, 143, 2, 41, 32, 212...</td>\n",
       "      <td>97.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59232</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[2965, 3162, 128, 1, 419, 5, 41, 19, 9284, 138...</td>\n",
       "      <td>109.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68658</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[188, 46, 4, 124, 1586, 763, 2, 1, 1586, 300, ...</td>\n",
       "      <td>206.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55783</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[178, 2699, 2073, 68, 24, 433, 315, 24, 2699, ...</td>\n",
       "      <td>241.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      teacher_prefix school_state project_grade_category  \\\n",
       "76202            [2]          [2]                    [4]   \n",
       "76133            [2]          [1]                    [2]   \n",
       "59232            [1]         [27]                    [3]   \n",
       "68658            [1]          [1]                    [2]   \n",
       "55783            [1]          [6]                    [1]   \n",
       "\n",
       "      project_subject_categories project_subject_subcategories  \\\n",
       "76202                        [2]                           [5]   \n",
       "76133                        [1]                          [34]   \n",
       "59232                        [2]                          [10]   \n",
       "68658                        [3]                           [3]   \n",
       "55783                        [1]                           [1]   \n",
       "\n",
       "                                               total_txt  remaining_input  \n",
       "76202  [5, 1137, 284, 2520, 1, 2120, 487, 2038, 1909,...           135.99  \n",
       "76133  [187, 310, 52, 1, 407, 93, 143, 2, 41, 32, 212...            97.44  \n",
       "59232  [2965, 3162, 128, 1, 419, 5, 41, 19, 9284, 138...           109.15  \n",
       "68658  [188, 46, 4, 124, 1586, 763, 2, 1, 1586, 300, ...           206.00  \n",
       "55783  [178, 2699, 2073, 68, 24, 433, 315, 24, 2699, ...           241.99  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Models\n",
    "\n",
    " ### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC score\n",
    "def auc( y_true, y_pred ) :\n",
    "    score = tf.py_func( lambda y_true, y_pred : roc_auc_score( y_true, y_pred, average='macro', sample_weight=None).astype('float32'),\n",
    "                        [y_true, y_pred],\n",
    "                        'float32',\n",
    "                        stateful=True,\n",
    "                        name='sklearnAUC' )\n",
    "    return score\n",
    "\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 1e-6\n",
    "    epochs_drop = 1\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_51 (InputLayer)           (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_44 (Embedding)        (None, 250, 300)     17071800    input_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 250, 300)     0           embedding_44[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_52 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_53 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_54 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_55 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_56 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_8 (CuDNNLSTM)        (None, 250, 128)     220160      spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_45 (Embedding)        (None, 1, 2)         104         input_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_46 (Embedding)        (None, 1, 2)         10          input_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_47 (Embedding)        (None, 1, 2)         100         input_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_48 (Embedding)        (None, 1, 50)        19250       input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_49 (Embedding)        (None, 1, 5)         30          input_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_57 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_43 (Flatten)            (None, 32000)        0           cu_dnnlstm_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_44 (Flatten)            (None, 2)            0           embedding_45[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)            (None, 2)            0           embedding_46[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)            (None, 2)            0           embedding_47[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)            (None, 50)           0           embedding_48[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_48 (Flatten)            (None, 5)            0           embedding_49[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 16)           32          input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32077)        0           flatten_43[0][0]                 \n",
      "                                                                 flatten_44[0][0]                 \n",
      "                                                                 flatten_45[0][0]                 \n",
      "                                                                 flatten_46[0][0]                 \n",
      "                                                                 flatten_47[0][0]                 \n",
      "                                                                 flatten_48[0][0]                 \n",
      "                                                                 dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 128)          4105984     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 128)          0           dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 64)           8256        dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 64)           0           dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64)           256         dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 32)           2080        batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 32)           0           dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 2)            66          dropout_24[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,428,128\n",
      "Trainable params: 4,356,200\n",
      "Non-trainable params: 17,071,928\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#input 1\n",
    "input1 = Input(shape=(250,))\n",
    "x1 = Embedding(input_dim=56906,output_dim= 300,weights=[embedding_mat(feature_names[5])],trainable=False)(input1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = CuDNNLSTM(128,return_sequences=True)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "#input 2\n",
    "input2 = Input(shape=(1,))\n",
    "x2 = Embedding(input_dim= 52,output_dim= 2)(input2)\n",
    "#x2 = SpatialDropout1D(0.3)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "#input 3\n",
    "input3 = Input(shape=(1,))\n",
    "x3 = Embedding(input_dim= 5,output_dim= 2)(input3)\n",
    "#x3 = SpatialDropout1D(0.3)(x3)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "#input 4\n",
    "input4 = Input(shape=(1,))\n",
    "x4 = Embedding(input_dim=50,output_dim= 2)(input4)\n",
    "#x4 = SpatialDropout1D(0.3)(x4)\n",
    "x4 = Flatten()(x4)\n",
    "\n",
    "#input 5\n",
    "input5 = Input(shape=(1,))\n",
    "x5 = Embedding(input_dim= 385,output_dim= 50)(input5)\n",
    "#x5 = SpatialDropout1D(0.3)(x5)\n",
    "x5 = Flatten()(x5)\n",
    "\n",
    "#input 6\n",
    "input6 = Input(shape=(1,))\n",
    "x6 = Embedding(input_dim= 6,output_dim= 5)(input6)\n",
    "#x6 = SpatialDropout1D(0.3)(x6)\n",
    "x6 = Flatten()(x6)\n",
    "\n",
    "#input 7\n",
    "input7 = Input(shape=(1,))\n",
    "x7 = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(input7)\n",
    "#x7 = Flatten()(x7)\n",
    "#merging all the inputs \n",
    "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
    "#x = BatchNormalization()(concat)\n",
    "\n",
    "x = Dense(128,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(2, activation = 'softmax')(x)\n",
    " \n",
    "# create model with seven inputs\n",
    "model = Model([input1,input2,input3,input4,input5,input6,input7], output)\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0006,decay = 1e-4),metrics=[auc])\n",
    "#lrate = LearningRateScheduler(step_decay)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 61178 samples, validate on 15295 samples\n",
      "Epoch 1/20\n",
      "61178/61178 [==============================] - 58s 942us/step - loss: 0.5711 - auc: 0.5193 - val_loss: 0.4844 - val_auc: 0.5926\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.59256, saving model to weights_copy.best.hdf5\n",
      "Epoch 2/20\n",
      "61178/61178 [==============================] - 57s 926us/step - loss: 0.4778 - auc: 0.5759 - val_loss: 0.4610 - val_auc: 0.6570\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.59256 to 0.65700, saving model to weights_copy.best.hdf5\n",
      "Epoch 3/20\n",
      "61178/61178 [==============================] - 57s 926us/step - loss: 0.4460 - auc: 0.6337 - val_loss: 0.4457 - val_auc: 0.6575\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.65700 to 0.65752, saving model to weights_copy.best.hdf5\n",
      "Epoch 4/20\n",
      "61178/61178 [==============================] - 61s 1000us/step - loss: 0.4290 - auc: 0.6665 - val_loss: 0.4152 - val_auc: 0.7094\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.65752 to 0.70942, saving model to weights_copy.best.hdf5\n",
      "Epoch 5/20\n",
      "61178/61178 [==============================] - 49s 808us/step - loss: 0.4188 - auc: 0.6868 - val_loss: 0.4162 - val_auc: 0.7183\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.70942 to 0.71825, saving model to weights_copy.best.hdf5\n",
      "Epoch 6/20\n",
      "61178/61178 [==============================] - 26s 432us/step - loss: 0.4103 - auc: 0.7038 - val_loss: 0.4003 - val_auc: 0.7311\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.71825 to 0.73111, saving model to weights_copy.best.hdf5\n",
      "Epoch 7/20\n",
      "61178/61178 [==============================] - 27s 434us/step - loss: 0.4074 - auc: 0.7059 - val_loss: 0.3988 - val_auc: 0.7370\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.73111 to 0.73698, saving model to weights_copy.best.hdf5\n",
      "Epoch 8/20\n",
      "61178/61178 [==============================] - 27s 437us/step - loss: 0.4011 - auc: 0.7193 - val_loss: 0.3941 - val_auc: 0.7427: 6s - loss\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.73698 to 0.74265, saving model to weights_copy.best.hdf5\n",
      "Epoch 9/20\n",
      "61178/61178 [==============================] - 27s 438us/step - loss: 0.4017 - auc: 0.7212 - val_loss: 0.3932 - val_auc: 0.7458\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.74265 to 0.74579, saving model to weights_copy.best.hdf5\n",
      "Epoch 10/20\n",
      "61178/61178 [==============================] - 27s 439us/step - loss: 0.3938 - auc: 0.7330 - val_loss: 0.3883 - val_auc: 0.7497 - loss: 0.3949 - auc: 0.72 - ETA:  - ETA: 11s - loss: 0.3943 - ETA: 10s - loss: 0.3945   - ETA: 5s - loss:  - \n",
      "\n",
      "Epoch 00010: val_auc improved from 0.74579 to 0.74966, saving model to weights_copy.best.hdf5\n",
      "Epoch 11/20\n",
      "61178/61178 [==============================] - 27s 439us/step - loss: 0.3913 - auc: 0.7398 - val_loss: 0.3855 - val_auc: 0.7567\n",
      "\n",
      "Epoch 00011: val_auc improved from 0.74966 to 0.75673, saving model to weights_copy.best.hdf5\n",
      "Epoch 12/20\n",
      "61178/61178 [==============================] - 27s 440us/step - loss: 0.3865 - auc: 0.7453 - val_loss: 0.3914 - val_auc: 0.7579 0\n",
      "\n",
      "Epoch 00012: val_auc improved from 0.75673 to 0.75792, saving model to weights_copy.best.hdf5\n",
      "Epoch 13/20\n",
      "61178/61178 [==============================] - 27s 441us/step - loss: 0.3840 - auc: 0.7526 - val_loss: 0.3830 - val_auc: 0.7560 - loss: 0.3842 - auc: 0.75 - ETA: 0s - loss: 0.3845 - auc: 0.75 - ETA: 0s - loss: 0.3843 - auc: \n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.75792\n",
      "Epoch 14/20\n",
      "61178/61178 [==============================] - 27s 441us/step - loss: 0.3819 - auc: 0.7519 - val_loss: 0.3817 - val_auc: 0.7585\n",
      "\n",
      "Epoch 00014: val_auc improved from 0.75792 to 0.75851, saving model to weights_copy.best.hdf5\n",
      "Epoch 15/20\n",
      "61178/61178 [==============================] - 27s 442us/step - loss: 0.3787 - auc: 0.7586 - val_loss: 0.3786 - val_auc: 0.7602\n",
      "\n",
      "Epoch 00015: val_auc improved from 0.75851 to 0.76025, saving model to weights_copy.best.hdf5\n",
      "Epoch 16/20\n",
      "61178/61178 [==============================] - 27s 445us/step - loss: 0.3762 - auc: 0.7654 - val_loss: 0.3778 - val_auc: 0.7633\n",
      "\n",
      "Epoch 00016: val_auc improved from 0.76025 to 0.76327, saving model to weights_copy.best.hdf5\n",
      "Epoch 17/20\n",
      "61178/61178 [==============================] - 27s 442us/step - loss: 0.3742 - auc: 0.7669 - val_loss: 0.3778 - val_auc: 0.7615\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.76327\n",
      "Epoch 18/20\n",
      "61178/61178 [==============================] - 27s 442us/step - loss: 0.3712 - auc: 0.7714 - val_loss: 0.3761 - val_auc: 0.7617\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.76327\n",
      "Epoch 19/20\n",
      "61178/61178 [==============================] - 27s 443us/step - loss: 0.3685 - auc: 0.7762 - val_loss: 0.3757 - val_auc: 0.7629\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.76327\n",
      "Epoch 20/20\n",
      "61178/61178 [==============================] - 27s 444us/step - loss: 0.3657 - auc: 0.7792 - val_loss: 0.3757 - val_auc: 0.7622\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.76327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244065fd898>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model fitting\n",
    "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "filepath=\"weights_copy.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint,tensorboard]\n",
    "model.fit([X_train,X_train_school_state,X_train_project_grade,X_train_project_cat,X_train_project_subcat,\n",
    "           X_train_teacher_prefix,train['remaining_input']], y_train, nb_epoch=20,verbose=1,batch_size=256,\n",
    "          validation_data=([X_cv,X_cv_school_state,X_cv_project_grade,X_cv_project_cat,X_cv_project_subcat,\n",
    "           X_cv_teacher_prefix,cv['remaining_input']]  , y_cv),callbacks =callbacks_list,class_weight = class_wght )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input 1\n",
    "input1 = Input(shape=(250,))\n",
    "x1 = Embedding(input_dim=56906,output_dim= 300,weights=[embedding_mat(feature_names[5])],trainable=False)(input1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = CuDNNLSTM(128,return_sequences=True)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "#input 2\n",
    "input2 = Input(shape=(1,))\n",
    "x2 = Embedding(input_dim= 52,output_dim= 2)(input2)\n",
    "#x2 = SpatialDropout1D(0.3)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "#input 3\n",
    "input3 = Input(shape=(1,))\n",
    "x3 = Embedding(input_dim= 5,output_dim= 2)(input3)\n",
    "#x3 = SpatialDropout1D(0.3)(x3)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "#input 4\n",
    "input4 = Input(shape=(1,))\n",
    "x4 = Embedding(input_dim=50,output_dim= 2)(input4)\n",
    "#x4 = SpatialDropout1D(0.3)(x4)\n",
    "x4 = Flatten()(x4)\n",
    "\n",
    "#input 5\n",
    "input5 = Input(shape=(1,))\n",
    "x5 = Embedding(input_dim= 385,output_dim= 50)(input5)\n",
    "#x5 = SpatialDropout1D(0.3)(x5)\n",
    "x5 = Flatten()(x5)\n",
    "\n",
    "#input 6\n",
    "input6 = Input(shape=(1,))\n",
    "x6 = Embedding(input_dim= 6,output_dim= 5)(input6)\n",
    "#x6 = SpatialDropout1D(0.3)(x6)\n",
    "x6 = Flatten()(x6)\n",
    "\n",
    "#input 7\n",
    "input7 = Input(shape=(1,))\n",
    "x7 = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(input7)\n",
    "#x7 = Flatten()(x7)\n",
    "#merging all the inputs \n",
    "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
    "#x = BatchNormalization()(concat)\n",
    "\n",
    "x = Dense(128,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(2, activation = 'softmax')(x)\n",
    " \n",
    "# create model with seven inputs\n",
    "model = Model([input1,input2,input3,input4,input5,input6,input7], output)\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0006,decay = 1e-4),metrics=[auc])\n",
    "model.load_weights(\"weights_copy.best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc for test data: 0.759\n",
      "Auc for CV data: 0.761\n",
      "Auc for train data: 0.802\n"
     ]
    }
   ],
   "source": [
    "print(\"Auc for test data: %0.3f\"%roc_auc_score(y_test,model.predict([X_test,X_test_school_state,X_test_project_grade,X_test_project_cat,X_test_project_subcat,\n",
    "           X_test_teacher_prefix,test['remaining_input']])))\n",
    "print(\"Auc for CV data: %0.3f\"%roc_auc_score(y_cv,model.predict([X_cv,X_cv_school_state,X_cv_project_grade,X_cv_project_cat,X_cv_project_subcat,\n",
    "           X_cv_teacher_prefix,cv['remaining_input']])))\n",
    "print(\"Auc for train data: %0.3f\"%roc_auc_score(y_train,model.predict([X_train,X_train_school_state,X_train_project_grade,X_train_project_cat,X_train_project_subcat,\n",
    "           X_train_teacher_prefix,train['remaining_input']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src ='model_1_epoch_auc_loss.jpg' >\n",
    "<img src = 'model_1_epoch_val_auc_loss.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
