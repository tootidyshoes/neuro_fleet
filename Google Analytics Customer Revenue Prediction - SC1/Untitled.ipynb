{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/julian3833/1-quick-start-read-csv-and-flatten-json-fields/notebook.\n",
    "json_columns = ['device', 'geoNetwork','totals', 'trafficSource']  #these 4 columns are of type jspn objects\n",
    "def load_dataframe(filename):\n",
    "    df = pd.read_csv(filename, converters={column: json.loads for column in json_columns}, \n",
    "                     dtype={'fullVisitorId': 'str'}) #loading json columns and specifying the type of fullvisitor id as string\n",
    "    \n",
    "    for column in json_columns:\n",
    "        column_as_df = json_normalize(df[column])  #normalizing json columns\n",
    "        column_as_df.columns = [f\"{column}_{subcolumn}\" for subcolumn in column_as_df.columns]  #creating subcolumns of json columns \n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)  #adding subcolumns and dropping the json columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_conv = load_dataframe('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.python.org/3/library/datetime.html\n",
    "#adding datetime column in data\n",
    "def add_date_features(df):\n",
    "    df['date'] = df['date'].astype(str)\n",
    "    df[\"date\"] = df[\"date\"].apply(lambda x : x[:4] + \"-\" + x[4:6] + \"-\" + x[6:])\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    \n",
    "    df[\"month\"]   = df['date'].dt.month  #getting month\n",
    "    df[\"day\"]     = df['date'].dt.day   #getting day\n",
    "    df[\"weekday\"] = df['date'].dt.weekday   #getting date\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_conv = add_date_features(test_data_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find constant columns\n",
    "constant_columns = [column for column in test_data_conv.columns if test_data_conv[column].nunique(dropna=False)==1]\n",
    "\n",
    "#dropping constant columns\n",
    "test_data_conv_dropped = test_data_conv.drop(columns=constant_columns)\n",
    "\n",
    "#Sorting by date to perform time based slicing\n",
    "sorted_test_data_conv_dropped = test_data_conv_dropped.sort_values(by='date',ascending=True)\n",
    "\n",
    "## non relevant columns\n",
    "non_relevant = [\"visitNumber\", \"date\", \"fullVisitorId\", \"sessionId\", \"visitId\", \"visitStartTime\"]\n",
    "\n",
    "## Drpiing non relevant columns\n",
    "test = sorted_test_data_conv_dropped.drop(columns=non_relevant)\n",
    "\n",
    "print(\"Before dropping the columns: \", test_data_conv.shape)\n",
    "print(\"After dropping the columns: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [column for column in test.columns if not column.startswith('total')]\n",
    "categorical_columns = [column for column in categorical_features_train if column not in constant_columns + non_relevant]\n",
    "\n",
    "for column in categorical_columns:\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    test_values = list(test[column].values.astype(str))\n",
    "    \n",
    "    le.fit(test_values)\n",
    "\n",
    "    test[column] = le.transform(test_values) \n",
    "    \n",
    "test['device_isMobile'] = le.transform(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling the NA values in totals column\n",
    "def normalize_numerical_columns(dataframe, isTrainDataset = True):\n",
    "    dataframe[\"totals_hits\"] = dataframe[\"totals_hits\"].astype(float)\n",
    "    #dataframe[\"totals.hits\"] = (dataframe[\"totals.hits\"] - min(dataframe[\"totals.hits\"])) / (max(dataframe[\"totals.hits\"]) - min(dataframe[\"totals.hits\"]))\n",
    "\n",
    "    dataframe[\"totals_pageviews\"] = dataframe[\"totals_pageviews\"].astype(float)\n",
    "    #dataframe[\"totals.pageviews\"] = (dataframe[\"totals.pageviews\"] - min(dataframe[\"totals.pageviews\"])) / (max(dataframe[\"totals.pageviews\"]) - min(dataframe[\"totals.pageviews\"]))\n",
    "    \n",
    "    dataframe[\"totals_bounces\"] = dataframe[\"totals_bounces\"].astype(float)\n",
    "    dataframe[\"totals_newVisits\"] = dataframe[\"totals_newVisits\"].astype(float)\n",
    "    \n",
    "    \n",
    "    if isTrainDataset:\n",
    "        dataframe[\"totals_transactionRevenue\"] = dataframe[\"totals_transactionRevenue\"].fillna(0.0)\n",
    "    return dataframe \n",
    "\n",
    "test = normalize_numerical_columns(test,isTrainDataset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.fillna(0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['mean_pageViews_per_networkDomain'] = X_test.groupby('geoNetwork_networkDomain')['totals_pageviews'].transform('mean').astype('int')\n",
    "X_test['mean_hits_per_networkDomain'] = X_test.groupby('geoNetwork_networkDomain')['totals_hits'].transform('mean').astype('int')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
