{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3TJcvfQWzzAh"
   },
   "source": [
    "## CNN on CIFAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eWqBuakAzzAj"
   },
   "source": [
    "<h3>About CIFAR dataset:</h3> \n",
    "Dataset and consists of 60,000 32x32 color images containing one of 10 object classes, with 6000 images per class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cf_RnmeEzzAk"
   },
   "source": [
    "### Assignment instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WPNnFF9dzzAl"
   },
   "source": [
    "1.  Please visit this link to access the state-of-art DenseNet code for reference - DenseNet - cifar10 notebook link\n",
    "2.  You need to create a copy of this and \"retrain\" this model to achieve 90+ test accuracy. \n",
    "3.  You cannot use Dense Layers (also called fully connected layers), or DropOut.\n",
    "4.  You MUST use Image Augmentation Techniques.\n",
    "5.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n",
    "6.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n",
    "7.  You cannot use test images for training the model.\n",
    "8.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n",
    "9.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n",
    "10. You cannot have more than 1 Million parameters in total\n",
    "11. You are free to move the code from Keras to Tensorflow, Pytorch, MXNET etc. \n",
    "12. You can use any optimization algorithm you need. \n",
    "13. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nvpuinRDzzAl"
   },
   "source": [
    "> Reference: https://arxiv.org/abs/1608.06993"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MFFUB6NSzzAm"
   },
   "source": [
    "### Labels in CIFAR-10 dataset\n",
    "<li>0: airplane</li>\n",
    "<li>1: automobile</li>\n",
    "<li>2: bird</li>\n",
    "<li>3: cat</li>\n",
    "<li>4: deer</li>\n",
    "<li>5: dog</li>\n",
    "<li>6: frog</li>\n",
    "<li>7: horse</li>\n",
    "<li>9: truck</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4UNMJm8zzAn"
   },
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5928,
     "status": "ok",
     "timestamp": 1577025310446,
     "user": {
      "displayName": "Vanshika Soni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtyF9JxznP1YRjask9-WpvFdu9lJWwZpPMm-wJcQ=s64",
      "userId": "18404784623742601191"
     },
     "user_tz": -330
    },
    "id": "wVIx_KIigxPV",
    "outputId": "0ae523c0-21cd-4f03-b929-c620dc8fce2b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage.filters import unsharp_mask\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ZpbRa6GzzAr"
   },
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9164,
     "status": "ok",
     "timestamp": 1577025313708,
     "user": {
      "displayName": "Vanshika Soni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtyF9JxznP1YRjask9-WpvFdu9lJWwZpPMm-wJcQ=s64",
      "userId": "18404784623742601191"
     },
     "user_tz": -330
    },
    "id": "mB7o3zu1g6eT",
    "outputId": "99fe5010-2fc3-42b1-b615-56eb8b927bd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR10 Data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9142,
     "status": "ok",
     "timestamp": 1577025313710,
     "user": {
      "displayName": "Vanshika Soni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtyF9JxznP1YRjask9-WpvFdu9lJWwZpPMm-wJcQ=s64",
      "userId": "18404784623742601191"
     },
     "user_tz": -330
    },
    "id": "1fHpGvHJzzAt",
    "outputId": "800ae07e-4147-4414-f6d6-f2b62e3859fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9121,
     "status": "ok",
     "timestamp": 1577025313711,
     "user": {
      "displayName": "Vanshika Soni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtyF9JxznP1YRjask9-WpvFdu9lJWwZpPMm-wJcQ=s64",
      "userId": "18404784623742601191"
     },
     "user_tz": -330
    },
    "id": "A5eT4witzzAw",
    "outputId": "9545e8ed-08ab-463e-c6eb-32ceff51c0a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9097,
     "status": "ok",
     "timestamp": 1577025313712,
     "user": {
      "displayName": "Vanshika Soni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtyF9JxznP1YRjask9-WpvFdu9lJWwZpPMm-wJcQ=s64",
      "userId": "18404784623742601191"
     },
     "user_tz": -330
    },
    "id": "Dwe2QCLqzzAx",
    "outputId": "e8db05d7-0a3d-46a0-b6d2-1519c1f7b945"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3g15AWGzzAz"
   },
   "source": [
    "### Sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9077,
     "status": "ok",
     "timestamp": 1577025313713,
     "user": {
      "displayName": "Vanshika Soni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtyF9JxznP1YRjask9-WpvFdu9lJWwZpPMm-wJcQ=s64",
      "userId": "18404784623742601191"
     },
     "user_tz": -330
    },
    "id": "M-pO1gmyzzA0",
    "outputId": "74f7a77c-4f49-4aff-d2ac-3f872a936517"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc6ee083630>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAACECAYAAADvN4zTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/41793931/plotting-images-side-by-side-using-matplotlib\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(X_train[4].reshape(32,32,3))\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(X_train[7].reshape(32,32,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OEFx5MPKzzA1"
   },
   "source": [
    "### Augmenting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10473,
     "status": "ok",
     "timestamp": 1577025315126,
     "user": {
      "displayName": "Vanshika Soni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtyF9JxznP1YRjask9-WpvFdu9lJWwZpPMm-wJcQ=s64",
      "userId": "18404784623742601191"
     },
     "user_tz": -330
    },
    "id": "Xa5Rn2IUzzA2",
    "outputId": "aff7b94c-b602-4856-8a64-367fad0f3d5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#https://keras.io/preprocessing/image/\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.5,\n",
    "    brightness_range=[0.2,1.0])\n",
    "\n",
    "\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "omLatp1MzzA4"
   },
   "source": [
    "### Defining blocks - (Dense, Transition and Output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee-sge5Kg7vr"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def denseblock(input, num_filter, dropout_rate):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same',kernel_initializer=he_normal())(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "## transition Block\n",
    "def transition(input, num_filter, dropout_rate):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same',kernel_initializer=he_normal())(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    conv = layers.Conv2D(10,(1,1), use_bias=False, padding='same')(AvgPooling)\n",
    "    last = layers.GlobalMaxPooling2D()(conv)\n",
    "    output = layers.Activation('softmax')(last)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9tp1DIx2zzA6"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnj90L2_zzA7"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 150\n",
    "l = 8\n",
    "compression = 1\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7308
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4158,
     "status": "ok",
     "timestamp": 1577025333874,
     "user": {
      "displayName": "Vanshika Soni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtyF9JxznP1YRjask9-WpvFdu9lJWwZpPMm-wJcQ=s64",
      "userId": "18404784623742601191"
     },
     "user_tz": -330
    },
    "id": "anPCpQWhhGb7",
    "outputId": "9d3c1cfa-096d-443e-daf9-64454ac3103b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 16, 16, 38)   1026        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16, 16, 38)   152         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16, 16, 38)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 38)   12996       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16, 16, 38)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 16, 76)   0           conv2d[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 76)   304         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16, 16, 76)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 38)   25992       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 38)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 114)  0           concatenate[0][0]                \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 114)  456         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16, 16, 114)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 38)   38988       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 38)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 152)  0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 152)  608         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16, 16, 152)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 38)   51984       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 16, 38)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 190)  0           concatenate_2[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 190)  760         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 190)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 38)   64980       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 38)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 228)  0           concatenate_3[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 228)  912         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 228)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 38)   77976       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 38)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 266)  0           concatenate_4[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 266)  1064        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 266)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 38)   90972       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16, 16, 38)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 16, 16, 304)  0           concatenate_5[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 304)  1216        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 304)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 38)   103968      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16, 16, 38)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 16, 16, 342)  0           concatenate_6[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 342)  1368        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 342)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 38)   12996       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16, 16, 38)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 8, 8, 38)     0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 38)     152         average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 38)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 38)     12996       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 8, 8, 38)     0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 8, 8, 76)     0           average_pooling2d[0][0]          \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 76)     304         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 76)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 38)     25992       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 8, 8, 38)     0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 8, 8, 114)    0           concatenate_8[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 114)    456         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 114)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 38)     38988       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 8, 8, 38)     0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 8, 8, 152)    0           concatenate_9[0][0]              \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 152)    608         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 152)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 38)     51984       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 8, 8, 38)     0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 8, 8, 190)    0           concatenate_10[0][0]             \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 190)    760         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 190)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 38)     64980       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 8, 8, 38)     0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 8, 8, 228)    0           concatenate_11[0][0]             \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 228)    912         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 228)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 38)     77976       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 8, 8, 38)     0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 8, 8, 266)    0           concatenate_12[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 266)    1064        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 266)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 38)     90972       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 8, 8, 38)     0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 8, 8, 304)    0           concatenate_13[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 304)    1216        concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 304)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 38)     103968      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 8, 8, 38)     0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 8, 8, 342)    0           concatenate_14[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 342)    1368        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 342)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 38)     12996       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 8, 8, 38)     0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 4, 4, 38)     0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 4, 38)     152         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 38)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 38)     12996       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 4, 4, 38)     0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 4, 4, 76)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 4, 76)     304         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 4, 76)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 38)     25992       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 4, 4, 38)     0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 4, 4, 114)    0           concatenate_16[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 4, 4, 114)    456         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 4, 4, 114)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 4, 4, 38)     38988       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 4, 4, 38)     0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 4, 4, 152)    0           concatenate_17[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 4, 4, 152)    608         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 4, 4, 152)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 4, 4, 38)     51984       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 4, 4, 38)     0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 4, 4, 190)    0           concatenate_18[0][0]             \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 4, 4, 190)    760         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 4, 4, 190)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 4, 4, 38)     64980       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 4, 4, 38)     0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 4, 4, 228)    0           concatenate_19[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 4, 4, 228)    912         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 4, 4, 228)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 4, 4, 38)     77976       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 4, 4, 38)     0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 4, 4, 266)    0           concatenate_20[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 4, 4, 266)    1064        concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 4, 4, 266)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 4, 4, 38)     90972       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 4, 4, 38)     0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 4, 4, 304)    0           concatenate_21[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 4, 4, 304)    1216        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 4, 4, 304)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 4, 4, 38)     103968      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 4, 4, 38)     0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 4, 4, 342)    0           concatenate_22[0][0]             \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 4, 4, 342)    1368        concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 4, 4, 342)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 4, 4, 38)     12996       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 4, 4, 38)     0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 2, 2, 38)     0           dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 2, 2, 38)     152         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 2, 2, 38)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 2, 2, 38)     12996       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 2, 2, 38)     0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 2, 2, 76)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 2, 2, 76)     304         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 2, 2, 76)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 2, 2, 38)     25992       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 2, 2, 38)     0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 2, 2, 114)    0           concatenate_24[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 2, 2, 114)    456         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 2, 2, 114)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 2, 2, 38)     38988       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 2, 2, 38)     0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 2, 2, 152)    0           concatenate_25[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 2, 2, 152)    608         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 2, 2, 152)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 2, 2, 38)     51984       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 2, 2, 38)     0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 2, 2, 190)    0           concatenate_26[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 2, 2, 190)    760         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 2, 2, 190)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 2, 2, 38)     64980       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 2, 2, 38)     0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 2, 2, 228)    0           concatenate_27[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 2, 2, 228)    912         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 2, 2, 228)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 2, 2, 38)     77976       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 2, 2, 38)     0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 2, 2, 266)    0           concatenate_28[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 2, 2, 266)    1064        concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 2, 2, 266)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 2, 2, 38)     90972       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 2, 2, 38)     0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 2, 2, 304)    0           concatenate_29[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 2, 2, 304)    1216        concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 2, 2, 304)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 2, 2, 38)     103968      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 2, 2, 38)     0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 2, 2, 342)    0           concatenate_30[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 2, 2, 342)    1368        concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 2, 2, 342)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 342)    0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 1, 1, 10)     3420        average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 10)           0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 10)           0           global_max_pooling2d[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 1,942,218\n",
      "Trainable params: 1,928,538\n",
      "Non-trainable params: 13,680\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = layers.Input(shape=(img_height, img_width, channel))\n",
    "First_Conv2D = layers.Conv2D(38, (3,3),strides=2, use_bias=False ,padding='same',activation='relu', kernel_initializer='he_uniform')(input)\n",
    "\n",
    "First_Block = denseblock(First_Conv2D, 38, 0.2)\n",
    "First_Transition = transition(First_Block, 38, 0.2)\n",
    "\n",
    "\n",
    "Second_Block = denseblock(First_Transition, 38, 0.2)\n",
    "Second_Transition = transition(Second_Block, 38, 0.2)\n",
    "\n",
    "\n",
    "Third_Block = denseblock(Second_Transition, 38, 0.2)\n",
    "Third_Transition = transition(Third_Block, 38, 0.2)\n",
    "\n",
    "\n",
    "Last_Block = denseblock(Third_Transition, 38, 0.2)\n",
    "output = output_layer(Last_Block)\n",
    "\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()\n",
    "tensorboard = TensorBoard(log_dir=\"logs/\".format(time))\n",
    "\n",
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 16055
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10145084,
     "status": "ok",
     "timestamp": 1577035483623,
     "user": {
      "displayName": "Vanshika Soni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtyF9JxznP1YRjask9-WpvFdu9lJWwZpPMm-wJcQ=s64",
      "userId": "18404784623742601191"
     },
     "user_tz": -330
    },
    "id": "By0QvWOFzzBC",
    "outputId": "70dff001-8058-4856-c0ad-b67d2262d53a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.7870 - acc: 0.3462Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 4s 427us/sample - loss: 2.0264 - acc: 0.3680\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.36800, saving model to weights.h5\n",
      "782/782 [==============================] - 92s 117ms/step - loss: 1.7869 - acc: 0.3463 - val_loss: 2.2817 - val_acc: 0.3680\n",
      "Epoch 2/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.4826 - acc: 0.4636Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 1.5479 - acc: 0.5236\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.36800 to 0.52360, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 1.4823 - acc: 0.4637 - val_loss: 1.4672 - val_acc: 0.5236\n",
      "Epoch 3/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.3484 - acc: 0.5213Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 327us/sample - loss: 1.3335 - acc: 0.5191\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.52360\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 1.3483 - acc: 0.5215 - val_loss: 1.5701 - val_acc: 0.5191\n",
      "Epoch 4/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.2351 - acc: 0.5618Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 1.1155 - acc: 0.5830\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.52360 to 0.58300, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 1.2351 - acc: 0.5618 - val_loss: 1.2729 - val_acc: 0.5830\n",
      "Epoch 5/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.1521 - acc: 0.5886Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.9934 - acc: 0.6444\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.58300 to 0.64440, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 1.1521 - acc: 0.5886 - val_loss: 1.0841 - val_acc: 0.6444\n",
      "Epoch 6/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0896 - acc: 0.6147Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 327us/sample - loss: 1.0304 - acc: 0.6968\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.64440 to 0.69680, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 1.0896 - acc: 0.6146 - val_loss: 0.9058 - val_acc: 0.6968\n",
      "Epoch 7/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.0337 - acc: 0.6357Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 1.0069 - acc: 0.6644\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.69680\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 1.0334 - acc: 0.6358 - val_loss: 1.0266 - val_acc: 0.6644\n",
      "Epoch 8/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.9855 - acc: 0.6541Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 327us/sample - loss: 0.8332 - acc: 0.7105\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.69680 to 0.71050, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.9856 - acc: 0.6540 - val_loss: 0.9202 - val_acc: 0.7105\n",
      "Epoch 9/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.9539 - acc: 0.6680Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.8595 - acc: 0.6707\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.71050\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.9539 - acc: 0.6679 - val_loss: 1.0234 - val_acc: 0.6707\n",
      "Epoch 10/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.9182 - acc: 0.6769Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 1.0354 - acc: 0.6697\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.71050\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.9185 - acc: 0.6767 - val_loss: 1.0145 - val_acc: 0.6697\n",
      "Epoch 11/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.8902 - acc: 0.6884Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 327us/sample - loss: 0.8516 - acc: 0.7095\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.71050\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 0.8901 - acc: 0.6884 - val_loss: 0.9528 - val_acc: 0.7095\n",
      "Epoch 12/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.8672 - acc: 0.6976Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 1.0049 - acc: 0.7066\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.71050\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.8671 - acc: 0.6976 - val_loss: 0.9830 - val_acc: 0.7066\n",
      "Epoch 13/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.8432 - acc: 0.7084Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.8260 - acc: 0.7479\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.71050 to 0.74790, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.8430 - acc: 0.7084 - val_loss: 0.8045 - val_acc: 0.7479\n",
      "Epoch 14/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.8181 - acc: 0.7173Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.8324 - acc: 0.7289\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.74790\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.8180 - acc: 0.7173 - val_loss: 0.8731 - val_acc: 0.7289\n",
      "Epoch 15/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.7962 - acc: 0.7229Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.6721 - acc: 0.7725\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.74790 to 0.77250, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.7962 - acc: 0.7229 - val_loss: 0.7188 - val_acc: 0.7725\n",
      "Epoch 16/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.7775 - acc: 0.7292Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.5831 - acc: 0.7780\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.77250 to 0.77800, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.7775 - acc: 0.7292 - val_loss: 0.7300 - val_acc: 0.7780\n",
      "Epoch 17/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.7616 - acc: 0.7365Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.7572 - acc: 0.7527\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.77800\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.7617 - acc: 0.7365 - val_loss: 0.8238 - val_acc: 0.7527\n",
      "Epoch 18/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.7425 - acc: 0.7425Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.5132 - acc: 0.7744\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.77800\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 0.7421 - acc: 0.7426 - val_loss: 0.7053 - val_acc: 0.7744\n",
      "Epoch 19/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.7286 - acc: 0.7487Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.6523 - acc: 0.7702\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.77800\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.7286 - acc: 0.7487 - val_loss: 0.7882 - val_acc: 0.7702\n",
      "Epoch 20/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.7160 - acc: 0.7531Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.6274 - acc: 0.7743\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.77800\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.7159 - acc: 0.7532 - val_loss: 0.7079 - val_acc: 0.7743\n",
      "Epoch 21/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.7019 - acc: 0.7577Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 1.0740 - acc: 0.7083\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.77800\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.7020 - acc: 0.7578 - val_loss: 1.1902 - val_acc: 0.7083\n",
      "Epoch 22/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.6932 - acc: 0.7587Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.5649 - acc: 0.7814\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.77800 to 0.78140, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.6932 - acc: 0.7587 - val_loss: 0.7222 - val_acc: 0.7814\n",
      "Epoch 23/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.6813 - acc: 0.7648Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.5994 - acc: 0.7876\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.78140 to 0.78760, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.6813 - acc: 0.7647 - val_loss: 0.7200 - val_acc: 0.7876\n",
      "Epoch 24/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.6709 - acc: 0.7668Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 326us/sample - loss: 0.4921 - acc: 0.8269\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.78760 to 0.82690, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.6711 - acc: 0.7668 - val_loss: 0.5391 - val_acc: 0.8269\n",
      "Epoch 25/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.6654 - acc: 0.7681Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 327us/sample - loss: 0.4429 - acc: 0.8145\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.82690\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.6652 - acc: 0.7682 - val_loss: 0.5857 - val_acc: 0.8145\n",
      "Epoch 26/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.6591 - acc: 0.7732Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.5419 - acc: 0.8122\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.82690\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.6591 - acc: 0.7731 - val_loss: 0.5800 - val_acc: 0.8122\n",
      "Epoch 27/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.6417 - acc: 0.7794Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.4741 - acc: 0.8193\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.82690\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.6415 - acc: 0.7794 - val_loss: 0.5690 - val_acc: 0.8193\n",
      "Epoch 28/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.6343 - acc: 0.7785Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.5455 - acc: 0.8253\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.82690\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.6343 - acc: 0.7785 - val_loss: 0.5878 - val_acc: 0.8253\n",
      "Epoch 29/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.6288 - acc: 0.7810Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.5726 - acc: 0.8195\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.82690\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.6286 - acc: 0.7811 - val_loss: 0.5929 - val_acc: 0.8195\n",
      "Epoch 30/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.6230 - acc: 0.7832Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.4639 - acc: 0.8021\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.82690\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.6230 - acc: 0.7832 - val_loss: 0.6573 - val_acc: 0.8021\n",
      "Epoch 31/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.6125 - acc: 0.7866Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.4317 - acc: 0.8290\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.82690 to 0.82900, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.6123 - acc: 0.7867 - val_loss: 0.5473 - val_acc: 0.8290\n",
      "Epoch 32/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.6088 - acc: 0.7880Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 325us/sample - loss: 1.1729 - acc: 0.7181\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.82900\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 0.6087 - acc: 0.7880 - val_loss: 1.1415 - val_acc: 0.7181\n",
      "Epoch 33/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5943 - acc: 0.7938Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.7583 - acc: 0.8049\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.82900\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.5944 - acc: 0.7937 - val_loss: 0.6414 - val_acc: 0.8049\n",
      "Epoch 34/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5946 - acc: 0.7955Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.4859 - acc: 0.8208\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.82900\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 0.5947 - acc: 0.7954 - val_loss: 0.6096 - val_acc: 0.8208\n",
      "Epoch 35/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5867 - acc: 0.7970Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.3792 - acc: 0.8413\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.82900 to 0.84130, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.5867 - acc: 0.7970 - val_loss: 0.5080 - val_acc: 0.8413\n",
      "Epoch 36/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5819 - acc: 0.8009Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.3662 - acc: 0.8496\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.84130 to 0.84960, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.5817 - acc: 0.8009 - val_loss: 0.4653 - val_acc: 0.8496\n",
      "Epoch 37/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5755 - acc: 0.8012Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.3544 - acc: 0.8466\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.84960\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.5755 - acc: 0.8012 - val_loss: 0.5051 - val_acc: 0.8466\n",
      "Epoch 38/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5707 - acc: 0.8028Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.8746 - acc: 0.7954\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.84960\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.5711 - acc: 0.8027 - val_loss: 0.6956 - val_acc: 0.7954\n",
      "Epoch 39/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5692 - acc: 0.8032Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.4105 - acc: 0.8435\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.84960\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.5690 - acc: 0.8033 - val_loss: 0.5113 - val_acc: 0.8435\n",
      "Epoch 40/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5675 - acc: 0.8034Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.4090 - acc: 0.8484\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.84960\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.5674 - acc: 0.8035 - val_loss: 0.5137 - val_acc: 0.8484\n",
      "Epoch 41/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5556 - acc: 0.8090Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.3261 - acc: 0.8591\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.84960 to 0.85910, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.5559 - acc: 0.8088 - val_loss: 0.4628 - val_acc: 0.8591\n",
      "Epoch 42/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5528 - acc: 0.8062Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.5682 - acc: 0.8161\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.85910\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.5526 - acc: 0.8062 - val_loss: 0.6329 - val_acc: 0.8161\n",
      "Epoch 43/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5484 - acc: 0.8120Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.3908 - acc: 0.8466\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.85910\n",
      "782/782 [==============================] - 68s 88ms/step - loss: 0.5483 - acc: 0.8120 - val_loss: 0.4869 - val_acc: 0.8466\n",
      "Epoch 44/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5398 - acc: 0.8131Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.4078 - acc: 0.8446\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.85910\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.5394 - acc: 0.8133 - val_loss: 0.5141 - val_acc: 0.8446\n",
      "Epoch 45/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5376 - acc: 0.8143Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3909 - acc: 0.8498\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.85910\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.5378 - acc: 0.8142 - val_loss: 0.5058 - val_acc: 0.8498\n",
      "Epoch 46/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5283 - acc: 0.8164Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.4900 - acc: 0.8318\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.85910\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.5282 - acc: 0.8164 - val_loss: 0.5669 - val_acc: 0.8318\n",
      "Epoch 47/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5297 - acc: 0.8173Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2965 - acc: 0.8745\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.85910 to 0.87450, saving model to weights.h5\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.5298 - acc: 0.8172 - val_loss: 0.4267 - val_acc: 0.8745\n",
      "Epoch 48/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5304 - acc: 0.8156Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.4576 - acc: 0.8456\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.5302 - acc: 0.8157 - val_loss: 0.5128 - val_acc: 0.8456\n",
      "Epoch 49/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5226 - acc: 0.8213Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.4179 - acc: 0.8446\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.5225 - acc: 0.8213 - val_loss: 0.4917 - val_acc: 0.8446\n",
      "Epoch 50/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5197 - acc: 0.8222Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.3343 - acc: 0.8588\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.5197 - acc: 0.8222 - val_loss: 0.4598 - val_acc: 0.8588\n",
      "Epoch 51/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5205 - acc: 0.8210Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.2624 - acc: 0.8705\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.5204 - acc: 0.8210 - val_loss: 0.4208 - val_acc: 0.8705\n",
      "Epoch 52/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5183 - acc: 0.8203Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.4129 - acc: 0.8596\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.5180 - acc: 0.8203 - val_loss: 0.4709 - val_acc: 0.8596\n",
      "Epoch 53/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5078 - acc: 0.8237Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.6004 - acc: 0.8666\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.5077 - acc: 0.8237 - val_loss: 0.4435 - val_acc: 0.8666\n",
      "Epoch 54/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5091 - acc: 0.8238Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.3537 - acc: 0.8614\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.5089 - acc: 0.8239 - val_loss: 0.4515 - val_acc: 0.8614\n",
      "Epoch 55/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5000 - acc: 0.8266Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.7580 - acc: 0.8298\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.5000 - acc: 0.8265 - val_loss: 0.6598 - val_acc: 0.8298\n",
      "Epoch 56/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5022 - acc: 0.8264Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.3255 - acc: 0.8688\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.5022 - acc: 0.8264 - val_loss: 0.4181 - val_acc: 0.8688\n",
      "Epoch 57/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4961 - acc: 0.8297Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3758 - acc: 0.8657\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4959 - acc: 0.8298 - val_loss: 0.4445 - val_acc: 0.8657\n",
      "Epoch 58/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4919 - acc: 0.8280Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.6266 - acc: 0.8372\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 0.4922 - acc: 0.8280 - val_loss: 0.5594 - val_acc: 0.8372\n",
      "Epoch 59/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4958 - acc: 0.8278Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.5857 - acc: 0.8438\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4959 - acc: 0.8277 - val_loss: 0.5493 - val_acc: 0.8438\n",
      "Epoch 60/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4890 - acc: 0.8304Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.5721 - acc: 0.8717\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 0.4891 - acc: 0.8303 - val_loss: 0.4250 - val_acc: 0.8717\n",
      "Epoch 61/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4916 - acc: 0.8297Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 337us/sample - loss: 0.3904 - acc: 0.8563\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4916 - acc: 0.8296 - val_loss: 0.5290 - val_acc: 0.8563\n",
      "Epoch 62/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4848 - acc: 0.8339Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.4512 - acc: 0.8559\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4850 - acc: 0.8338 - val_loss: 0.5100 - val_acc: 0.8559\n",
      "Epoch 63/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4782 - acc: 0.8350Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.4007 - acc: 0.8635\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4781 - acc: 0.8350 - val_loss: 0.4594 - val_acc: 0.8635\n",
      "Epoch 64/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4843 - acc: 0.8349Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.6071 - acc: 0.8505\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4844 - acc: 0.8348 - val_loss: 0.5671 - val_acc: 0.8505\n",
      "Epoch 65/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4729 - acc: 0.8369Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.2888 - acc: 0.8571\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4727 - acc: 0.8370 - val_loss: 0.4890 - val_acc: 0.8571\n",
      "Epoch 66/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4752 - acc: 0.8370Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.6709 - acc: 0.8405\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4753 - acc: 0.8369 - val_loss: 0.5899 - val_acc: 0.8405\n",
      "Epoch 67/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4723 - acc: 0.8371Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.3453 - acc: 0.8675\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.87450\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4724 - acc: 0.8370 - val_loss: 0.4394 - val_acc: 0.8675\n",
      "Epoch 68/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4703 - acc: 0.8391Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2872 - acc: 0.8784\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.87450 to 0.87840, saving model to weights.h5\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4704 - acc: 0.8391 - val_loss: 0.4148 - val_acc: 0.8784\n",
      "Epoch 69/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4678 - acc: 0.8388Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.4323 - acc: 0.8567\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.87840\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4677 - acc: 0.8388 - val_loss: 0.4912 - val_acc: 0.8567\n",
      "Epoch 70/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4684 - acc: 0.8390Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3998 - acc: 0.8672\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.87840\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4686 - acc: 0.8389 - val_loss: 0.4676 - val_acc: 0.8672\n",
      "Epoch 71/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4580 - acc: 0.8410Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.3555 - acc: 0.8635\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.87840\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4579 - acc: 0.8410 - val_loss: 0.4557 - val_acc: 0.8635\n",
      "Epoch 72/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4633 - acc: 0.8397Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.5644 - acc: 0.8649\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.87840\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4633 - acc: 0.8397 - val_loss: 0.5067 - val_acc: 0.8649\n",
      "Epoch 73/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4572 - acc: 0.8414Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.5044 - acc: 0.8686\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.87840\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4573 - acc: 0.8413 - val_loss: 0.4651 - val_acc: 0.8686\n",
      "Epoch 74/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4614 - acc: 0.8416Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3390 - acc: 0.8776\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.87840\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 0.4614 - acc: 0.8416 - val_loss: 0.4193 - val_acc: 0.8776\n",
      "Epoch 75/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4560 - acc: 0.8423Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.4075 - acc: 0.8757\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.87840\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 0.4561 - acc: 0.8423 - val_loss: 0.4160 - val_acc: 0.8757\n",
      "Epoch 76/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4530 - acc: 0.8437Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 336us/sample - loss: 0.4247 - acc: 0.8779\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.87840\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 0.4529 - acc: 0.8436 - val_loss: 0.4739 - val_acc: 0.8779\n",
      "Epoch 77/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4525 - acc: 0.8427Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.4198 - acc: 0.8692\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.87840\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 0.4527 - acc: 0.8427 - val_loss: 0.4383 - val_acc: 0.8692\n",
      "Epoch 78/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4471 - acc: 0.8454Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 327us/sample - loss: 0.3353 - acc: 0.8775\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.87840\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4472 - acc: 0.8453 - val_loss: 0.4293 - val_acc: 0.8775\n",
      "Epoch 79/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4515 - acc: 0.8455Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.3130 - acc: 0.8792\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.87840 to 0.87920, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4516 - acc: 0.8456 - val_loss: 0.3926 - val_acc: 0.8792\n",
      "Epoch 80/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4481 - acc: 0.8457Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.5548 - acc: 0.8854\n",
      "\n",
      "Epoch 00080: val_acc improved from 0.87920 to 0.88540, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4481 - acc: 0.8457 - val_loss: 0.4423 - val_acc: 0.8854\n",
      "Epoch 81/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4495 - acc: 0.8452Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.4659 - acc: 0.8768\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.88540\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4493 - acc: 0.8453 - val_loss: 0.4199 - val_acc: 0.8768\n",
      "Epoch 82/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4402 - acc: 0.8478Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.4195 - acc: 0.8700\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.88540\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 0.4403 - acc: 0.8478 - val_loss: 0.4642 - val_acc: 0.8700\n",
      "Epoch 83/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4423 - acc: 0.8455Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.6638 - acc: 0.8625\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.88540\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 0.4422 - acc: 0.8456 - val_loss: 0.5468 - val_acc: 0.8625\n",
      "Epoch 84/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4464 - acc: 0.8461Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.3199 - acc: 0.8843\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.88540\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4464 - acc: 0.8460 - val_loss: 0.4177 - val_acc: 0.8843\n",
      "Epoch 85/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4348 - acc: 0.8512Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.3743 - acc: 0.8802\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.88540\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4346 - acc: 0.8513 - val_loss: 0.4539 - val_acc: 0.8802\n",
      "Epoch 86/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4331 - acc: 0.8500Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.2586 - acc: 0.8912\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.88540 to 0.89120, saving model to weights.h5\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4330 - acc: 0.8501 - val_loss: 0.3639 - val_acc: 0.8912\n",
      "Epoch 87/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4309 - acc: 0.8508Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.5177 - acc: 0.8624\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.89120\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4307 - acc: 0.8509 - val_loss: 0.5146 - val_acc: 0.8624\n",
      "Epoch 88/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4306 - acc: 0.8510Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.3728 - acc: 0.8796\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.89120\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4305 - acc: 0.8511 - val_loss: 0.4368 - val_acc: 0.8796\n",
      "Epoch 89/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4278 - acc: 0.8522Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3832 - acc: 0.8837\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.89120\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4280 - acc: 0.8521 - val_loss: 0.4276 - val_acc: 0.8837\n",
      "Epoch 90/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4264 - acc: 0.8521Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.5560 - acc: 0.8423\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.89120\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 0.4265 - acc: 0.8520 - val_loss: 0.7201 - val_acc: 0.8423\n",
      "Epoch 91/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4286 - acc: 0.8531Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.3283 - acc: 0.8942\n",
      "\n",
      "Epoch 00091: val_acc improved from 0.89120 to 0.89420, saving model to weights.h5\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.4285 - acc: 0.8531 - val_loss: 0.4077 - val_acc: 0.8942\n",
      "Epoch 92/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4293 - acc: 0.8539Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.2338 - acc: 0.8849\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4291 - acc: 0.8540 - val_loss: 0.3914 - val_acc: 0.8849\n",
      "Epoch 93/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4245 - acc: 0.8542Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.5419 - acc: 0.8724\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4245 - acc: 0.8542 - val_loss: 0.4704 - val_acc: 0.8724\n",
      "Epoch 94/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4271 - acc: 0.8513Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.4151 - acc: 0.8912\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4272 - acc: 0.8512 - val_loss: 0.4066 - val_acc: 0.8912\n",
      "Epoch 95/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4224 - acc: 0.8543Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.4199 - acc: 0.8740\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4223 - acc: 0.8543 - val_loss: 0.4519 - val_acc: 0.8740\n",
      "Epoch 96/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4209 - acc: 0.8558Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.4485 - acc: 0.8837\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4210 - acc: 0.8557 - val_loss: 0.4513 - val_acc: 0.8837\n",
      "Epoch 97/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4162 - acc: 0.8564Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.3670 - acc: 0.8806\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4162 - acc: 0.8564 - val_loss: 0.4172 - val_acc: 0.8806\n",
      "Epoch 98/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4198 - acc: 0.8543Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 335us/sample - loss: 0.3265 - acc: 0.8801\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4199 - acc: 0.8542 - val_loss: 0.4449 - val_acc: 0.8801\n",
      "Epoch 99/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4155 - acc: 0.8573Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.5135 - acc: 0.8842\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4157 - acc: 0.8572 - val_loss: 0.4100 - val_acc: 0.8842\n",
      "Epoch 100/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4183 - acc: 0.8564Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 334us/sample - loss: 0.3342 - acc: 0.8832\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 0.4182 - acc: 0.8564 - val_loss: 0.4075 - val_acc: 0.8832\n",
      "Epoch 101/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4152 - acc: 0.8567Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.3633 - acc: 0.8826\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4151 - acc: 0.8568 - val_loss: 0.4296 - val_acc: 0.8826\n",
      "Epoch 102/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4114 - acc: 0.8596Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 327us/sample - loss: 0.4792 - acc: 0.8719\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4116 - acc: 0.8596 - val_loss: 0.4867 - val_acc: 0.8719\n",
      "Epoch 103/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4106 - acc: 0.8580Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 333us/sample - loss: 0.4176 - acc: 0.8787\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4106 - acc: 0.8580 - val_loss: 0.4688 - val_acc: 0.8787\n",
      "Epoch 104/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4072 - acc: 0.8583Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3603 - acc: 0.8869\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4074 - acc: 0.8582 - val_loss: 0.3969 - val_acc: 0.8869\n",
      "Epoch 105/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4094 - acc: 0.8585Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 325us/sample - loss: 0.4263 - acc: 0.8729\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4095 - acc: 0.8584 - val_loss: 0.4638 - val_acc: 0.8729\n",
      "Epoch 106/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4049 - acc: 0.8604Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.2394 - acc: 0.8933\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4049 - acc: 0.8605 - val_loss: 0.3655 - val_acc: 0.8933\n",
      "Epoch 107/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4065 - acc: 0.8597Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.4423 - acc: 0.8888\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4064 - acc: 0.8597 - val_loss: 0.4010 - val_acc: 0.8888\n",
      "Epoch 108/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4040 - acc: 0.8603Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3317 - acc: 0.8875\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4040 - acc: 0.8604 - val_loss: 0.4700 - val_acc: 0.8875\n",
      "Epoch 109/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4032 - acc: 0.8602Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.4853 - acc: 0.8793\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4033 - acc: 0.8601 - val_loss: 0.4269 - val_acc: 0.8793\n",
      "Epoch 110/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3968 - acc: 0.8623Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.3761 - acc: 0.8889\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3969 - acc: 0.8623 - val_loss: 0.3898 - val_acc: 0.8889\n",
      "Epoch 111/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4051 - acc: 0.8628Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3956 - acc: 0.8923\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4051 - acc: 0.8628 - val_loss: 0.3869 - val_acc: 0.8923\n",
      "Epoch 112/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4046 - acc: 0.8593Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.3108 - acc: 0.8831\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.4048 - acc: 0.8592 - val_loss: 0.4636 - val_acc: 0.8831\n",
      "Epoch 113/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3966 - acc: 0.8634Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.3024 - acc: 0.8935\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 0.3966 - acc: 0.8633 - val_loss: 0.3558 - val_acc: 0.8935\n",
      "Epoch 114/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3973 - acc: 0.8638Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.5471 - acc: 0.8865\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3973 - acc: 0.8638 - val_loss: 0.4282 - val_acc: 0.8865\n",
      "Epoch 115/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3939 - acc: 0.8634Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3328 - acc: 0.8941\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.89420\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3940 - acc: 0.8633 - val_loss: 0.3432 - val_acc: 0.8941\n",
      "Epoch 116/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3958 - acc: 0.8631Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.3062 - acc: 0.8951\n",
      "\n",
      "Epoch 00116: val_acc improved from 0.89420 to 0.89510, saving model to weights.h5\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 0.3959 - acc: 0.8631 - val_loss: 0.4120 - val_acc: 0.8951\n",
      "Epoch 117/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3960 - acc: 0.8631Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 338us/sample - loss: 0.2619 - acc: 0.8957\n",
      "\n",
      "Epoch 00117: val_acc improved from 0.89510 to 0.89570, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3960 - acc: 0.8631 - val_loss: 0.3587 - val_acc: 0.8957\n",
      "Epoch 118/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3998 - acc: 0.8624Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.3497 - acc: 0.8846\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.89570\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3997 - acc: 0.8624 - val_loss: 0.4160 - val_acc: 0.8846\n",
      "Epoch 119/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3965 - acc: 0.8638Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3730 - acc: 0.8915\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.89570\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3967 - acc: 0.8637 - val_loss: 0.3768 - val_acc: 0.8915\n",
      "Epoch 120/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3921 - acc: 0.8651Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.4023 - acc: 0.8873\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.89570\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3920 - acc: 0.8651 - val_loss: 0.4325 - val_acc: 0.8873\n",
      "Epoch 121/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3970 - acc: 0.8641Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3146 - acc: 0.8863\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.89570\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3971 - acc: 0.8641 - val_loss: 0.3900 - val_acc: 0.8863\n",
      "Epoch 122/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3929 - acc: 0.8643Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 327us/sample - loss: 0.3167 - acc: 0.8979\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.89570 to 0.89790, saving model to weights.h5\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 0.3929 - acc: 0.8643 - val_loss: 0.3508 - val_acc: 0.8979\n",
      "Epoch 123/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3888 - acc: 0.8656Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.5070 - acc: 0.8761\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.89790\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3889 - acc: 0.8656 - val_loss: 0.4580 - val_acc: 0.8761\n",
      "Epoch 124/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3929 - acc: 0.8651Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.3301 - acc: 0.9018\n",
      "\n",
      "Epoch 00124: val_acc improved from 0.89790 to 0.90180, saving model to weights.h5\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 0.3928 - acc: 0.8651 - val_loss: 0.3473 - val_acc: 0.9018\n",
      "Epoch 125/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3864 - acc: 0.8666Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.3024 - acc: 0.8946\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.90180\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3864 - acc: 0.8666 - val_loss: 0.3882 - val_acc: 0.8946\n",
      "Epoch 126/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3869 - acc: 0.8691Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3212 - acc: 0.8953\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.90180\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3872 - acc: 0.8690 - val_loss: 0.3887 - val_acc: 0.8953\n",
      "Epoch 127/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3842 - acc: 0.8675Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 327us/sample - loss: 0.3233 - acc: 0.8815\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.90180\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3842 - acc: 0.8674 - val_loss: 0.4519 - val_acc: 0.8815\n",
      "Epoch 128/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3826 - acc: 0.8681Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 327us/sample - loss: 0.2581 - acc: 0.9000\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.90180\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 0.3825 - acc: 0.8682 - val_loss: 0.3401 - val_acc: 0.9000\n",
      "Epoch 129/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3856 - acc: 0.8682Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.4217 - acc: 0.8976\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.90180\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3855 - acc: 0.8682 - val_loss: 0.3715 - val_acc: 0.8976\n",
      "Epoch 130/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3815 - acc: 0.8680Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.6599 - acc: 0.8857\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.90180\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 0.3815 - acc: 0.8680 - val_loss: 0.5231 - val_acc: 0.8857\n",
      "Epoch 131/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3796 - acc: 0.8695Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.2178 - acc: 0.9005\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.90180\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3796 - acc: 0.8695 - val_loss: 0.3469 - val_acc: 0.9005\n",
      "Epoch 132/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3789 - acc: 0.8702Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.4258 - acc: 0.8770\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.90180\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3789 - acc: 0.8703 - val_loss: 0.4815 - val_acc: 0.8770\n",
      "Epoch 133/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3810 - acc: 0.8688Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.4211 - acc: 0.8936\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.90180\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3812 - acc: 0.8687 - val_loss: 0.3881 - val_acc: 0.8936\n",
      "Epoch 134/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3788 - acc: 0.8698Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3890 - acc: 0.8874\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.90180\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3790 - acc: 0.8696 - val_loss: 0.4793 - val_acc: 0.8874\n",
      "Epoch 135/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3734 - acc: 0.8724Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3037 - acc: 0.9035\n",
      "\n",
      "Epoch 00135: val_acc improved from 0.90180 to 0.90350, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3736 - acc: 0.8724 - val_loss: 0.3688 - val_acc: 0.9035\n",
      "Epoch 136/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3761 - acc: 0.8718Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.4274 - acc: 0.9012\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.90350\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 0.3760 - acc: 0.8718 - val_loss: 0.4299 - val_acc: 0.9012\n",
      "Epoch 137/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3784 - acc: 0.8715Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.4426 - acc: 0.8919\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.90350\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 0.3784 - acc: 0.8715 - val_loss: 0.4313 - val_acc: 0.8919\n",
      "Epoch 138/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3757 - acc: 0.8710Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 327us/sample - loss: 0.3380 - acc: 0.8980\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.90350\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 0.3760 - acc: 0.8709 - val_loss: 0.3907 - val_acc: 0.8980\n",
      "Epoch 139/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3698 - acc: 0.8741Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 327us/sample - loss: 0.3599 - acc: 0.9001\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.90350\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 0.3696 - acc: 0.8742 - val_loss: 0.3836 - val_acc: 0.9001\n",
      "Epoch 140/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3698 - acc: 0.8725Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.2248 - acc: 0.9097\n",
      "\n",
      "Epoch 00140: val_acc improved from 0.90350 to 0.90970, saving model to weights.h5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3696 - acc: 0.8726 - val_loss: 0.3059 - val_acc: 0.9097\n",
      "Epoch 141/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3747 - acc: 0.8717Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3729 - acc: 0.8931\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.90970\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3747 - acc: 0.8716 - val_loss: 0.4113 - val_acc: 0.8931\n",
      "Epoch 142/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3736 - acc: 0.8709Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 330us/sample - loss: 0.4377 - acc: 0.8949\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.90970\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3736 - acc: 0.8709 - val_loss: 0.3994 - val_acc: 0.8949\n",
      "Epoch 143/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3675 - acc: 0.8750Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3859 - acc: 0.9048\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.90970\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3675 - acc: 0.8750 - val_loss: 0.3404 - val_acc: 0.9048\n",
      "Epoch 144/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3774 - acc: 0.8707Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.4123 - acc: 0.8957\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.90970\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3775 - acc: 0.8707 - val_loss: 0.3843 - val_acc: 0.8957\n",
      "Epoch 145/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3696 - acc: 0.8717Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 328us/sample - loss: 0.4388 - acc: 0.8899\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.90970\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3697 - acc: 0.8717 - val_loss: 0.4213 - val_acc: 0.8899\n",
      "Epoch 146/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3714 - acc: 0.8732Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.4117 - acc: 0.8952\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.90970\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3713 - acc: 0.8731 - val_loss: 0.4130 - val_acc: 0.8952\n",
      "Epoch 147/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3698 - acc: 0.8723Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 331us/sample - loss: 0.3084 - acc: 0.8847\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.90970\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3697 - acc: 0.8723 - val_loss: 0.4558 - val_acc: 0.8847\n",
      "Epoch 148/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3690 - acc: 0.8732Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 327us/sample - loss: 0.3242 - acc: 0.9028\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.90970\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3690 - acc: 0.8732 - val_loss: 0.3341 - val_acc: 0.9028\n",
      "Epoch 149/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3671 - acc: 0.8748Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 332us/sample - loss: 0.3122 - acc: 0.8944\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.90970\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3670 - acc: 0.8748 - val_loss: 0.4008 - val_acc: 0.8944\n",
      "Epoch 150/150\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3647 - acc: 0.8745Epoch 1/150\n",
      "10000/782 [===============================================================================================================================================================================================================================================================================================================================================================================================] - 3s 329us/sample - loss: 0.4032 - acc: 0.9054\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.90970\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3645 - acc: 0.8745 - val_loss: 0.3406 - val_acc: 0.9054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc6ec5b0ac8>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights.h5\", monitor='val_acc' ,verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), epochs=epochs,verbose=1, \n",
    "                    validation_data=(X_test, y_test),callbacks=[checkpointer,tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4m444Xwvdm8"
   },
   "source": [
    "## Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZO3689vEzzBF"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights.h5\")\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_C84yTqzzBH"
   },
   "source": [
    "### Evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6395,
     "status": "ok",
     "timestamp": 1577035638096,
     "user": {
      "displayName": "Vanshika Soni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtyF9JxznP1YRjask9-WpvFdu9lJWwZpPMm-wJcQ=s64",
      "userId": "18404784623742601191"
     },
     "user_tz": -330
    },
    "id": "ZcWydmIVhZGr",
    "outputId": "7aea026d-ba19-4844-fe62-0e267344ab66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 477us/sample - loss: 0.3067 - acc: 0.9097\n",
      "| -------------------------------------------------- |\n",
      "  Test loss: 0.30672525559067726\n",
      "| -------------------------------------------------- |\n",
      "  Test accuracy: 0.9097\n",
      "| -------------------------------------------------- |\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"|\",\"-\"*50,\"|\")\n",
    "print('  Test loss:', score[0])\n",
    "print(\"|\",\"-\"*50,\"|\")\n",
    "print('  Test accuracy:', score[1])\n",
    "print(\"|\",\"-\"*50,\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visulaizing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%load_ext tensorboard\\n%tensorboard --logdir logs'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"%load_ext tensorboard\n",
    "%tensorboard --logdir logs\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"model.png\">"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vanshikasoni616gmail.com-CIFAR.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
