{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, InputLayer, Dense, Dropout, ZeroPadding2D, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.initializers import he_normal\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Softmax output dim\n",
    "num_classes = 10\n",
    "batch_size = 140\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format()=='channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "    \n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0],  img_rows, img_cols,1)\n",
    "    X_test = X_test.reshape(X_test.shape[0],  img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "old_v = tf.logging.get_verbosity\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0:30000]=np.fliplr(X_train[0:30000])\n",
    "X_test[0:5000]=np.fliplr(X_test[0:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e5ca7405c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[299].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 444,890\n",
      "Trainable params: 443,706\n",
      "Non-trainable params: 1,184\n",
      "_________________________________________________________________\n",
      "None \n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.5274 - acc: 0.8351 - val_loss: 0.1312 - val_acc: 0.9574\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.1818 - acc: 0.9440 - val_loss: 0.0924 - val_acc: 0.9706\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.1323 - acc: 0.9587 - val_loss: 0.0742 - val_acc: 0.9755\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1083 - acc: 0.9662 - val_loss: 0.0626 - val_acc: 0.9805\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0953 - acc: 0.9699 - val_loss: 0.0610 - val_acc: 0.9810\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 70s 1ms/step - loss: 0.0838 - acc: 0.9738 - val_loss: 0.0574 - val_acc: 0.9824\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0765 - acc: 0.9764 - val_loss: 0.0569 - val_acc: 0.9821\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0705 - acc: 0.9776 - val_loss: 0.0669 - val_acc: 0.9793\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0648 - acc: 0.9792 - val_loss: 0.0530 - val_acc: 0.9828\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 76s 1ms/step - loss: 0.0630 - acc: 0.9797 - val_loss: 0.0463 - val_acc: 0.9846\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 70s 1ms/step - loss: 0.0594 - acc: 0.9814 - val_loss: 0.0502 - val_acc: 0.9841\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0566 - acc: 0.9818 - val_loss: 0.0405 - val_acc: 0.9871\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0531 - acc: 0.9827 - val_loss: 0.0534 - val_acc: 0.9829\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0495 - acc: 0.9845 - val_loss: 0.0518 - val_acc: 0.9837\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0455 - acc: 0.9855 - val_loss: 0.0431 - val_acc: 0.9861\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0495 - acc: 0.9840 - val_loss: 0.0415 - val_acc: 0.9870\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0438 - acc: 0.9853 - val_loss: 0.0460 - val_acc: 0.9857\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0437 - acc: 0.9860 - val_loss: 0.0455 - val_acc: 0.9861\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0398 - acc: 0.9870 - val_loss: 0.0434 - val_acc: 0.9869\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 71s 1ms/step - loss: 0.0401 - acc: 0.9873 - val_loss: 0.0376 - val_acc: 0.9881\n"
     ]
    }
   ],
   "source": [
    "# Converting y_train 10-D vector\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), strides =(1,1), padding = 'same',\n",
    "                 activation = 'relu', input_shape = input_shape,\n",
    "                 kernel_initializer = he_normal(seed=None)))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), strides =(1,1), padding = 'same',\n",
    "                 activation = 'relu', kernel_initializer = he_normal(seed=None)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), strides =(1,1), padding = 'same',\n",
    "                 activation = 'relu', kernel_initializer = he_normal(seed=None)))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), strides =(1,1), padding = 'same',\n",
    "                 activation = 'relu', kernel_initializer = he_normal(seed=None)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units = 512, activation='relu', kernel_initializer= he_normal(seed=None)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(units = 64, activation='relu', kernel_initializer= he_normal(seed=None)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(units = num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary(), '\\n')\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = batch_size,\n",
    "                    epochs = epochs, verbose = 1, validation_data = (X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist.h5')\n",
    "model.save_weights('mnist_weights.h5')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def auc (y_true, y_pred):\n",
    "    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
